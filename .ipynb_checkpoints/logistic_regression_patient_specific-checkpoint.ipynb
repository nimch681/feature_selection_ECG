{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "\n",
    "\n",
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old = DF.get_all_dataframe_patient_specific(200,patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_log.text', 'rb')\n",
    "n_s = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_log.text', 'rb')\n",
    "n_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_log.text', 'rb')\n",
    "n_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_log.text', 'rb')\n",
    "s_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_log.text', 'rb')\n",
    "s_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_log.text', 'rb')\n",
    "v_f = pickle.load(f)[1]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test from DB1\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 0] = 1\n",
    "y_train[y_train == 0] = 0\n",
    "\n",
    "y_test[y_test != 0] = 1\n",
    "y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test from DB1\n",
    "## Train test from DB1\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 1] = 0\n",
    "y_train[y_train == 1] = 1\n",
    "\n",
    "y_test[y_test != 1] = 0\n",
    "y_test[y_test == 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test from DB1\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test from DB1\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "y_test[y_test != 3] = 0\n",
    "y_test[y_test == 3] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test = X_test[2000:4000]\n",
    "y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 0] = 1\n",
    "y_train[y_train == 0] = 0\n",
    "\n",
    "y_test[y_test != 0] = 1\n",
    "y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test = X_test[2000:4000]\n",
    "y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 1] = 0\n",
    "y_train[y_train == 1] = 1\n",
    "\n",
    "y_test[y_test != 1] = 0\n",
    "y_test[y_test == 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test = X_test[2000:4000]\n",
    "y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "X_test = X_test[2000:4000]\n",
    "y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "y_test[y_test != 3] = 0\n",
    "y_test[y_test == 3] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 0] =1\n",
    "y_train[y_train == 0] = 0\n",
    "\n",
    "y_test[y_test != 0] = 1\n",
    "y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 1] = 0\n",
    "y_train[y_train == 1] = 1\n",
    "\n",
    "y_test[y_test != 1] = 0\n",
    "y_test[y_test == 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, test, y_train, ytest = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#X_test = X_test[2000:4000]\n",
    "#y_test = y_test[2000:4000]\n",
    "#train, X_test, ytrain, y_test = train_test_split(X_test, y_test, test_size=0.80, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "y_test[y_test != 3] = 0\n",
    "y_test[y_test == 3] = 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
