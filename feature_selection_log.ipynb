{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "\n",
    "\n",
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_log.text', 'rb')\n",
    "n_s = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_log.text', 'rb')\n",
    "n_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_log.text', 'rb')\n",
    "n_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_log.text', 'rb')\n",
    "s_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_log.text', 'rb')\n",
    "s_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_log.text', 'rb')\n",
    "v_f = pickle.load(f)[1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-37452470094b>, line 97)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-37452470094b>\"\u001b[1;36m, line \u001b[1;32m97\u001b[0m\n\u001b[1;33m    =ada.fit_sample(X_test, y_test)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"ensamble ln\")\n",
    "print(\"all\")\n",
    "#classifier.voting_ensemble_lin(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.voting_ensemble_lin(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.voting_ensemble_lin(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.voting_ensemble_lin(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.voting_ensemble_lin(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.voting_ensemble_lin(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.voting_ensemble_lin(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "\n",
    "ada=RandomUnderSampler(ratio='not minority')\n",
    "train, train_labels=ada.fit_sample(X_train, y_train)\n",
    "test, \n",
    "=ada.fit_sample(X_test, y_test)\n",
    "\n",
    "X_train = train\n",
    "#X_test = test\n",
    "y_train = train_labels\n",
    "#y_test = test_labels\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "\n",
    "\n",
    "print(\"ensamble ln\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n vs all results for various classifier\n",
      "n_s\n",
      "[[43360   229   352    80]\n",
      " [ 1519    35   463    33]\n",
      " [ 1448    38  1669    65]\n",
      " [  381     0     7     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     44021\n",
      "           1       0.12      0.02      0.03      2050\n",
      "           2       0.67      0.52      0.58      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.43      0.38      0.39     49679\n",
      "weighted avg       0.87      0.91      0.89     49679\n",
      "\n",
      "[0.4313224958380087, 1.3213022351893482, 0.38082402731767284]\n"
     ]
    }
   ],
   "source": [
    "##N class majority\n",
    "## V_f ensemble all \n",
    "#V_f lin\n",
    "##1 n_v Low percision but high recall  (43360)\n",
    "\n",
    "### \n",
    "\n",
    "\n",
    "print(\"n vs all results for various classifier\")\n",
    "\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "y_pred_rand_n_s = classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])[2]\n",
    "ab_normal_X_test_1 =X_test[y_pred_rand_n_s != 0]\n",
    "ab_normal_y_test_1 =y_test[y_pred_rand_n_s != 0]\n",
    "\n",
    "\n",
    "normal_x_test = X_test[y_pred_rand_n_s == 0]\n",
    "normal_y_pred = y_pred_rand_n_s[y_pred_rand_n_s == 0]\n",
    "normal_y_test = y_test[y_pred_rand_n_s == 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41363    31   162  1804]\n",
      " [ 1509     2     4     4]\n",
      " [  202    42  1142    62]\n",
      " [  141     1    41   198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     43360\n",
      "           1       0.03      0.00      0.00      1519\n",
      "           2       0.85      0.79      0.82      1448\n",
      "           3       0.10      0.52      0.16       381\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     46708\n",
      "   macro avg       0.48      0.57      0.48     46708\n",
      "weighted avg       0.92      0.91      0.91     46708\n",
      "\n",
      "[0.3869327429872356, 1.6628594805412609, 0.4013238065612754]\n"
     ]
    }
   ],
   "source": [
    "normal_x_test = pd.DataFrame(normal_x_test,columns=features_clinic)\n",
    "##s_v seperate v class best\n",
    "y_pred_ensemble_lin = classifier.voting_ensemble_lin(X_train[s_v], y_train, normal_x_test[s_v], normal_y_test, jk=True,labels=[0,1,2,3])[1]\n",
    "\n",
    "\n",
    "normal_x_test_s_v =normal_x_test[y_pred_ensemble_lin != 2]\n",
    "normal_y_test_s_v =normal_y_test[y_pred_ensemble_lin != 2]\n",
    "\n",
    "\n",
    "normal_x_v_normal = normal_x_test[y_pred_ensemble_lin == 2]\n",
    "y_pred_svm_v_normal = y_pred_ensemble_lin[y_pred_ensemble_lin == 2]\n",
    "y_test_svm_v_normal = normal_y_test[y_pred_ensemble_lin == 2]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ensemble_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41363    31   162  1804]\n",
      " [ 1509     2     4     4]\n",
      " [  202    42  1142    62]\n",
      " [  141     1    41   198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     43360\n",
      "           1       0.03      0.00      0.00      1519\n",
      "           2       0.85      0.79      0.82      1448\n",
      "           3       0.10      0.52      0.16       381\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     46708\n",
      "   macro avg       0.48      0.57      0.48     46708\n",
      "weighted avg       0.92      0.91      0.91     46708\n",
      "\n",
      "[0.3869327429872356, 1.6628594805412609, 0.4013238065612754]\n"
     ]
    }
   ],
   "source": [
    "normal_x_test = pd.DataFrame(normal_x_test,columns=features_clinic)\n",
    "##s_v seperate v class best\n",
    "y_pred_ensemble_lin = classifier.voting_ensemble_lin(X_train[s_v], y_train, normal_x_test[s_v], normal_y_test, jk=True,labels=[0,1,2,3])[1]\n",
    "\n",
    "\n",
    "normal_x_test_s_v =normal_x_test[y_pred_ensemble_lin != 2]\n",
    "normal_y_test_s_v =normal_y_test[y_pred_ensemble_lin != 2]\n",
    "\n",
    "#y_pred_temp = y_pred_ensemble_lin[y_pred_ensemble_lin != 2]\n",
    "\n",
    "#normal_x_test_s_v =normal_x_test_s_v[y_pred_temp != 3]\n",
    "#normal_y_test_s_v =normal_y_test_s_v[y_pred_temp != 3]\n",
    "\n",
    "\n",
    "y_pred_svm_f_normal = y_pred_ensemble_lin[y_pred_ensemble_lin == 3]\n",
    "y_test_svm_f_normal = normal_y_test[y_pred_ensemble_lin == 3] \n",
    "\n",
    "y_pred_svm_v_normal = y_pred_ensemble_lin[y_pred_ensemble_lin == 2]\n",
    "y_test_svm_v_normal = normal_y_test[y_pred_ensemble_lin == 2]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42608    14   139   437]\n",
      " [ 1502    10     2     1]\n",
      " [  192     7    63    44]\n",
      " [   39     0     0   301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     43198\n",
      "           1       0.32      0.01      0.01      1515\n",
      "           2       0.31      0.21      0.25       306\n",
      "           3       0.38      0.89      0.54       340\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     45359\n",
      "   macro avg       0.49      0.52      0.44     45359\n",
      "weighted avg       0.93      0.95      0.93     45359\n",
      "\n",
      "[0.2386826086238746, 0.8438871875802381, 0.22482720275946705]\n"
     ]
    }
   ],
   "source": [
    "normal_x_test_s_v = pd.DataFrame(normal_x_test_s_v,columns=features_clinic)\n",
    "##s_v seperate v class best\n",
    "y_pred_ensemble_lin = classifier.voting_ensemble_lin(X_train[v_f], y_train, normal_x_test_s_v[v_f], normal_y_test_s_v, jk=True,labels=[0,1,2,3])[1]\n",
    "\n",
    "\n",
    "normal_x_test_v_f =normal_x_test_s_v[y_pred_ensemble_lin != 3]\n",
    "normal_y_test_v_f =normal_y_test_s_v[y_pred_ensemble_lin != 3]\n",
    "\n",
    "\n",
    "normal_x_test_f =normal_x_test_s_v[y_pred_ensemble_lin == 3]\n",
    "y_pred_svm_f_normal = y_pred_ensemble_lin[y_pred_ensemble_lin == 3]\n",
    "y_test_svm_f_normal = normal_x_test_s_v[y_pred_ensemble_lin == 3]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39933  2828     0     0]\n",
      " [  264  1250     0     0]\n",
      " [   57   205     0     0]\n",
      " [   35     4     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     42761\n",
      "           1       0.29      0.83      0.43      1514\n",
      "           2       0.00      0.00      0.00       262\n",
      "           3       0.00      0.00      0.00        39\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     44576\n",
      "   macro avg       0.32      0.44      0.35     44576\n",
      "weighted avg       0.96      0.92      0.94     44576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-5693aa29650d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0my_pred_ensemble_lin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogisticRegress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormal_x_test_v_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormal_y_test_v_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36mlogisticRegress\u001b[1;34m(X_train, y_train, X_test, y_test, jk, penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, solver, max_iter, multi_class, verbose, warm_start, n_jobs, labels)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mmet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mmet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\metric.py\u001b[0m in \u001b[0;36mget_metrics\u001b[1;34m(yhat, labels, lb)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlb\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mkappa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_kappa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_j_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mjkappa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkappa\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.125\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjkappa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\metric.py\u001b[0m in \u001b[0;36mget_j_index\u001b[1;34m(confusion_matrix)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_j_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mSes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mSev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mPs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mPv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "#ls.extend(['V', 'E'])                         # VEB\n",
    "#ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "#ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "#ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "\n",
    "\n",
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "#X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "#y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "\n",
    "rank_n_s = pd.read_csv(\"database/features_n_vs_s_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "\n",
    "score_n_s = 0.01\n",
    "\n",
    "\n",
    "n_s = rank_n_s[rank_n_s['rfscore'] >= score_n_s]['features'].values\n",
    "\n",
    "\n",
    "y_pred_ensemble_lin = classifier.logisticRegress(X_train[n_s], y_train, normal_x_test_v_f[n_s], normal_y_test_v_f, jk=True,labels=[0,1,2,3])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44576,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_y_test_v_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_linear\n",
      "all\n",
      "n_s\n",
      "[[45696   763     0     0]\n",
      " [  979  2241     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     46459\n",
      "           1       0.75      0.70      0.72      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     49679\n",
      "   macro avg       0.43      0.42      0.43     49679\n",
      "weighted avg       0.96      0.96      0.96     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45666   793     0     0]\n",
      " [ 1759  1461     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     46459\n",
      "           1       0.65      0.45      0.53      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.40      0.36      0.38     49679\n",
      "weighted avg       0.94      0.95      0.94     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45711   748     0     0]\n",
      " [  480  2740     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     46459\n",
      "           1       0.79      0.85      0.82      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     49679\n",
      "   macro avg       0.44      0.46      0.45     49679\n",
      "weighted avg       0.98      0.98      0.98     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45711   748     0     0]\n",
      " [  480  2740     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     46459\n",
      "           1       0.79      0.85      0.82      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     49679\n",
      "   macro avg       0.44      0.46      0.45     49679\n",
      "weighted avg       0.98      0.98      0.98     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46301   158     0     0]\n",
      " [ 1357  1863     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     46459\n",
      "           1       0.92      0.58      0.71      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.47      0.39      0.42     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45972   487     0     0]\n",
      " [  963  2257     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     46459\n",
      "           1       0.82      0.70      0.76      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.45      0.42      0.44     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "svm_poly\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45654   805     0     0]\n",
      " [ 1345  1875     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     46459\n",
      "           1       0.70      0.58      0.64      3220\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     49679\n",
      "   macro avg       0.84      0.78      0.81     49679\n",
      "weighted avg       0.95      0.96      0.95     49679\n",
      "\n",
      "n_v\n",
      "[[45967   492     0     0]\n",
      " [ 2570   650     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     46459\n",
      "           1       0.57      0.20      0.30      3220\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.76      0.60      0.63     49679\n",
      "weighted avg       0.92      0.94      0.92     49679\n",
      "\n",
      "n_f\n",
      "[[44355  2104     0     0]\n",
      " [  650  2570     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     46459\n",
      "           1       0.55      0.80      0.65      3220\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.77      0.88      0.81     49679\n",
      "weighted avg       0.96      0.94      0.95     49679\n",
      "\n",
      "s_v\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_balanced\n",
    "\n",
    "y_train = good_features_y\n",
    "\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.voting_ensemble(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.voting_ensemble(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.voting_ensemble(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.voting_ensemble(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.voting_ensemble(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.voting_ensemble(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[37876  6145     0     0]\n",
      " [  516  1534     0     0]\n",
      " [  192  3028     0     0]\n",
      " [  237   151     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.91     44021\n",
      "           1       0.14      0.75      0.24      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.28      0.40      0.29     49679\n",
      "weighted avg       0.87      0.79      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40357  3664     0     0]\n",
      " [  385  1665     0     0]\n",
      " [  394  2826     0     0]\n",
      " [  333    55     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     44021\n",
      "           1       0.20      0.81      0.32      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.29      0.43      0.32     49679\n",
      "weighted avg       0.87      0.85      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37304  6717     0     0]\n",
      " [ 1847   203     0     0]\n",
      " [  130  3090     0     0]\n",
      " [  240   148     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.02      0.10      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.84      0.75      0.79     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37304  6717     0     0]\n",
      " [ 1847   203     0     0]\n",
      " [  130  3090     0     0]\n",
      " [  240   148     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.02      0.10      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.84      0.75      0.79     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36383  7638     0     0]\n",
      " [ 1761   289     0     0]\n",
      " [  579  2641     0     0]\n",
      " [  220   168     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     44021\n",
      "           1       0.03      0.14      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.83      0.74      0.78     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40681  3340     0     0]\n",
      " [  412  1638     0     0]\n",
      " [  139  3081     0     0]\n",
      " [  262   126     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95     44021\n",
      "           1       0.20      0.80      0.32      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.30      0.43      0.32     49679\n",
      "weighted avg       0.88      0.85      0.86     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42481  1540     0     0]\n",
      " [ 1633   417     0     0]\n",
      " [ 1111  2109     0     0]\n",
      " [  252   136     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.10      0.20      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.26      0.29      0.27     49679\n",
      "weighted avg       0.83      0.86      0.85     49679\n",
      "\n",
      "n_v\n",
      "[[43470   551     0     0]\n",
      " [ 1556   494     0     0]\n",
      " [ 1428  1792     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.17      0.24      0.20      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.28      0.31      0.29     49679\n",
      "weighted avg       0.83      0.88      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42913  1108     0     0]\n",
      " [ 2009    41     0     0]\n",
      " [  394  2826     0     0]\n",
      " [  227   161     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.86      0.85     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42913  1108     0     0]\n",
      " [ 2009    41     0     0]\n",
      " [  394  2826     0     0]\n",
      " [  227   161     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.86      0.85     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43185   836     0     0]\n",
      " [ 2035    15     0     0]\n",
      " [  988  2232     0     0]\n",
      " [  296    92     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     44021\n",
      "           1       0.00      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.87      0.85     49679\n",
      "\n",
      "v_f\n",
      "[[43602   419     0     0]\n",
      " [ 1773   277     0     0]\n",
      " [  620  2600     0     0]\n",
      " [  341    47     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     44021\n",
      "           1       0.08      0.14      0.10      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.26      0.28      0.27     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38832  5189     0     0]\n",
      " [ 1359   691     0     0]\n",
      " [  459  2761     0     0]\n",
      " [  120   268     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92     44021\n",
      "           1       0.08      0.34      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.26      0.30      0.26     49679\n",
      "weighted avg       0.85      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41468  2553     0     0]\n",
      " [ 1296   754     0     0]\n",
      " [  366  2854     0     0]\n",
      " [  302    86     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     44021\n",
      "           1       0.12      0.37      0.18      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.27      0.33      0.28     49679\n",
      "weighted avg       0.85      0.85      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37826  6195     0     0]\n",
      " [ 1617   433     0     0]\n",
      " [  334  2886     0     0]\n",
      " [  292    96     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     44021\n",
      "           1       0.05      0.21      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.77      0.80     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37882  6139     0     0]\n",
      " [ 1576   474     0     0]\n",
      " [  341  2879     0     0]\n",
      " [  294    94     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     44021\n",
      "           1       0.05      0.23      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.25      0.27      0.25     49679\n",
      "weighted avg       0.84      0.77      0.80     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41044  2977     0     0]\n",
      " [ 1538   512     0     0]\n",
      " [  332  2888     0     0]\n",
      " [  302    86     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     44021\n",
      "           1       0.08      0.25      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.26      0.30      0.27     49679\n",
      "weighted avg       0.84      0.84      0.84     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39002  5019     0     0]\n",
      " [ 1256   794     0     0]\n",
      " [  153  3067     0     0]\n",
      " [   28   360     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     44021\n",
      "           1       0.09      0.39      0.14      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.26      0.32      0.27     49679\n",
      "weighted avg       0.86      0.80      0.82     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([1, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 0] = 1\n",
    "y_train[y_train == 0] = 0\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[40792  3229     0     0]\n",
      " [  276  1774     0     0]\n",
      " [  818  2402     0     0]\n",
      " [  375    13     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     44021\n",
      "           1       0.24      0.87      0.37      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.30      0.45      0.33     49679\n",
      "weighted avg       0.87      0.86      0.85     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39724  4297     0     0]\n",
      " [ 1127   923     0     0]\n",
      " [ 1185  2035     0     0]\n",
      " [  326    62     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     44021\n",
      "           1       0.13      0.45      0.20      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.27      0.34      0.28     49679\n",
      "weighted avg       0.84      0.82      0.82     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34837  9184     0     0]\n",
      " [ 1480   570     0     0]\n",
      " [ 2659   561     0     0]\n",
      " [  379     9     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84     44021\n",
      "           1       0.06      0.28      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     49679\n",
      "   macro avg       0.24      0.27      0.23     49679\n",
      "weighted avg       0.79      0.71      0.74     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34837  9184     0     0]\n",
      " [ 1480   570     0     0]\n",
      " [ 2659   561     0     0]\n",
      " [  379     9     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84     44021\n",
      "           1       0.06      0.28      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     49679\n",
      "   macro avg       0.24      0.27      0.23     49679\n",
      "weighted avg       0.79      0.71      0.74     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34773  9248     0     0]\n",
      " [  862  1188     0     0]\n",
      " [ 1772  1448     0     0]\n",
      " [  377    11     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     44021\n",
      "           1       0.10      0.58      0.17      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     49679\n",
      "   macro avg       0.26      0.34      0.26     49679\n",
      "weighted avg       0.82      0.72      0.76     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36434  7587     0     0]\n",
      " [  855  1195     0     0]\n",
      " [  850  2370     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88     44021\n",
      "           1       0.11      0.58      0.18      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.26      0.35      0.27     49679\n",
      "weighted avg       0.84      0.76      0.79     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43707   314     0     0]\n",
      " [ 1983    67     0     0]\n",
      " [ 3049   171     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.12      0.03      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.26      0.25     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_v\n",
      "[[43782   239     0     0]\n",
      " [ 1989    61     0     0]\n",
      " [ 3165    55     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.17      0.03      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.26      0.26      0.25     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43941    80     0     0]\n",
      " [ 2044     6     0     0]\n",
      " [ 2995   225     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43941    80     0     0]\n",
      " [ 2044     6     0     0]\n",
      " [ 2995   225     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43987    34     0     0]\n",
      " [ 2047     3     0     0]\n",
      " [ 3122    98     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "v_f\n",
      "[[43971    50     0     0]\n",
      " [ 2004    46     0     0]\n",
      " [ 2937   283     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.12      0.02      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.25      0.26      0.25     49679\n",
      "weighted avg       0.80      0.89      0.84     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43647   374     0     0]\n",
      " [ 1972    78     0     0]\n",
      " [ 3118   102     0     0]\n",
      " [  386     2     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.14      0.04      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.26      0.26      0.25     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43095   926     0     0]\n",
      " [ 1953    97     0     0]\n",
      " [ 2904   316     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     44021\n",
      "           1       0.07      0.05      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.79      0.87      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42566  1455     0     0]\n",
      " [ 1828   222     0     0]\n",
      " [ 3213     7     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     44021\n",
      "           1       0.13      0.11      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42568  1453     0     0]\n",
      " [ 1832   218     0     0]\n",
      " [ 3214     6     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     44021\n",
      "           1       0.13      0.11      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43213   808     0     0]\n",
      " [ 1847   203     0     0]\n",
      " [ 3197    23     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     44021\n",
      "           1       0.20      0.10      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.27      0.27      0.27     49679\n",
      "weighted avg       0.80      0.87      0.83     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43697   324     0     0]\n",
      " [ 1926   124     0     0]\n",
      " [ 3190    30     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.26      0.06      0.10      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.29      0.26      0.26     49679\n",
      "weighted avg       0.80      0.88      0.83     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 1] = 0\n",
    "y_train[y_train == 1] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[40111  3910     0     0]\n",
      " [ 1000  1050     0     0]\n",
      " [  301  2919     0     0]\n",
      " [  365    23     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94     44021\n",
      "           1       0.13      0.51      0.21      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.27      0.36      0.29     49679\n",
      "weighted avg       0.86      0.83      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41258  2763     0     0]\n",
      " [  461  1589     0     0]\n",
      " [  384  2836     0     0]\n",
      " [  345    43     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95     44021\n",
      "           1       0.22      0.78      0.34      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.30      0.43      0.32     49679\n",
      "weighted avg       0.87      0.86      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39160  4861     0     0]\n",
      " [ 1991    59     0     0]\n",
      " [  175  3045     0     0]\n",
      " [  244   144     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.23      0.23     49679\n",
      "weighted avg       0.84      0.79      0.81     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39160  4861     0     0]\n",
      " [ 1991    59     0     0]\n",
      " [  175  3045     0     0]\n",
      " [  244   144     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.23      0.23     49679\n",
      "weighted avg       0.84      0.79      0.81     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39564  4457     0     0]\n",
      " [ 2000    50     0     0]\n",
      " [  517  2703     0     0]\n",
      " [  324    64     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.23      0.23      0.23     49679\n",
      "weighted avg       0.83      0.80      0.81     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41654  2367     0     0]\n",
      " [  482  1568     0     0]\n",
      " [  352  2868     0     0]\n",
      " [  381     7     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     44021\n",
      "           1       0.23      0.76      0.35      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.30      0.43      0.33     49679\n",
      "weighted avg       0.87      0.87      0.86     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43001  1020     0     0]\n",
      " [ 1670   380     0     0]\n",
      " [ 1289  1931     0     0]\n",
      " [  284   104     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     44021\n",
      "           1       0.11      0.19      0.14      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.26      0.29      0.27     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "n_v\n",
      "[[43648   373     0     0]\n",
      " [ 1597   453     0     0]\n",
      " [ 1588  1632     0     0]\n",
      " [  381     7     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     44021\n",
      "           1       0.18      0.22      0.20      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.28      0.30      0.29     49679\n",
      "weighted avg       0.83      0.89      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43433   588     0     0]\n",
      " [ 2018    32     0     0]\n",
      " [  443  2777     0     0]\n",
      " [  288   100     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43433   588     0     0]\n",
      " [ 2018    32     0     0]\n",
      " [  443  2777     0     0]\n",
      " [  288   100     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43636   385     0     0]\n",
      " [ 2039    11     0     0]\n",
      " [ 1028  2192     0     0]\n",
      " [  321    67     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.00      0.01      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.88      0.85     49679\n",
      "\n",
      "v_f\n",
      "[[43759   262     0     0]\n",
      " [ 1806   244     0     0]\n",
      " [  773  2447     0     0]\n",
      " [  367    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.08      0.12      0.10      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.25      0.28      0.27     49679\n",
      "weighted avg       0.83      0.89      0.86     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39749  4272     0     0]\n",
      " [ 1490   560     0     0]\n",
      " [  499  2721     0     0]\n",
      " [  123   265     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93     44021\n",
      "           1       0.07      0.27      0.11      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.26      0.29      0.26     49679\n",
      "weighted avg       0.84      0.81      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43114   907     0     0]\n",
      " [ 1478   572     0     0]\n",
      " [  743  2477     0     0]\n",
      " [  362    26     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     44021\n",
      "           1       0.14      0.28      0.19      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.27      0.31      0.29     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40496  3525     0     0]\n",
      " [ 1806   244     0     0]\n",
      " [  448  2772     0     0]\n",
      " [  342    46     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.04      0.12      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.83      0.82      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40490  3531     0     0]\n",
      " [ 1797   253     0     0]\n",
      " [  433  2787     0     0]\n",
      " [  339    49     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.04      0.12      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.83      0.82      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42752  1269     0     0]\n",
      " [ 2018    32     0     0]\n",
      " [  445  2775     0     0]\n",
      " [  318    70     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.86      0.85     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43659   362     0     0]\n",
      " [ 1551   499     0     0]\n",
      " [  377  2843     0     0]\n",
      " [  367    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     44021\n",
      "           1       0.13      0.24      0.17      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.27      0.31      0.29     49679\n",
      "weighted avg       0.85      0.89      0.87     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_linear\n",
      "all\n",
      "n_s\n",
      "[[43637   384     0     0]\n",
      " [ 1679   371     0     0]\n",
      " [  979  2241     0     0]\n",
      " [  380     8     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.12      0.18      0.15      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.26      0.29      0.28     49679\n",
      "weighted avg       0.83      0.89      0.86     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43677   344     0     0]\n",
      " [ 1603   447     0     0]\n",
      " [ 1759  1461     0     0]\n",
      " [  386     2     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     44021\n",
      "           1       0.20      0.22      0.21      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.28      0.30      0.29     49679\n",
      "weighted avg       0.82      0.89      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43351   670     0     0]\n",
      " [ 2041     9     0     0]\n",
      " [  480  2740     0     0]\n",
      " [  319    69     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3e01c3dc274b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s_v\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s_f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36msvm_model_linear\u001b[1;34m(X_train, y_train, X_test, y_test, jk, C, kernel, degree, gamma, coef0, shrinking, probability, tol, cache_size, verbose, max_iter, decision_function_shape, random_state, labels)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[38039  5982     0     0]\n",
      " [ 1889   161     0     0]\n",
      " [ 2016  1204     0     0]\n",
      " [   52   336     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88     44021\n",
      "           1       0.02      0.08      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.80      0.77      0.79     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40448  3573     0     0]\n",
      " [ 1608   442     0     0]\n",
      " [ 2177  1043     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91     44021\n",
      "           1       0.09      0.22      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.81      0.82      0.81     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39696  4325     0     0]\n",
      " [ 1841   209     0     0]\n",
      " [ 2186  1034     0     0]\n",
      " [  150   238     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     44021\n",
      "           1       0.04      0.10      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.80      0.80      0.80     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39696  4325     0     0]\n",
      " [ 1841   209     0     0]\n",
      " [ 2186  1034     0     0]\n",
      " [  150   238     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     44021\n",
      "           1       0.04      0.10      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.80      0.80      0.80     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40039  3982     0     0]\n",
      " [ 1734   316     0     0]\n",
      " [ 2772   448     0     0]\n",
      " [  223   165     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     44021\n",
      "           1       0.06      0.15      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.27      0.25     49679\n",
      "weighted avg       0.80      0.81      0.80     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40647  3374     0     0]\n",
      " [ 1839   211     0     0]\n",
      " [ 2740   480     0     0]\n",
      " [   41   347     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     44021\n",
      "           1       0.05      0.10      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.80      0.82      0.81     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43980    41     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3109   111     0     0]\n",
      " [  335    53     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "n_v\n",
      "[[43989    32     0     0]\n",
      " [ 2032    18     0     0]\n",
      " [ 3190    30     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.23      0.01      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.28      0.25      0.24     49679\n",
      "weighted avg       0.80      0.89      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43383   638     0     0]\n",
      " [ 2021    29     0     0]\n",
      " [ 3041   179     0     0]\n",
      " [  281   107     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.03      0.01      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.87      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43383   638     0     0]\n",
      " [ 2021    29     0     0]\n",
      " [ 3041   179     0     0]\n",
      " [  281   107     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.03      0.01      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.87      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43991    30     0     0]\n",
      " [ 2049     1     0     0]\n",
      " [ 3040   180     0     0]\n",
      " [  140   248     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.84     49679\n",
      "\n",
      "v_f\n",
      "[[43814   207     0     0]\n",
      " [ 2048     2     0     0]\n",
      " [ 3037   183     0     0]\n",
      " [  102   286     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.22      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44018     3     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3220     0     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43949    72     0     0]\n",
      " [ 2048     2     0     0]\n",
      " [ 3215     5     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.03      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44013     8     0     0]\n",
      " [ 2039    11     0     0]\n",
      " [ 3220     0     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.58      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.37      0.25      0.24     49679\n",
      "weighted avg       0.81      0.89      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44009    12     0     0]\n",
      " [ 2036    14     0     0]\n",
      " [ 3220     0     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.54      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.36      0.25      0.24     49679\n",
      "weighted avg       0.81      0.89      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43907   114     0     0]\n",
      " [ 2045     5     0     0]\n",
      " [ 3216     4     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.04      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41119  2902     0     0]\n",
      " [ 2049     1     0     0]\n",
      " [ 3201    19     0     0]\n",
      " [  126   262     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.22      0.23      0.23     49679\n",
      "weighted avg       0.78      0.83      0.81     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_tr = StandardScaler()\n",
    "scale_te = StandardScaler()\n",
    "\n",
    "scale_tr.fit(X_train)\n",
    "scale_te.fit(X_test)\n",
    "X_train = scale_tr.transform(X_train)\n",
    "X_test = scale_te.transform(X_test)\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[36922  7099     0     0]\n",
      " [ 1878   172     0     0]\n",
      " [ 1905  1315     0     0]\n",
      " [   45   343     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87     44021\n",
      "           1       0.02      0.08      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.23      0.23      0.23     49679\n",
      "weighted avg       0.80      0.75      0.77     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39622  4399     0     0]\n",
      " [ 1522   528     0     0]\n",
      " [ 2164  1056     0     0]\n",
      " [  359    29     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     44021\n",
      "           1       0.09      0.26      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.25      0.29      0.26     49679\n",
      "weighted avg       0.81      0.81      0.81     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35681  8340     0     0]\n",
      " [ 1702   348     0     0]\n",
      " [ 1696  1524     0     0]\n",
      " [   22   366     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86     44021\n",
      "           1       0.03      0.17      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.24      0.25      0.23     49679\n",
      "weighted avg       0.81      0.73      0.76     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35681  8340     0     0]\n",
      " [ 1702   348     0     0]\n",
      " [ 1696  1524     0     0]\n",
      " [   22   366     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86     44021\n",
      "           1       0.03      0.17      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.24      0.25      0.23     49679\n",
      "weighted avg       0.81      0.73      0.76     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35696  8325     0     0]\n",
      " [ 1691   359     0     0]\n",
      " [ 2577   643     0     0]\n",
      " [   37   351     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85     44021\n",
      "           1       0.04      0.18      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.23      0.25      0.23     49679\n",
      "weighted avg       0.79      0.73      0.76     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36599  7422     0     0]\n",
      " [ 1609   441     0     0]\n",
      " [ 2625   595     0     0]\n",
      " [   31   357     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86     44021\n",
      "           1       0.05      0.22      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.80      0.75      0.77     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43918   103     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3037   183     0     0]\n",
      " [  290    98     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.22      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_v\n",
      "[[43918   103     0     0]\n",
      " [ 2019    31     0     0]\n",
      " [ 3006   214     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.09      0.02      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39912  4109     0     0]\n",
      " [ 2010    40     0     0]\n",
      " [ 2737   483     0     0]\n",
      " [   32   356     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.23      0.23      0.23     49679\n",
      "weighted avg       0.79      0.80      0.80     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39912  4109     0     0]\n",
      " [ 2010    40     0     0]\n",
      " [ 2737   483     0     0]\n",
      " [   32   356     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.23      0.23      0.23     49679\n",
      "weighted avg       0.79      0.80      0.80     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43463   558     0     0]\n",
      " [ 2042     8     0     0]\n",
      " [ 2977   243     0     0]\n",
      " [   48   340     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     44021\n",
      "           1       0.01      0.00      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "v_f\n",
      "[[43480   541     0     0]\n",
      " [ 2036    14     0     0]\n",
      " [ 2995   225     0     0]\n",
      " [   50   338     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44012     9     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3220     0     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43984    37     0     0]\n",
      " [ 2049     1     0     0]\n",
      " [ 3218     2     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43662   359     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3219     1     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.78      0.88      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43574   447     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3216     4     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.78      0.88      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43861   160     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3215     5     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.78      0.88      0.83     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41764  2257     0     0]\n",
      " [ 2049     1     0     0]\n",
      " [ 3140    80     0     0]\n",
      " [  183   205     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.22      0.24      0.23     49679\n",
      "weighted avg       0.79      0.84      0.81     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[39550  4471     0     0]\n",
      " [  424  1626     0     0]\n",
      " [  279  2941     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     44021\n",
      "           1       0.18      0.79      0.29      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.29      0.42      0.31     49679\n",
      "weighted avg       0.87      0.83      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40961  3060     0     0]\n",
      " [  415  1635     0     0]\n",
      " [  392  2828     0     0]\n",
      " [  366    22     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     44021\n",
      "           1       0.22      0.80      0.34      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.30      0.43      0.32     49679\n",
      "weighted avg       0.87      0.86      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39063  4958     0     0]\n",
      " [ 1903   147     0     0]\n",
      " [  119  3101     0     0]\n",
      " [  262   126     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     44021\n",
      "           1       0.02      0.07      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.24      0.24     49679\n",
      "weighted avg       0.84      0.79      0.81     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39063  4958     0     0]\n",
      " [ 1903   147     0     0]\n",
      " [  119  3101     0     0]\n",
      " [  262   126     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     44021\n",
      "           1       0.02      0.07      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.24      0.24     49679\n",
      "weighted avg       0.84      0.79      0.81     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37878  6143     0     0]\n",
      " [ 1838   212     0     0]\n",
      " [  591  2629     0     0]\n",
      " [  332    56     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89     44021\n",
      "           1       0.02      0.10      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.83      0.77      0.79     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40797  3224     0     0]\n",
      " [  436  1614     0     0]\n",
      " [  300  2920     0     0]\n",
      " [  380     8     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     44021\n",
      "           1       0.21      0.79      0.33      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.30      0.43      0.32     49679\n",
      "weighted avg       0.87      0.85      0.85     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42825  1196     0     0]\n",
      " [ 1615   435     0     0]\n",
      " [ 1076  2144     0     0]\n",
      " [  324    64     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.11      0.21      0.15      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.26      0.30      0.28     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "n_v\n",
      "[[43497   524     0     0]\n",
      " [ 1556   494     0     0]\n",
      " [ 1438  1782     0     0]\n",
      " [  384     4     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.18      0.24      0.20      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.28      0.31      0.29     49679\n",
      "weighted avg       0.83      0.89      0.86     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43535   486     0     0]\n",
      " [ 2016    34     0     0]\n",
      " [  370  2850     0     0]\n",
      " [  287   101     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43535   486     0     0]\n",
      " [ 2016    34     0     0]\n",
      " [  370  2850     0     0]\n",
      " [  287   101     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43605   416     0     0]\n",
      " [ 2037    13     0     0]\n",
      " [  995  2225     0     0]\n",
      " [  335    53     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.00      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.88      0.85     49679\n",
      "\n",
      "v_f\n",
      "[[43633   388     0     0]\n",
      " [ 1728   322     0     0]\n",
      " [  658  2562     0     0]\n",
      " [  376    12     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     44021\n",
      "           1       0.10      0.16      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.26      0.29      0.27     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38952  5069     0     0]\n",
      " [ 1377   673     0     0]\n",
      " [  471  2749     0     0]\n",
      " [  112   276     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92     44021\n",
      "           1       0.08      0.33      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.26      0.30      0.26     49679\n",
      "weighted avg       0.85      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41811  2210     0     0]\n",
      " [ 1325   725     0     0]\n",
      " [  427  2793     0     0]\n",
      " [  352    36     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     44021\n",
      "           1       0.13      0.35      0.19      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.27      0.33      0.28     49679\n",
      "weighted avg       0.85      0.86      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40010  4011     0     0]\n",
      " [ 1767   283     0     0]\n",
      " [  419  2801     0     0]\n",
      " [  335    53     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     44021\n",
      "           1       0.04      0.14      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.25      0.26      0.25     49679\n",
      "weighted avg       0.84      0.81      0.82     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40092  3929     0     0]\n",
      " [ 1789   261     0     0]\n",
      " [  416  2804     0     0]\n",
      " [  340    48     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     44021\n",
      "           1       0.04      0.13      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.83      0.81      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41832  2189     0     0]\n",
      " [ 1580   470     0     0]\n",
      " [  404  2816     0     0]\n",
      " [  343    45     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     44021\n",
      "           1       0.09      0.23      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.26      0.29      0.27     49679\n",
      "weighted avg       0.84      0.85      0.85     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43115   906     0     0]\n",
      " [ 1160   890     0     0]\n",
      " [  249  2971     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     44021\n",
      "           1       0.19      0.43      0.26      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.29      0.35      0.31     49679\n",
      "weighted avg       0.86      0.89      0.87     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "#y_train_b = np.copy(y_train)\n",
    "y_train[y_train == 2] = -2\n",
    "\n",
    "y_train[y_train == 1] = -1\n",
    "y_train[y_train >= 0] = 0\n",
    "\n",
    "y_train[y_train < 0] = 1\n",
    "#y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "#y_train[y_train == -2] = 2\n",
    "\n",
    "#y_train[y_train == -1] = 1\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
