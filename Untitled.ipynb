{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn import svm, metrics\n",
    "\n",
    "\n",
    "\n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "rank = pd.read_csv(\"database/features_ranking.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "\n",
    "rank_n_f = pd.read_csv(\"database/features_n_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_n_s = pd.read_csv(\"database/features_n_vs_s_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_n_v = pd.read_csv(\"database/features_n_vs_v_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_s_f = pd.read_csv(\"database/features_s_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_s_v = pd.read_csv(\"database/features_s_vs_v_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_v_f = pd.read_csv(\"database/features_v_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_lin.text', 'rb')\n",
    "n_s_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_lin.text', 'rb')\n",
    "n_v_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_lin.text', 'rb')\n",
    "n_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_lin.text', 'rb')\n",
    "s_v_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_lin.text', 'rb')\n",
    "s_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_lin.text', 'rb')\n",
    "v_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_log.text', 'rb')\n",
    "n_s_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_log.text', 'rb')\n",
    "n_v_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_log.text', 'rb')\n",
    "n_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_log.text', 'rb')\n",
    "s_v_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_log.text', 'rb')\n",
    "s_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_log.text', 'rb')\n",
    "v_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "score = 0.01\n",
    "score_n_s = 0.01\n",
    "score_n_f = 0.015\n",
    "score_n_v = 0.01\n",
    "score_s_f = 0.01\n",
    "score_s_v = 0.015\n",
    "score_v_f = 0.01\n",
    "feature_good = rank[rank['rfscore'] >= score]['features'].values\n",
    "n_s = rank_n_s[rank_n_s['rfscore'] >= score_n_s]['features'].values\n",
    "n_f = rank_n_f[rank_n_f['rfscore'] >= score_n_f]['features'].values\n",
    "n_v = rank_n_v[rank_n_v['rfscore'] >= score_n_v]['features'].values\n",
    "s_f = rank_s_f[rank_s_f['rfscore'] >= score_s_f]['features'].values\n",
    "s_v = rank_s_v[rank_s_v['rfscore'] >= score_s_v]['features'].values\n",
    "v_f = rank_v_f[rank_v_f['rfscore'] >= score_v_f]['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_f\n",
      "[[43069   952     0     0]\n",
      " [ 1777   273     0     0]\n",
      " [  382  2838     0     0]\n",
      " [  355    33     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     44021\n",
      "           1       0.07      0.13      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.84      0.87      0.86     49679\n",
      "\n",
      "all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42600  1421     0     0]\n",
      " [ 1786   264     0     0]\n",
      " [  338  2882     0     0]\n",
      " [  357    31     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96     44021\n",
      "           1       0.06      0.13      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.84      0.86      0.85     49679\n",
      "\n",
      "n_s\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42369  1652     0     0]\n",
      " [ 1523   527     0     0]\n",
      " [  223  2997     0     0]\n",
      " [  370    18     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     44021\n",
      "           1       0.10      0.26      0.15      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.26      0.30      0.28     49679\n",
      "weighted avg       0.85      0.86      0.85     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41556  2465     0     0]\n",
      " [ 1801   249     0     0]\n",
      " [  254  2966     0     0]\n",
      " [  336    52     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     44021\n",
      "           1       0.04      0.12      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.25      0.27      0.25     49679\n",
      "weighted avg       0.84      0.84      0.84     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43433   588     0     0]\n",
      " [ 2018    32     0     0]\n",
      " [  443  2777     0     0]\n",
      " [  288   100     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39896  4125     0     0]\n",
      " [ 1491   559     0     0]\n",
      " [  502  2718     0     0]\n",
      " [  123   265     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     44021\n",
      "           1       0.07      0.27      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.26      0.29      0.26     49679\n",
      "weighted avg       0.84      0.81      0.83     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42264  1757     0     0]\n",
      " [ 2027    23     0     0]\n",
      " [ 2462   758     0     0]\n",
      " [  142   246     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.80      0.85      0.82     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37601  6420     0     0]\n",
      " [ 1788   262     0     0]\n",
      " [  352  2868     0     0]\n",
      " [  325    63     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.03      0.13      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.24      0.25      0.23     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43633   388     0     0]\n",
      " [ 1562   488     0     0]\n",
      " [  385  2835     0     0]\n",
      " [  366    22     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     44021\n",
      "           1       0.13      0.24      0.17      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.27      0.31      0.28     49679\n",
      "weighted avg       0.85      0.89      0.87     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43433   588     0     0]\n",
      " [ 2018    32     0     0]\n",
      " [  443  2777     0     0]\n",
      " [  288   100     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39160  4861     0     0]\n",
      " [ 1991    59     0     0]\n",
      " [  175  3045     0     0]\n",
      " [  244   144     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.23      0.23     49679\n",
      "weighted avg       0.84      0.79      0.81     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_train_b = np.copy(y_train)\n",
    "\n",
    "y_train_b[y_train_b != 2] = 0\n",
    "y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "print(\"v_f\")\n",
    "y=classifier.randomForest(X_train[v_f], y_train_b, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "print(\"all\")\n",
    "y1=classifier.randomForest(X_train[feature_good], y_train_b, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"n_s\")\n",
    "\n",
    "print(\"v_f\")\n",
    "y2=classifier.logisticRegress(X_train[v_f], y_train_b, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "print(\"s_f\")\n",
    "y3=classifier.logisticRegress(X_train[s_f], y_train_b, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "y4=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y5=classifier.randomForest(X_train[n_s_log], y_train_b, X_test[n_s_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y6=classifier.logisticRegress(X_train[n_v_ln], y_train_b, X_test[n_s_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y7=classifier.logisticRegress(X_train[n_v_ln], y_train_b, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "yv=classifier.randomForest(X_train[v_f_log], y_train_b, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "yv1=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "yv2=classifier.logisticRegress(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43689   332     0     0]\n",
      " [ 1823   227     0     0]\n",
      " [  166  3054     0     0]\n",
      " [  341    47     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     44021\n",
      "           1       0.06      0.11      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "inds1 = []\n",
    "for i in range(len(y)):\n",
    "    #avg.append(np.mean([y[i], y1[i], y2[i], y3[i], y4[i], y4[i],y5[i], y6[i], y7[i], y8[i]]))\n",
    "    #avg.append(round(np.mean([y[i],y3[i], y4[i],  y5[i],  y6[i]]),0))\n",
    "    #print(np.mean(  [y5[i],  y6[i]]))\n",
    "   # indes.append(voting( [y5[i],y4[i],  y6[i]])\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i], y7[i]], focus = 2, amount=2))\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i]], focus = 2, amount=2))\n",
    "    #if(2 in [y[i],y6[i],  y7[i]]):\n",
    "    inds1.append(classifier.voting( [y4[i],y2[i],  y3[i]], focus = 1, amount=2, random = False))\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,inds1 , labels=[0,1,2,3]))\n",
    "print(classification_report(y_test,inds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_v\n",
      "[[37601  6420     0     0]\n",
      " [ 1788   262     0     0]\n",
      " [  352  2868     0     0]\n",
      " [  325    63     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.03      0.13      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.24      0.25      0.23     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"n_v\")\n",
    "y6=classifier.logisticRegress(X_train[n_v_ln], y_train_b, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 252    0   80    0]\n",
      " [  31    0  196    0]\n",
      " [ 219    0 2835    0]\n",
      " [  14    0   33    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.76      0.59       332\n",
      "           1       0.00      0.00      0.00       227\n",
      "           2       0.90      0.93      0.91      3054\n",
      "           3       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      3660\n",
      "   macro avg       0.35      0.42      0.38      3660\n",
      "weighted avg       0.80      0.84      0.82      3660\n",
      "\n",
      "[[ 279    0   53    0]\n",
      " [ 220    0    7    0]\n",
      " [ 293    0 2761    0]\n",
      " [  11    0   36    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.84      0.49       332\n",
      "           1       0.00      0.00      0.00       227\n",
      "           2       0.97      0.90      0.93      3054\n",
      "           3       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      3660\n",
      "   macro avg       0.33      0.44      0.36      3660\n",
      "weighted avg       0.84      0.83      0.82      3660\n",
      "\n",
      "[[ 241    0   91    0]\n",
      " [ 212    0   15    0]\n",
      " [ 113    0 2941    0]\n",
      " [   8    0   39    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.73      0.53       332\n",
      "           1       0.00      0.00      0.00       227\n",
      "           2       0.95      0.96      0.96      3054\n",
      "           3       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3660\n",
      "   macro avg       0.34      0.42      0.37      3660\n",
      "weighted avg       0.83      0.87      0.85      3660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "inds1 = np.asarray(inds1)\n",
    "\n",
    "y_test_2 = y_test[inds1==1] \n",
    "\n",
    "X_test_2 = X_test[inds1==1] \n",
    "\n",
    "X_train_0 = X_train[y_train==0]\n",
    "X_train_2 = X_train[y_train==2]\n",
    "X_train_bi = np.vstack((X_train_0,X_train_2))\n",
    "y_train_0 = y_train[y_train==0]\n",
    "y_train_2 = y_train[y_train==2]\n",
    "y_train_bi = np.hstack((y_train_0,y_train_2))\n",
    "\n",
    "\n",
    "X_train_bi = pd.DataFrame(X_train_bi,columns=features_clinic)\n",
    "\n",
    "yv=classifier.randomForest(X_train_bi[v_f_log], y_train_bi, X_test_2[v_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "yv1=classifier.Linear_D(X_train_bi[n_f_log], y_train_bi, X_test_2[n_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "yv2=classifier.logisticRegress(X_train_bi[n_f_log], y_train_bi, X_test_2[n_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 239   93    0    0]\n",
      " [ 213   14    0    0]\n",
      " [ 114 2940    0    0]\n",
      " [   8   39    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.72      0.53       332\n",
      "           1       0.00      0.06      0.01       227\n",
      "           2       0.00      0.00      0.00      3054\n",
      "           3       0.00      0.00      0.00        47\n",
      "\n",
      "   micro avg       0.07      0.07      0.07      3660\n",
      "   macro avg       0.11      0.20      0.13      3660\n",
      "weighted avg       0.04      0.07      0.05      3660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#yg=classifier.randomForest(X_train[v_f_log], y_train_b, X_test_2[v_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "#yg1=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test_2[n_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "yg2=classifier.logisticRegress(X_train[n_f_log], y_train_b, X_test_2[n_f_log], y_test_2, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "yg0 = y_test_2[yg2==0]\n",
    "\n",
    "xg0 = X_test_2[yg2==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41002  2926     0     0]\n",
      " [ 2010    26     0     0]\n",
      " [  247    33     0     0]\n",
      " [   29   320     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     46593\n",
      "   macro avg       0.24      0.24      0.24     46593\n",
      "weighted avg       0.89      0.88      0.89     46593\n",
      "\n",
      "[[36248  7680     0     0]\n",
      " [ 1910   126     0     0]\n",
      " [  109   171     0     0]\n",
      " [   16   333     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88     43928\n",
      "           1       0.02      0.06      0.02      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     46593\n",
      "   macro avg       0.24      0.22      0.23     46593\n",
      "weighted avg       0.89      0.78      0.83     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43447   481     0     0]\n",
      " [ 2025    11     0     0]\n",
      " [  219    61     0     0]\n",
      " [   61   288     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     46593\n",
      "   macro avg       0.24      0.25      0.24     46593\n",
      "weighted avg       0.90      0.93      0.91     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32867 11061     0     0]\n",
      " [ 1594   442     0     0]\n",
      " [  224    56     0     0]\n",
      " [   19   330     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84     43928\n",
      "           1       0.04      0.22      0.06      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     46593\n",
      "   macro avg       0.25      0.24      0.22     46593\n",
      "weighted avg       0.89      0.71      0.79     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40796  3132     0     0]\n",
      " [ 2016    20     0     0]\n",
      " [  252    28     0     0]\n",
      " [   24   325     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     46593\n",
      "   macro avg       0.24      0.23      0.24     46593\n",
      "weighted avg       0.89      0.88      0.88     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41915  2013     0     0]\n",
      " [ 2032     4     0     0]\n",
      " [  247    33     0     0]\n",
      " [   24   325     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     43928\n",
      "           1       0.00      0.00      0.00      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     46593\n",
      "   macro avg       0.24      0.24      0.24     46593\n",
      "weighted avg       0.89      0.90      0.90     46593\n",
      "\n",
      "[[43447   481     0     0]\n",
      " [ 2025    11     0     0]\n",
      " [  219    61     0     0]\n",
      " [   61   288     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     46593\n",
      "   macro avg       0.24      0.25      0.24     46593\n",
      "weighted avg       0.90      0.93      0.91     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "inds1 = np.asarray(inds1)\n",
    "\n",
    "\n",
    "\n",
    "y_test_0 = y_test[inds1==0] \n",
    "\n",
    "X_test_0 = X_test[inds1==0] \n",
    "\n",
    "\n",
    "X_test_0 = np.vstack((X_test_0,xg0))\n",
    "#y_train_0 = y_train[y_train==0]\n",
    "#y_train_1 = y_train[y_train==1]\n",
    "y_test_0 = np.hstack((y_test_0,yg0))\n",
    "\n",
    "\n",
    "X_test_0 = pd.DataFrame(X_test_0,columns=features_clinic)\n",
    "\n",
    "X_train_2 = X_train[y_train!=2]\n",
    "\n",
    "X_train_2 = pd.DataFrame(X_train_2,columns=features_clinic)\n",
    "\n",
    "#X_train_2 = X_train[y_train!=2]\n",
    "\n",
    "y_train_2 = np.asarray(y_train[y_train!=2], dtype=int)\n",
    "#y_train_2 = np.copy(y_train)\n",
    "\n",
    "y_train_2[y_train_2 != 3] = 0\n",
    "y_train_2[y_train_2 == 3] = 1\n",
    "\n",
    "\n",
    "#y_test_0[y_test_0 != 3] = 0\n",
    "#y_test_0[y_test_0 == 3] = 1\n",
    "\n",
    "f2 = classifier.Linear_D(X_train_2[n_s], y_train_2,X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f3 = classifier.logisticRegress(X_train_2[n_s], y_train_2, X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f4 = classifier.Linear_D(X_train_2[v_f_log], y_train_2, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f5 = classifier.logisticRegress(X_train_2[n_f_ln], y_train_2, X_test_0[n_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f6= classifier.Linear_D(X_train_2[v_f_ln], y_train_2, X_test_0[v_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f7=classifier.Linear_D(X_train_2[s_f_log], y_train_2, X_test_0[s_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f8=classifier.Linear_D(X_train_2[v_f_log], y_train_2, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "#ysfinal =classifier.logisticRegress(X_train_2[n_s_log], y_train_2, X_test_0[n_s_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39031  4897     0     0]\n",
      " [ 2006    30     0     0]\n",
      " [  254    26     0     0]\n",
      " [   23   326     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     46593\n",
      "   macro avg       0.24      0.23      0.23     46593\n",
      "weighted avg       0.89      0.84      0.86     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43604   324     0     0]\n",
      " [ 2034     2     0     0]\n",
      " [  258    22     0     0]\n",
      " [  161   188     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     43928\n",
      "           1       0.00      0.00      0.00      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     46593\n",
      "   macro avg       0.24      0.25      0.24     46593\n",
      "weighted avg       0.89      0.94      0.91     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43604   324     0     0]\n",
      " [ 2034     2     0     0]\n",
      " [  258    22     0     0]\n",
      " [  161   188     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     43928\n",
      "           1       0.00      0.00      0.00      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     46593\n",
      "   macro avg       0.24      0.25      0.24     46593\n",
      "weighted avg       0.89      0.94      0.91     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38526  5402     0     0]\n",
      " [ 2004    32     0     0]\n",
      " [  256    24     0     0]\n",
      " [   25   324     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91     43928\n",
      "           1       0.01      0.02      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     46593\n",
      "   macro avg       0.24      0.22      0.23     46593\n",
      "weighted avg       0.89      0.83      0.86     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38985  4943     0     0]\n",
      " [ 2007    29     0     0]\n",
      " [  254    26     0     0]\n",
      " [   22   327     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     43928\n",
      "           1       0.01      0.01      0.01      2036\n",
      "           2       0.00      0.00      0.00       280\n",
      "           3       0.00      0.00      0.00       349\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     46593\n",
      "   macro avg       0.24      0.23      0.23     46593\n",
      "weighted avg       0.89      0.84      0.86     46593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'R_duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-df0203c3cd16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mf13\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_ln\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_ln\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mf14\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_ln\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_ln\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mf15\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mf16\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_model_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36msvm_model_linear\u001b[1;34m(X_train, y_train, X_test, y_test, jk, C, kernel, degree, gamma, coef0, shrinking, probability, tol, cache_size, verbose, max_iter, decision_function_shape, random_state, labels)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model_linear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    148\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'R_duration'"
     ]
    }
   ],
   "source": [
    "f9=classifier.svm_model_linear(X_train_2[v_f_log], y_train_2, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n",
    "f10 = classifier.svm_model_linear(X_train_2[n_s], y_train_2,X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f11 = classifier.svm_model_linear(X_train_2[n_s], y_train_2, X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "#f12= classifier.svm_model_linear(X_train_2[v_f_log], y_train_2, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f13 = classifier.svm_model_linear(X_train_2[n_f_ln], y_train_2, X_test_0[n_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f14= classifier.svm_model_linear(X_train_2[v_f_ln], y_train_2, X_test_0[v_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f15=classifier.svm_model_linear([s_f_log], y_train_2, X_test_0[s_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f16=classifier.svm_model_linear(X_train_2[v_f_log], y_train_2, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45847   397     0     0]\n",
      " [   39   310     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     46244\n",
      "           1       0.44      0.89      0.59       349\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     46593\n",
      "   macro avg       0.72      0.94      0.79     46593\n",
      "weighted avg       0.99      0.99      0.99     46593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inds2 = []\n",
    "for i in range(len(f4)):\n",
    "    #avg.append(np.mean([y[i], y1[i], y2[i], y3[i], y4[i], y4[i],y5[i], y6[i], y7[i], y8[i]]))\n",
    "    #avg.append(round(np.mean([y[i],y3[i], y4[i],  y5[i],  y6[i]]),0))\n",
    "    #print(np.mean(  [y5[i],  y6[i]]))\n",
    "   # indes.append(voting( [y5[i],y4[i],  y6[i]])\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i], y7[i]], focus = 2, amount=2))\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i]], focus = 2, amount=2))\n",
    "    #if(2 in [y[i],y6[i],  y7[i]]):\n",
    "    inds2.append(classifier.voting( [f8[i],f7[i],  f2[i]], focus = 1, amount=2, random = False))\n",
    "\n",
    "    #inds2.append(classifier.voting( [f4[i],f2[i]], focus = 1, amount=1, random = False))\n",
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_0,inds2 , labels=[0,1,2,3]))\n",
    "print(classification_report(y_test_0,inds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40120  3327     0     0]\n",
      " [  275  1750     0     0]\n",
      " [   42   177     0     0]\n",
      " [   57     4     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96     43447\n",
      "           1       0.33      0.86      0.48      2025\n",
      "           2       0.00      0.00      0.00       219\n",
      "           3       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     45752\n",
      "   macro avg       0.33      0.45      0.36     45752\n",
      "weighted avg       0.96      0.92      0.93     45752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38883  4564     0     0]\n",
      " [  284  1741     0     0]\n",
      " [   68   151     0     0]\n",
      " [   58     3     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     43447\n",
      "           1       0.27      0.86      0.41      2025\n",
      "           2       0.00      0.00      0.00       219\n",
      "           3       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     45752\n",
      "   macro avg       0.31      0.44      0.34     45752\n",
      "weighted avg       0.95      0.89      0.91     45752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36140  7307     0     0]\n",
      " [ 1541   484     0     0]\n",
      " [   85   134     0     0]\n",
      " [   40    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89     43447\n",
      "           1       0.06      0.24      0.10      2025\n",
      "           2       0.00      0.00      0.00       219\n",
      "           3       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     45752\n",
      "   macro avg       0.25      0.27      0.25     45752\n",
      "weighted avg       0.91      0.80      0.85     45752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39950  3497     0     0]\n",
      " [  241  1784     0     0]\n",
      " [   46   173     0     0]\n",
      " [   59     2     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     43447\n",
      "           1       0.33      0.88      0.48      2025\n",
      "           2       0.00      0.00      0.00       219\n",
      "           3       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     45752\n",
      "   macro avg       0.33      0.45      0.36     45752\n",
      "weighted avg       0.96      0.91      0.93     45752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "f4 = np.asarray(f4)\n",
    "\n",
    "\n",
    "\n",
    "y_test_1 = y_test_0[f4==0] \n",
    "\n",
    "X_test_1 = X_test_0[f4==0] \n",
    "\n",
    "\n",
    "y_train_0 = y_train[y_train==0]\n",
    "y_train_1 = y_train[y_train==1]\n",
    "y_train_2 = np.hstack((y_train_0,y_train_1))\n",
    "\n",
    "X_train_0 = X_train[y_train==0]\n",
    "X_train_1 = X_train[y_train==1]\n",
    "X_train_2 = np.vstack((X_train_0,X_train_1))\n",
    "\n",
    "\n",
    "X_train_2 = pd.DataFrame(X_train_2,columns=features_clinic)\n",
    "\n",
    "\n",
    "X_test_0 = pd.DataFrame(X_test_0,columns=features_clinic)\n",
    "\n",
    "\n",
    "\n",
    "y_train_2[y_train_2 != 1] = 0\n",
    "y_train_2[y_train_2 == 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "ys = classifier.logisticRegress(X_train_2[n_s], y_train_2, X_test_1[n_s], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "ys = classifier.logisticRegress(X_train_2[n_s_ln], y_train_2, X_test_1[n_s_ln], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "classifier.logisticRegress(X_train_2[s_f_ln], y_train_2, X_test_1[s_f_ln], y_test_1, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "ysfinal =classifier.logisticRegress(X_train_2[n_s_log], y_train_2, X_test_1[n_s_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([45809,   976], dtype=int64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_2,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([45809,   976,  3788,   414], dtype=int64))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ys = classifier.logisticRegress(X_train[n_s], y_train, X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "ys = classifier.logisticRegress(X_train[n_s_ln], y_train, X_test_0[n_s_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 = y_test_0[ysfinal==0]\n",
    "X_test_0 = X_test_0[ysfinal==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38091     0  1081   750]\n",
      " [  239     0     2     0]\n",
      " [   69     0    16    11]\n",
      " [   32     0    22   230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.01      0.17      0.03        96\n",
      "           3       0.23      0.81      0.36       284\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     40543\n",
      "   macro avg       0.31      0.48      0.34     40543\n",
      "weighted avg       0.98      0.95      0.96     40543\n",
      "\n",
      "[[38933    11   629   349]\n",
      " [  237     0     3     1]\n",
      " [   61     1    17    17]\n",
      " [  122     0     1   161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.03      0.18      0.05        96\n",
      "           3       0.30      0.57      0.40       284\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     40543\n",
      "   macro avg       0.33      0.43      0.36     40543\n",
      "weighted avg       0.98      0.96      0.97     40543\n",
      "\n",
      "[[39363     1   123   435]\n",
      " [  240     0     0     1]\n",
      " [   80     0     2    14]\n",
      " [   34     0     0   250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.02      0.02      0.02        96\n",
      "           3       0.36      0.88      0.51       284\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     40543\n",
      "   macro avg       0.34      0.47      0.38     40543\n",
      "weighted avg       0.98      0.98      0.98     40543\n",
      "\n",
      "[[34362   213  2204  3143]\n",
      " [  103    11   115    12]\n",
      " [   65     3    11    17]\n",
      " [   19     0     0   265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92     39922\n",
      "           1       0.05      0.05      0.05       241\n",
      "           2       0.00      0.11      0.01        96\n",
      "           3       0.08      0.93      0.14       284\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     40543\n",
      "   macro avg       0.28      0.49      0.28     40543\n",
      "weighted avg       0.98      0.85      0.91     40543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37433     0   560  1929]\n",
      " [  237     0     4     0]\n",
      " [   44     0    47     5]\n",
      " [   22     0     0   262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.08      0.49      0.13        96\n",
      "           3       0.12      0.92      0.21       284\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     40543\n",
      "   macro avg       0.30      0.59      0.33     40543\n",
      "weighted avg       0.98      0.93      0.95     40543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39047     7   329   539]\n",
      " [  240     0     0     1]\n",
      " [   74     1     9    12]\n",
      " [   27     0     2   255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.03      0.09      0.04        96\n",
      "           3       0.32      0.90      0.47       284\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     40543\n",
      "   macro avg       0.33      0.49      0.37     40543\n",
      "weighted avg       0.98      0.97      0.97     40543\n",
      "\n",
      "[[39363     1   123   435]\n",
      " [  240     0     0     1]\n",
      " [   80     0     2    14]\n",
      " [   34     0     0   250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     39922\n",
      "           1       0.00      0.00      0.00       241\n",
      "           2       0.02      0.02      0.02        96\n",
      "           3       0.36      0.88      0.51       284\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     40543\n",
      "   macro avg       0.34      0.47      0.38     40543\n",
      "weighted avg       0.98      0.98      0.98     40543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f2 = classifier.Linear_D(X_train[n_s], y_train,X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f3 = classifier.logisticRegress(X_train[n_s], y_train, X_test_0[n_s], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f4 = classifier.Linear_D(X_train[v_f_log], y_train, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f5 = classifier.logisticRegress(X_train[n_f_ln], y_train, X_test_0[n_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f6= classifier.Linear_D(X_train[v_f_ln], y_train, X_test_0[v_f_ln], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f7=classifier.Linear_D(X_train[s_f_log], y_train, X_test_0[s_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n",
    "f8=classifier.Linear_D(X_train[v_f_log], y_train, X_test_0[v_f_log], y_test_0, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40429   294     0     0]\n",
      " [  266    10     0     0]\n",
      " [   84    22     0     0]\n",
      " [   62   276     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     40723\n",
      "           1       0.02      0.04      0.02       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     41443\n",
      "   macro avg       0.25      0.26      0.25     41443\n",
      "weighted avg       0.97      0.98      0.97     41443\n",
      "\n",
      "[[35496  5227     0     0]\n",
      " [  256    20     0     0]\n",
      " [   55    51     0     0]\n",
      " [   15   323     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93     40723\n",
      "           1       0.00      0.07      0.01       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     41443\n",
      "   macro avg       0.25      0.24      0.23     41443\n",
      "weighted avg       0.97      0.86      0.91     41443\n",
      "\n",
      "[[40218   505     0     0]\n",
      " [  266    10     0     0]\n",
      " [   82    24     0     0]\n",
      " [   38   300     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     40723\n",
      "           1       0.01      0.04      0.02       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.25      0.26      0.25     41443\n",
      "weighted avg       0.97      0.97      0.97     41443\n",
      "\n",
      "[[32725  7998     0     0]\n",
      " [  109   167     0     0]\n",
      " [   67    39     0     0]\n",
      " [   15   323     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89     40723\n",
      "           1       0.02      0.61      0.04       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     41443\n",
      "   macro avg       0.25      0.35      0.23     41443\n",
      "weighted avg       0.98      0.79      0.87     41443\n",
      "\n",
      "[[38483  2240     0     0]\n",
      " [  275     1     0     0]\n",
      " [   90    16     0     0]\n",
      " [   25   313     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     41443\n",
      "   macro avg       0.25      0.24      0.24     41443\n",
      "weighted avg       0.97      0.93      0.95     41443\n",
      "\n",
      "[[40191   532     0     0]\n",
      " [  271     5     0     0]\n",
      " [   82    24     0     0]\n",
      " [   35   303     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     40723\n",
      "           1       0.01      0.02      0.01       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.25      0.25      0.25     41443\n",
      "weighted avg       0.97      0.97      0.97     41443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40218   505     0     0]\n",
      " [  266    10     0     0]\n",
      " [   82    24     0     0]\n",
      " [   38   300     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     40723\n",
      "           1       0.01      0.04      0.02       276\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.00      0.00      0.00       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.25      0.26      0.25     41443\n",
      "weighted avg       0.97      0.97      0.97     41443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "y_test_1 = y_test_0[ysfinal==0]\n",
    "X_test_1 = X_test_0[ysfinal==0]\n",
    "\n",
    "\n",
    "X_train_0 = X_train[y_train==0]\n",
    "X_train_1 = X_train[y_train==1]\n",
    "X_train_bi = np.vstack((X_train_0,X_train_1))\n",
    "y_train_0 = y_train[y_train==0]\n",
    "y_train_1 = y_train[y_train==1]\n",
    "y_train_bi = np.hstack((y_train_0,y_train_1))\n",
    "\n",
    "\n",
    "X_train_bi = pd.DataFrame(X_train_bi,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train_bi = np.copy(y_train)\n",
    "\n",
    "y_train_bi[y_train_bi != 1] = 0\n",
    "y_train_bi[y_train_bi == 1] = 1\n",
    "\n",
    "f2 = classifier.Linear_D(X_train[n_s], y_train_bi,X_test_1[n_s], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f3 = classifier.logisticRegress(X_train[n_s], y_train_bi, X_test_1[n_s], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f4 = classifier.Linear_D(X_train[v_f_log], y_train_bi, X_test_1[v_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f5 = classifier.logisticRegress(X_train[n_f_ln], y_train_bi, X_test_1[n_f_ln], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f6= classifier.Linear_D(X_train[v_f_ln], y_train_bi, X_test_1[v_f_ln], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f7=classifier.Linear_D(X_train[s_f_log], y_train_bi, X_test_1[s_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f8=classifier.Linear_D(X_train[v_f_log], y_train_bi, X_test_1[v_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38639     0  1289   795]\n",
      " [  260     0    16     0]\n",
      " [   63     0    23    20]\n",
      " [   33     0    32   273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.02      0.22      0.03       106\n",
      "           3       0.25      0.81      0.38       338\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     41443\n",
      "   macro avg       0.31      0.49      0.35     41443\n",
      "weighted avg       0.98      0.94      0.96     41443\n",
      "\n",
      "[[39674     8   661   380]\n",
      " [  255     3    17     1]\n",
      " [   57     5    22    22]\n",
      " [  122     0     7   209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     40723\n",
      "           1       0.19      0.01      0.02       276\n",
      "           2       0.03      0.21      0.05       106\n",
      "           3       0.34      0.62      0.44       338\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     41443\n",
      "   macro avg       0.39      0.45      0.37     41443\n",
      "weighted avg       0.98      0.96      0.97     41443\n",
      "\n",
      "[[40091     1   142   489]\n",
      " [  261     0     5    10]\n",
      " [   70     1    11    24]\n",
      " [   37     0     0   301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.07      0.10      0.08       106\n",
      "           3       0.37      0.89      0.52       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.36      0.49      0.40     41443\n",
      "weighted avg       0.98      0.97      0.97     41443\n",
      "\n",
      "[[34742   210  2231  3540]\n",
      " [  114    11   124    27]\n",
      " [   66     3    10    27]\n",
      " [   21     0     0   317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92     40723\n",
      "           1       0.05      0.04      0.04       276\n",
      "           2       0.00      0.09      0.01       106\n",
      "           3       0.08      0.94      0.15       338\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     41443\n",
      "   macro avg       0.28      0.48      0.28     41443\n",
      "weighted avg       0.98      0.85      0.90     41443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38013     0   603  2107]\n",
      " [  270     0     4     2]\n",
      " [   52     0    38    16]\n",
      " [   24     0     0   314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.06      0.36      0.10       106\n",
      "           3       0.13      0.93      0.23       338\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     41443\n",
      "   macro avg       0.29      0.56      0.32     41443\n",
      "weighted avg       0.97      0.93      0.95     41443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39793     8   362   560]\n",
      " [  270     0     2     4]\n",
      " [   66     1    16    23]\n",
      " [   29     0     2   307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.04      0.15      0.07       106\n",
      "           3       0.34      0.91      0.50       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.34      0.51      0.39     41443\n",
      "weighted avg       0.98      0.97      0.97     41443\n",
      "\n",
      "[[40091     1   142   489]\n",
      " [  261     0     5    10]\n",
      " [   70     1    11    24]\n",
      " [   37     0     0   301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     40723\n",
      "           1       0.00      0.00      0.00       276\n",
      "           2       0.07      0.10      0.08       106\n",
      "           3       0.37      0.89      0.52       338\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     41443\n",
      "   macro avg       0.36      0.49      0.40     41443\n",
      "weighted avg       0.98      0.97      0.97     41443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "y_test_1 = y_test_0[ysfinal==0]\n",
    "X_test_1 = X_test_0[ysfinal==0]\n",
    "\n",
    "\n",
    "#X_train_0 = X_train[y_train==0]\n",
    "#X_train_1 = X_train[y_train==1]\n",
    "#X_train_bi = np.vstack((X_train_0,X_train_1))\n",
    "#y_train_0 = y_train[y_train==0]\n",
    "#y_train_1 = y_train[y_train==1]\n",
    "#y_train_bi = np.hstack((y_train_0,y_train_1))\n",
    "\n",
    "\n",
    "#X_train_bi = pd.DataFrame(X_train_bi,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train_bi = np.copy(y_train)\n",
    "\n",
    "#y_train_bi[y_train_bi != 3] = 0\n",
    "#y_train_bi[y_train_bi == 3] = 1\n",
    "\n",
    "f2 = classifier.Linear_D(X_train[n_s], y_train_bi,X_test_1[n_s], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f3 = classifier.logisticRegress(X_train[n_s], y_train_bi, X_test_1[n_s], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f4 = classifier.Linear_D(X_train[v_f_log], y_train_bi, X_test_1[v_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f5 = classifier.logisticRegress(X_train[n_f_ln], y_train_bi, X_test_1[n_f_ln], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f6= classifier.Linear_D(X_train[v_f_ln], y_train_bi, X_test_1[v_f_ln], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f7=classifier.Linear_D(X_train[s_f_log], y_train_bi, X_test_1[s_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "f8=classifier.Linear_D(X_train[v_f_log], y_train_bi, X_test_1[v_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "[[39245     8   645   293]\n",
      " [  254     3    14     0]\n",
      " [   56     5    19     2]\n",
      " [   32     0     1     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     40191\n",
      "           1       0.19      0.01      0.02       271\n",
      "           2       0.03      0.23      0.05        82\n",
      "           3       0.01      0.06      0.01        35\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     40579\n",
      "   macro avg       0.30      0.32      0.27     40579\n",
      "weighted avg       0.98      0.97      0.97     40579\n",
      "\n",
      "y1\n",
      "[[39822    33   157   179]\n",
      " [  242    18     9     2]\n",
      " [   46     0    24    12]\n",
      " [   33     1     1     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     40191\n",
      "           1       0.35      0.07      0.11       271\n",
      "           2       0.13      0.29      0.18        82\n",
      "           3       0.00      0.00      0.00        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     40579\n",
      "   macro avg       0.37      0.34      0.32     40579\n",
      "weighted avg       0.99      0.98      0.98     40579\n",
      "\n",
      "y2\n",
      "[[38349     0  1168   674]\n",
      " [  258     0    13     0]\n",
      " [   63     0    19     0]\n",
      " [   23     0     7     5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     40191\n",
      "           1       0.00      0.00      0.00       271\n",
      "           2       0.02      0.23      0.03        82\n",
      "           3       0.01      0.14      0.01        35\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     40579\n",
      "   macro avg       0.25      0.33      0.25     40579\n",
      "weighted avg       0.98      0.95      0.96     40579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_test_3 = y_test_1[f7==0]\n",
    "X_test_3 = X_test_1[f7==0]\n",
    "\n",
    "print(\"y\")\n",
    "y = classifier.logisticRegress(X_train[n_s], y_train, X_test_3[n_s], y_test_3, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y1\")\n",
    "y1 = classifier.logisticRegress(X_train[v_f], y_train, X_test_3[v_f], y_test_3, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y2\")\n",
    "y2 = classifier.Linear_D(X_train[n_s], y_train, X_test_3[n_s], y_test_3, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
