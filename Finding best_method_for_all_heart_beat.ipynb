{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn import svm, metrics\n",
    "\n",
    "\n",
    "\n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "rank = pd.read_csv(\"database/features_ranking.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "\n",
    "rank_n_f = pd.read_csv(\"database/features_n_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_n_s = pd.read_csv(\"database/features_n_vs_s_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_n_v = pd.read_csv(\"database/features_n_vs_v_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_s_f = pd.read_csv(\"database/features_s_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_s_v = pd.read_csv(\"database/features_s_vs_v_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "rank_v_f = pd.read_csv(\"database/features_v_vs_f_randomforest.py\").sort_values(['rfscore', 'features'], ascending=[0,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_lin.text', 'rb')\n",
    "n_s_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_lin.text', 'rb')\n",
    "n_v_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_lin.text', 'rb')\n",
    "n_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_lin.text', 'rb')\n",
    "s_v_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_lin.text', 'rb')\n",
    "s_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_lin.text', 'rb')\n",
    "v_f_ln = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_log.text', 'rb')\n",
    "n_s_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_log.text', 'rb')\n",
    "n_v_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_log.text', 'rb')\n",
    "n_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_log.text', 'rb')\n",
    "s_v_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_log.text', 'rb')\n",
    "s_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_log.text', 'rb')\n",
    "v_f_log = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "score = 0.01\n",
    "score_n_s = 0.01\n",
    "score_n_f = 0.015\n",
    "score_n_v = 0.01\n",
    "score_s_f = 0.01\n",
    "score_s_v = 0.015\n",
    "score_v_f = 0.01\n",
    "feature_good = rank[rank['rfscore'] >= score]['features'].values\n",
    "n_s = rank_n_s[rank_n_s['rfscore'] >= score_n_s]['features'].values\n",
    "n_f = rank_n_f[rank_n_f['rfscore'] >= score_n_f]['features'].values\n",
    "n_v = rank_n_v[rank_n_v['rfscore'] >= score_n_v]['features'].values\n",
    "s_f = rank_s_f[rank_s_f['rfscore'] >= score_s_f]['features'].values\n",
    "s_v = rank_s_v[rank_s_v['rfscore'] >= score_s_v]['features'].values\n",
    "v_f = rank_v_f[rank_v_f['rfscore'] >= score_v_f]['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "[[41468  1081  1090   382]\n",
      " [  457  1402   186     5]\n",
      " [  411   377  2334    98]\n",
      " [  130     1    22   235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     44021\n",
      "           1       0.49      0.68      0.57      2050\n",
      "           2       0.64      0.72      0.68      3220\n",
      "           3       0.33      0.61      0.42       388\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.61      0.74      0.66     49679\n",
      "weighted avg       0.93      0.91      0.92     49679\n",
      "\n",
      "y1\n",
      "[[42752   373   525   371]\n",
      " [ 1508   111   402    29]\n",
      " [  178   165  2620   257]\n",
      " [  232     1     3   152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     44021\n",
      "           1       0.17      0.05      0.08      2050\n",
      "           2       0.74      0.81      0.77      3220\n",
      "           3       0.19      0.39      0.25       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.51      0.56      0.52     49679\n",
      "weighted avg       0.90      0.92      0.91     49679\n",
      "\n",
      "y2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41176   386  1658   801]\n",
      " [ 1737   262    51     0]\n",
      " [  838   318  1874   190]\n",
      " [   42     0    40   306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     44021\n",
      "           1       0.27      0.13      0.17      2050\n",
      "           2       0.52      0.58      0.55      3220\n",
      "           3       0.24      0.79      0.36       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.49      0.61      0.51     49679\n",
      "weighted avg       0.88      0.88      0.88     49679\n",
      "\n",
      "y3\n",
      "[[41034   955  1021  1011]\n",
      " [  512  1245   237    56]\n",
      " [  537   404  2226    53]\n",
      " [  361     0     6    21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     44021\n",
      "           1       0.48      0.61      0.54      2050\n",
      "           2       0.64      0.69      0.66      3220\n",
      "           3       0.02      0.05      0.03       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.53      0.57      0.54     49679\n",
      "weighted avg       0.92      0.90      0.91     49679\n",
      "\n",
      "y4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42710   778   416   117]\n",
      " [ 1076   857   117     0]\n",
      " [ 1866   359   939    56]\n",
      " [  360     0    16    12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.43      0.42      0.42      2050\n",
      "           2       0.63      0.29      0.40      3220\n",
      "           3       0.06      0.03      0.04       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.51      0.43      0.45     49679\n",
      "weighted avg       0.88      0.90      0.88     49679\n",
      "\n",
      "y5\n",
      "[[43521   258   212    30]\n",
      " [ 2019    14    16     1]\n",
      " [  764    57  2205   194]\n",
      " [  349    12     5    22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.04      0.01      0.01      2050\n",
      "           2       0.90      0.68      0.78      3220\n",
      "           3       0.09      0.06      0.07       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.49      0.43      0.46     49679\n",
      "weighted avg       0.89      0.92      0.90     49679\n",
      "\n",
      "y6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43556   152   286    27]\n",
      " [ 1633   263   154     0]\n",
      " [  588    82  2341   209]\n",
      " [  287     0     2    99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     44021\n",
      "           1       0.53      0.13      0.21      2050\n",
      "           2       0.84      0.73      0.78      3220\n",
      "           3       0.30      0.26      0.27       388\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     49679\n",
      "   macro avg       0.65      0.52      0.56     49679\n",
      "weighted avg       0.92      0.93      0.92     49679\n",
      "\n",
      "y7\n",
      "[[42258   511   840   412]\n",
      " [  963    96   924    67]\n",
      " [  645   130  2287   158]\n",
      " [  380     0     7     1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     44021\n",
      "           1       0.13      0.05      0.07      2050\n",
      "           2       0.56      0.71      0.63      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.41      0.43      0.41     49679\n",
      "weighted avg       0.89      0.90      0.89     49679\n",
      "\n",
      "y8\n",
      "[[39847   660   540  2974]\n",
      " [  727   131  1122    70]\n",
      " [  337   222  2408   253]\n",
      " [   33     2     0   353]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     44021\n",
      "           1       0.13      0.06      0.09      2050\n",
      "           2       0.59      0.75      0.66      3220\n",
      "           3       0.10      0.91      0.17       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.45      0.66      0.46     49679\n",
      "weighted avg       0.91      0.86      0.88     49679\n",
      "\n",
      "y9\n",
      "[[43360   229   352    80]\n",
      " [ 1519    35   463    33]\n",
      " [ 1448    38  1669    65]\n",
      " [  381     0     7     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     44021\n",
      "           1       0.12      0.02      0.03      2050\n",
      "           2       0.67      0.52      0.58      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.43      0.38      0.39     49679\n",
      "weighted avg       0.87      0.91      0.89     49679\n",
      "\n",
      "y10\n",
      "[[43123   139   231   528]\n",
      " [ 1755    40   240    15]\n",
      " [  616   119  2271   214]\n",
      " [   49     0     0   339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     44021\n",
      "           1       0.13      0.02      0.03      2050\n",
      "           2       0.83      0.71      0.76      3220\n",
      "           3       0.31      0.87      0.46       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.55      0.64      0.55     49679\n",
      "weighted avg       0.90      0.92      0.91     49679\n",
      "\n",
      "y11\n",
      "[[43820    42    66    93]\n",
      " [ 2032     1     2    15]\n",
      " [ 3016     9   141    54]\n",
      " [  372     0    16     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.00      2050\n",
      "           2       0.63      0.04      0.08      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.38      0.26      0.26     49679\n",
      "weighted avg       0.83      0.88      0.84     49679\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier.logisticRegress(X_train[new_row], y_train, X_test[new_row], y_test, jk=True,labels=[0,1,2,3])[1]\n",
    "#y_train[y_train == 0] = 0\n",
    "#y_train[y_train != 0] = 1\n",
    "\n",
    "#y_test[y_test == 0] = 0\n",
    "#y_test[y_test != 0] = 1\n",
    "print(\"y\")\n",
    "y = classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y1\")\n",
    "y1 = classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y2\")\n",
    "y2 = classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "print(\"y3\")\n",
    "y3 = classifier.logisticRegress(X_train[n_s_ln], y_train, X_test[n_s_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y4\")\n",
    "y4 = classifier.Linear_D(X_train[n_s_ln], y_train, X_test[n_s_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y5\")\n",
    "y5 = classifier.Linear_D(X_train[n_v_ln], y_train, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n",
    "print(\"y6\")\n",
    "y6 = classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y7\")\n",
    "y7 = classifier.logisticRegress(X_train[n_v_log], y_train, X_test[n_v_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y8\")\n",
    "y8 = classifier.logisticRegress(X_train[v_f_log], y_train, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y9\")\n",
    "y9 = classifier.Linear_D(X_train[n_v_log], y_train, X_test[n_v_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y10\")\n",
    "y10 = classifier.Linear_D(X_train[v_f_log], y_train, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y11\")\n",
    "y11 = classifier.Linear_D(X_train[n_v_log], y_train, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n",
    "\n",
    "#classifier.voting_ensemble_lin_rf(X_train[new_row], y_train, X_test[new_row], y_test, jk=True,labels=[0,1,2,3])\n",
    "#classifier.logisticRegress(X_train[rank], y_train, X_test[rank], y_test, jk=True,labels=[0,1,2,3])\n",
    "#classifier.Linear_D(X_train[rank], y_train, X_test[rank], y_test, jk=True,labels=[0,1,2,3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "[[41342  5117     0     0]\n",
      " [  372  2848     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     46459\n",
      "           1       0.36      0.88      0.51      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.34      0.44      0.36     49679\n",
      "weighted avg       0.95      0.89      0.91     49679\n",
      "\n",
      "y1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44262  2197     0     0]\n",
      " [  223  2997     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     46459\n",
      "           1       0.58      0.93      0.71      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.39      0.47      0.42     49679\n",
      "weighted avg       0.97      0.95      0.96     49679\n",
      "\n",
      "y2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44203  2256     0     0]\n",
      " [ 1128  2092     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     46459\n",
      "           1       0.48      0.65      0.55      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     49679\n",
      "   macro avg       0.36      0.40      0.38     49679\n",
      "weighted avg       0.94      0.93      0.94     49679\n",
      "\n",
      "y3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41031  5428     0     0]\n",
      " [  463  2757     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93     46459\n",
      "           1       0.34      0.86      0.48      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.33      0.43      0.35     49679\n",
      "weighted avg       0.95      0.88      0.90     49679\n",
      "\n",
      "y4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45835   624     0     0]\n",
      " [ 2237   983     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     46459\n",
      "           1       0.61      0.31      0.41      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.39      0.32      0.34     49679\n",
      "weighted avg       0.93      0.94      0.93     49679\n",
      "\n",
      "y5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46194   265     0     0]\n",
      " [ 1023  2197     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46459\n",
      "           1       0.89      0.68      0.77      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.47      0.42      0.44     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "y6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45862   597     0     0]\n",
      " [  829  2391     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     46459\n",
      "           1       0.80      0.74      0.77      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.45      0.43      0.44     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "y7\n",
      "[[42064  4395     0     0]\n",
      " [  384  2836     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95     46459\n",
      "           1       0.39      0.88      0.54      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.35      0.45      0.37     49679\n",
      "weighted avg       0.95      0.90      0.92     49679\n",
      "\n",
      "y8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42517  3942     0     0]\n",
      " [  352  2868     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     46459\n",
      "           1       0.42      0.89      0.57      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.35      0.45      0.38     49679\n",
      "weighted avg       0.95      0.91      0.93     49679\n",
      "\n",
      "y9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45626   833     0     0]\n",
      " [ 1588  1632     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     46459\n",
      "           1       0.66      0.51      0.57      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.41      0.37      0.39     49679\n",
      "weighted avg       0.95      0.95      0.95     49679\n",
      "\n",
      "y10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45932   527     0     0]\n",
      " [  773  2447     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46459\n",
      "           1       0.82      0.76      0.79      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.45      0.44      0.44     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "y11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46250   209     0     0]\n",
      " [ 2990   230     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     46459\n",
      "           1       0.52      0.07      0.13      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.37      0.27      0.27     49679\n",
      "weighted avg       0.91      0.94      0.91     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "print(\"y\")\n",
    "y = classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y1\")\n",
    "y1 = classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y2\")\n",
    "y2 = classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "print(\"y3\")\n",
    "y3 = classifier.logisticRegress(X_train[n_s_ln], y_train, X_test[n_s_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y4\")\n",
    "y4 = classifier.Linear_D(X_train[n_s_ln], y_train, X_test[n_s_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y5\")\n",
    "y5 = classifier.Linear_D(X_train[n_v_ln], y_train, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n",
    "print(\"y6\")\n",
    "y6 = classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y7\")\n",
    "y7 = classifier.logisticRegress(X_train[n_v_log], y_train, X_test[n_v_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y8\")\n",
    "y8 = classifier.logisticRegress(X_train[v_f_log], y_train, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y9\")\n",
    "y9 = classifier.Linear_D(X_train[n_v_log], y_train, X_test[n_v_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y10\")\n",
    "y10 = classifier.Linear_D(X_train[v_f_log], y_train, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "print(\"y11\")\n",
    "y11 = classifier.Linear_D(X_train[n_v_log], y_train, X_test[n_v_ln], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_under' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1cbd6e951e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#y_test[y_test != 0] = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogisticRegress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_under\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munder_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogisticRegress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_under\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munder_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_under' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40941    45   128  2907]\n",
      " [ 1994    15     8    33]\n",
      " [  272    34  2767   147]\n",
      " [   73     0     8   307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     44021\n",
      "           1       0.16      0.01      0.01      2050\n",
      "           2       0.95      0.86      0.90      3220\n",
      "           3       0.09      0.79      0.16       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.54      0.65      0.50     49679\n",
      "weighted avg       0.91      0.89      0.89     49679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f70e4d8a5135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#y_test[y_test != 2] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#y_test[y_test == 2] = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_train_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_train_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train_b\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#### For v class\n",
    "\n",
    "#y_test[y_test != 2] = 0\n",
    "#y_test[y_test == 2] = 1\n",
    "y_train_b = np.copy(y_train)\n",
    "y_train_b[y_train_b == 3] = -1\n",
    "\n",
    "y_train_b[y_train_b == 0] = -1\n",
    "y_train_b[y_train_b >= 0] = 0\n",
    "\n",
    "y_train_b[y_train_b < 0] = 1\n",
    "#y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "y=classifier.randomForest(X_train[v_f_log], y_train_b, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y5=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y6=classifier.logisticRegress(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4015    0    0    0]\n",
      " [ 545    0    0    0]\n",
      " [2970    0    0    0]\n",
      " [ 358    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67      4015\n",
      "           1       0.00      0.00      0.00       545\n",
      "           2       0.00      0.00      0.00      2970\n",
      "           3       0.00      0.00      0.00       358\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      7888\n",
      "   macro avg       0.13      0.25      0.17      7888\n",
      "weighted avg       0.26      0.51      0.34      7888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4015    0    0    0]\n",
      " [ 545    0    0    0]\n",
      " [2970    0    0    0]\n",
      " [ 358    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67      4015\n",
      "           1       0.00      0.00      0.00       545\n",
      "           2       0.00      0.00      0.00      2970\n",
      "           3       0.00      0.00      0.00       358\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      7888\n",
      "   macro avg       0.13      0.25      0.17      7888\n",
      "weighted avg       0.26      0.51      0.34      7888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:402: RuntimeWarning: invalid value encountered in true_divide\n",
      "  S**2))[:self._max_components]\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a18e5ac9dd39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0my3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear_D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0my4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogisticRegress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f_log\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36mlogisticRegress\u001b[1;34m(X_train, y_train, X_test, y_test, jk, penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, solver, max_iter, multi_class, verbose, warm_start, n_jobs, labels)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;31m# dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=1, class_weight=None, random_state=None, solver=warn, max_iter=100, multi_class=warn, verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1305\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1306\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    879\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m    880\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "y_1 = y[y==1]\n",
    "\n",
    "y_test_1 = y_test[y==1]\n",
    "\n",
    "X_test_1 = X_test[y==1]\n",
    "\n",
    "y_train_b = np.copy(y_train)\n",
    "y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "y_train_b[y_train_b != 2] = 0\n",
    "\n",
    "y2=classifier.randomForest(X_train[v_f_log], y_train_b, X_test_1[v_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "y3=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test_1[n_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n",
    "y4=classifier.logisticRegress(X_train[n_f_log], y_train_b, X_test_1[n_f_log], y_test_1, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43849   172     0     0]\n",
      " [ 1861   189     0     0]\n",
      " [  918  2302     0     0]\n",
      " [  377    11     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     44021\n",
      "           1       0.07      0.09      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.83      0.89      0.86     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42922  1099     0     0]\n",
      " [ 2013    37     0     0]\n",
      " [  412  2808     0     0]\n",
      " [  167   221     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.86      0.85     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40398  3623     0     0]\n",
      " [ 2021    29     0     0]\n",
      " [  415  2805     0     0]\n",
      " [  182   206     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.00      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.23      0.23     49679\n",
      "weighted avg       0.83      0.81      0.82     49679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y=classifier.svm_model_linear(X_train[v_f_log], y_train_b, X_test[v_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y7=classifier.Linear_D(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "y6=classifier.xgboost(X_train[n_f_log], y_train_b, X_test[n_f_log], y_test, jk=False,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45739   720     0     0]\n",
      " [  443  2777     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     46459\n",
      "           1       0.79      0.86      0.83      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     49679\n",
      "   macro avg       0.45      0.46      0.45     49679\n",
      "weighted avg       0.98      0.98      0.98     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41395  5064     0     0]\n",
      " [  175  3045     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     46459\n",
      "           1       0.38      0.95      0.54      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.34      0.46      0.37     49679\n",
      "weighted avg       0.96      0.89      0.91     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[y_test != 2] = 0\n",
    "#y_test[y_test == 2] = 1\n",
    "\n",
    "#y_train[y_train != 2] = 0\n",
    "#y_train[y_train == 2] = 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "scale_test = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "scale_test.fit(X_test)\n",
    "X_train_s = scale.transform(X_train)\n",
    "X_test_s = scale_test.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39761    21   123  4116]\n",
      " [ 2004     1     5    40]\n",
      " [  343    80  2420   377]\n",
      " [   23     0     6   359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     44021\n",
      "           1       0.01      0.00      0.00      2050\n",
      "           2       0.95      0.75      0.84      3220\n",
      "           3       0.07      0.93      0.14       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.49      0.65      0.47     49679\n",
      "weighted avg       0.90      0.86      0.87     49679\n",
      "\n",
      "[[39880   850   960  2331]\n",
      " [ 1837   160    14    39]\n",
      " [  214    55  2799   152]\n",
      " [  139     1    45   203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     44021\n",
      "           1       0.15      0.08      0.10      2050\n",
      "           2       0.73      0.87      0.80      3220\n",
      "           3       0.07      0.52      0.13       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.48      0.59      0.49     49679\n",
      "weighted avg       0.89      0.87      0.88     49679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y7=classifier.Linear_D(X_train_s[n_f_log], y_train, X_test_s[n_f_log], y_test, jk=False)[2]\n",
    "y6=classifier.logisticRegress(X_train[n_f_log], y_train, X_test[n_f_log], y_test, jk=False)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40903    48   127  2943]\n",
      " [ 1994    15     8    33]\n",
      " [  272    34  2767   147]\n",
      " [   72     0     7   309]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     44021\n",
      "           1       0.15      0.01      0.01      2050\n",
      "           2       0.95      0.86      0.90      3220\n",
      "           3       0.09      0.80      0.16       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.54      0.65      0.50     49679\n",
      "weighted avg       0.91      0.89      0.89     49679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inds1 = []\n",
    "for i in range(len(y)):\n",
    "    #avg.append(np.mean([y[i], y1[i], y2[i], y3[i], y4[i], y4[i],y5[i], y6[i], y7[i], y8[i]]))\n",
    "    #avg.append(round(np.mean([y[i],y3[i], y4[i],  y5[i],  y6[i]]),0))\n",
    "    #print(np.mean(  [y5[i],  y6[i]]))\n",
    "   # indes.append(voting( [y5[i],y4[i],  y6[i]])\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i], y7[i]], focus = 2, amount=2))\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i]], focus = 2, amount=2))\n",
    "    #if(2 in [y[i],y6[i],  y7[i]]):\n",
    "    inds1.append(classifier.voting( [y[i],y6[i],  y7[i]], focus = 2, amount=2, random = False))\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,inds1 , labels=[0,1,2,3]))\n",
    "print(classification_report(y_test,inds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds1 = np.asarray(inds1)\n",
    "X_test_s = X_test[inds1!=2]\n",
    "y_test_s = y_test[inds1!=2]\n",
    "\n",
    "\n",
    "X_train_s = X_train[y_train != 2]\n",
    "y_train_s = y_train[y_train != 2]\n",
    "\n",
    "y_pred_v = inds1[inds1==2]\n",
    "y_true_v = y_test[inds1==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41397  1068  1051   378]\n",
      " [  457  1396   184     5]\n",
      " [  147    68   180    58]\n",
      " [  128     1    18   234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     43894\n",
      "           1       0.55      0.68      0.61      2042\n",
      "           2       0.13      0.40      0.19       453\n",
      "           3       0.35      0.61      0.44       381\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     46770\n",
      "   macro avg       0.50      0.66      0.55     46770\n",
      "weighted avg       0.95      0.92      0.94     46770\n",
      "\n",
      "[[40956   946   981  1011]\n",
      " [  511  1243   232    56]\n",
      " [  213    76   146    18]\n",
      " [  358     0     3    20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     43894\n",
      "           1       0.55      0.61      0.58      2042\n",
      "           2       0.11      0.32      0.16       453\n",
      "           3       0.02      0.05      0.03       381\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     46770\n",
      "   macro avg       0.41      0.48      0.43     46770\n",
      "weighted avg       0.94      0.91      0.92     46770\n",
      "\n",
      "[[41049  1512   623   710]\n",
      " [  398  1553    68    23]\n",
      " [  161   126   126    40]\n",
      " [  246     1    13   121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     43894\n",
      "           1       0.49      0.76      0.59      2042\n",
      "           2       0.15      0.28      0.20       453\n",
      "           3       0.14      0.32      0.19       381\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     46770\n",
      "   macro avg       0.44      0.57      0.48     46770\n",
      "weighted avg       0.94      0.92      0.93     46770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y2 = classifier.logisticRegress(X_train[n_s], y_train, X_test_s[n_s], y_test_s, jk=False,labels=[0,1,2,3])[2]\n",
    "y5 = classifier.logisticRegress(X_train[n_s_ln], y_train, X_test_s[n_s_ln], y_test_s, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "inds2 = []\n",
    "for i in range(len(y2)):\n",
    "    #avg.append(np.mean([y[i], y1[i], y2[i], y3[i], y4[i], y4[i],y5[i], y6[i], y7[i], y8[i]]))\n",
    "    #avg.append(round(np.mean([y[i],y3[i], y4[i],  y5[i],  y6[i]]),0))\n",
    "    #print(np.mean(  [y5[i],  y6[i]]))\n",
    "   # indes.append(voting( [y5[i],y4[i],  y6[i]])\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i], y7[i]], focus = 2, amount=2))\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i]], focus = 2, amount=2))\n",
    "    inds2.append(classifier.voting( [y2[i],y5[i]], focus = 1, amount=1, random = True))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_test_s,inds2 , labels=[0,1,2,3]))\n",
    "print(classification_report(y_test_s,inds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds2 = np.asarray(inds2)\n",
    "X_test_f = X_test_s[inds2!=1]\n",
    "y_test_f = y_test_s[inds2!=1]\n",
    "\n",
    "\n",
    "X_train_f = X_train_s[y_train_s != 1]\n",
    "y_train_f = y_train_s[y_train_s != 1]\n",
    "\n",
    "y_pred_s = inds[inds2==1]\n",
    "y_true_s = y_test_s[inds2==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40160     6  1418   798]\n",
      " [  449     2    38     0]\n",
      " [  173     6    64    84]\n",
      " [   38     0    37   305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     42382\n",
      "           1       0.14      0.00      0.01       489\n",
      "           2       0.04      0.20      0.07       327\n",
      "           3       0.26      0.80      0.39       380\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     43578\n",
      "   macro avg       0.36      0.49      0.36     43578\n",
      "weighted avg       0.96      0.93      0.94     43578\n",
      "\n",
      "[[41170     0   834   378]\n",
      " [  414     0    70     5]\n",
      " [  131     0   140    56]\n",
      " [  128     0    18   234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     42382\n",
      "           1       0.00      0.00      0.00       489\n",
      "           2       0.13      0.43      0.20       327\n",
      "           3       0.35      0.62      0.44       380\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     43578\n",
      "   macro avg       0.37      0.50      0.41     43578\n",
      "weighted avg       0.96      0.95      0.96     43578\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41709    12   148   513]\n",
      " [  458     3    17    11]\n",
      " [  177     6    55    89]\n",
      " [   42     0     0   338]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     42382\n",
      "           1       0.14      0.01      0.01       489\n",
      "           2       0.25      0.17      0.20       327\n",
      "           3       0.36      0.89      0.51       380\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     43578\n",
      "   macro avg       0.43      0.51      0.43     43578\n",
      "weighted avg       0.96      0.97      0.96     43578\n",
      "\n",
      "[[36080   255  2443  3604]\n",
      " [  265    19   165    40]\n",
      " [  148     5    33   141]\n",
      " [   22     0     3   355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91     42382\n",
      "           1       0.07      0.04      0.05       489\n",
      "           2       0.01      0.10      0.02       327\n",
      "           3       0.09      0.93      0.16       380\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     43578\n",
      "   macro avg       0.29      0.48      0.29     43578\n",
      "weighted avg       0.96      0.84      0.89     43578\n",
      "\n",
      "[0.11429859230210813, 0.22035368460026994, 0.0846935067260878]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39600     6   635  2141]\n",
      " [  468     2    11     8]\n",
      " [  168     0    76    83]\n",
      " [   29     0     1   350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96     42382\n",
      "           1       0.25      0.00      0.01       489\n",
      "           2       0.11      0.23      0.14       327\n",
      "           3       0.14      0.92      0.24       380\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     43578\n",
      "   macro avg       0.37      0.52      0.34     43578\n",
      "weighted avg       0.96      0.92      0.94     43578\n",
      "\n",
      "[0.19135216807294642, 0.5916234473892537, 0.16962901496012991]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41442    12   361   567]\n",
      " [  475     0     6     8]\n",
      " [  142     1   104    80]\n",
      " [   33     0     4   343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     42382\n",
      "           1       0.00      0.00      0.00       489\n",
      "           2       0.22      0.32      0.26       327\n",
      "           3       0.34      0.90      0.50       380\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     43578\n",
      "   macro avg       0.39      0.55      0.43     43578\n",
      "weighted avg       0.96      0.96      0.96     43578\n",
      "\n",
      "[0.35750248402516854, 0.5369901818767101, 0.24587501474717305]\n",
      "[[41709    12   148   513]\n",
      " [  458     3    17    11]\n",
      " [  177     6    55    89]\n",
      " [   42     0     0   338]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     42382\n",
      "           1       0.14      0.01      0.01       489\n",
      "           2       0.25      0.17      0.20       327\n",
      "           3       0.36      0.89      0.51       380\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     43578\n",
      "   macro avg       0.43      0.51      0.43     43578\n",
      "weighted avg       0.96      0.97      0.96     43578\n",
      "\n",
      "[0.3718834875386272, 0.5671878308367305, 0.25684022262390493]\n"
     ]
    }
   ],
   "source": [
    "f2 = classifier.Linear_D(X_train[n_s], y_train, X_test_f[n_s], y_test_f, jk=False,labels=[0,1,2,3])[2]\n",
    "f3 = classifier.logisticRegress(X_train[n_s], y_train, X_test_f[n_s], y_test_f, jk=False,labels=[0,1,2,3])[2]\n",
    "f4 = classifier.Linear_D(X_train[v_f_log], y_train, X_test_f[v_f_log], y_test_f, jk=False,labels=[0,1,2,3])[2]\n",
    "f5 = classifier.logisticRegress(X_train[n_f_ln], y_train, X_test_f[n_f_ln], y_test_f, jk=True,labels=[0,1,2,3])[2]\n",
    "f6= classifier.Linear_D(X_train[v_f_ln], y_train, X_test_f[v_f_ln], y_test_f, jk=True,labels=[0,1,2,3])[2]\n",
    "f7=classifier.Linear_D(X_train[s_f_log], y_train, X_test_f[s_f_log], y_test_f, jk=True,labels=[0,1,2,3])[2]\n",
    "f8=classifier.Linear_D(X_train[v_f_log], y_train, X_test_f[v_f_log], y_test_f, jk=True,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41442    12   361   567]\n",
      " [  475     0     6     8]\n",
      " [  142     1   104    80]\n",
      " [   33     0     4   343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     42382\n",
      "           1       0.00      0.00      0.00       489\n",
      "           2       0.22      0.32      0.26       327\n",
      "           3       0.34      0.90      0.50       380\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     43578\n",
      "   macro avg       0.39      0.55      0.43     43578\n",
      "weighted avg       0.96      0.96      0.96     43578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inds3 = []\n",
    "for i in range(len(f2)):\n",
    "    #avg.append(np.mean([y[i], y1[i], y2[i], y3[i], y4[i], y4[i],y5[i], y6[i], y7[i], y8[i]]))\n",
    "    #avg.append(round(np.mean([y[i],y3[i], y4[i],  y5[i],  y6[i]]),0))\n",
    "    #print(np.mean(  [y5[i],  y6[i]]))\n",
    "   # indes.append(voting( [y5[i],y4[i],  y6[i]])\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i], y7[i]], focus = 2, amount=2))\n",
    "    #inds.append(voting( [y[i],y3[i],  y6[i]], focus = 2, amount=2))\n",
    "    #print(classifier.voting( [f2[i],f3[i], f4[i], f5[i], f6[i], f7[i], f8[i]], focus = 3, amount=3, random = True))\n",
    "#\n",
    "   # inds3.append(classifier.voting( [f2[i],f3[i], f4[i], f5[i], f6[i], f7[i], f8[i]], focus = 3, amount=3, random = True))\n",
    "    inds3.append(classifier.voting( [ f4[i], f6[i], f7[i], f8[i]], focus = 3, amount=2, random = True))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "print(metrics.confusion_matrix(y_test_f,f7 , labels=[0,1,2,3]))\n",
    "print(classification_report(y_test_f,f7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred_v = inds1[inds1==2]\n",
    "#y_true_v = y_test[inds1==2]\n",
    "\n",
    "#y_pred_s = inds[inds2==1]\n",
    "#y_true_s = y_test_s[inds2==1]\n",
    "y_pred_f = f7\n",
    "f7[f7 != 3] = 0\n",
    "y_test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = np.hstack((y_pred_v, y_pred_s , y_pred_f))\n",
    "y_true = np.hstack((y_true_v,y_true_s,  y_test_f))\n",
    "y_pred_n = np.hstack((y_pred_v, y_pred_s , f7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41815  1512   127   567]\n",
      " [  481  1553     8     8]\n",
      " [  247   126  2767    80]\n",
      " [   37     1     7   343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     44021\n",
      "           1       0.49      0.76      0.59      2050\n",
      "           2       0.95      0.86      0.90      3220\n",
      "           3       0.34      0.88      0.49       388\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.69      0.86      0.74     49679\n",
      "weighted avg       0.95      0.94      0.94     49679\n",
      "\n",
      "[[41815  1512   127   567]\n",
      " [  481  1553     8     8]\n",
      " [  247   126  2767    80]\n",
      " [   37     1     7   343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     44021\n",
      "           1       0.49      0.76      0.59      2050\n",
      "           2       0.95      0.86      0.90      3220\n",
      "           3       0.34      0.88      0.49       388\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.69      0.86      0.74     49679\n",
      "weighted avg       0.95      0.94      0.94     49679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_true,y_pred , labels=[0,1,2,3]))\n",
    "print(classification_report(y_true,y_pred))\n",
    "\n",
    "\n",
    "print(metrics.confusion_matrix(y_true,y_pred_n , labels=[0,1,2,3]))\n",
    "print(classification_report(y_true,y_pred_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7245367357215096, 3.0545925424129345, 0.7440924356623716]\n",
      "[0.7245367357215096, 3.0545925424129345, 0.7440924356623716]\n"
     ]
    }
   ],
   "source": [
    "labels = [0,1,2,3]\n",
    "print(metric.get_metrics(y_true,y_pred,lb=labels))\n",
    "print(metric.get_metrics(y_true,y_pred_n,lb=labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SparseRandomProjection(n_components = 10, eps=0.1)\n",
    "transformer.fit(X_train[n_s])\n",
    "X_new = transformer.transform(X_train[n_s])\n",
    "X_new_test = transformer.transform(X_test[n_s])\n",
    "\n",
    "transformer = GaussianRandomProjection(n_components = 10, eps=0.1)\n",
    "transformer.fit(X_train[n_s])\n",
    "X_new_g = transformer.transform(X_train[n_s])\n",
    "X_new_test_g = transformer.transform(X_test[n_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(X_new_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41297  1096  1052   576]\n",
      " [  433  1501   109     7]\n",
      " [  360   308  2461    91]\n",
      " [  114     1    25   248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     44021\n",
      "           1       0.52      0.73      0.61      2050\n",
      "           2       0.67      0.76      0.72      3220\n",
      "           3       0.27      0.64      0.38       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.61      0.77      0.66     49679\n",
      "weighted avg       0.93      0.92      0.92     49679\n",
      "\n",
      "[0.6499460300609754, 2.6877995926047715, 0.6609479641060841]\n",
      "[[41385  1094   924   618]\n",
      " [  457  1487    94    12]\n",
      " [  418   355  2351    96]\n",
      " [  127     1    25   235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     44021\n",
      "           1       0.51      0.73      0.60      2050\n",
      "           2       0.69      0.73      0.71      3220\n",
      "           3       0.24      0.61      0.35       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.60      0.75      0.65     49679\n",
      "weighted avg       0.93      0.92      0.92     49679\n",
      "\n",
      "[0.64140133257105, 2.6544820093874337, 0.6525109174589543]\n",
      "[[41468  1081  1090   382]\n",
      " [  457  1402   186     5]\n",
      " [  411   377  2334    98]\n",
      " [  130     1    22   235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     44021\n",
      "           1       0.49      0.68      0.57      2050\n",
      "           2       0.64      0.72      0.68      3220\n",
      "           3       0.33      0.61      0.42       388\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.61      0.74      0.66     49679\n",
      "weighted avg       0.93      0.91      0.92     49679\n",
      "\n",
      "[0.6373095096068558, 2.541406752990806, 0.6363305989272787]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.logisticRegress(X_new, y_train, X_new_test, y_test, jk=True,labels=[0,1,2,3])[2]\n",
    "classifier.logisticRegress(X_new_g, y_train, X_new_test_g, y_test, jk=True,labels=[0,1,2,3])[2]\n",
    "\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = GaussianRandomProjection(n_components = 10, eps=0.1)\n",
    "transformer.fit(X_train[n_s])\n",
    "X_new = transformer.transform(X_train[n_s])\n",
    "X_new_test = transformer.transform(X_test[n_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr, HOS, myMorph training features\n",
    "train_rr=np.loadtxt('database/rr-train.txt', dtype=float)[:,1:] # extract class labels\n",
    "train_hos=np.loadtxt('database/hos_train.txt', dtype=float)\n",
    "train_mmorph=np.loadtxt('database/morph_train.txt', dtype=float)\n",
    "\n",
    "# rr, HOS, myMorph testing features\n",
    "test_rr=np.loadtxt('database/rr-test.txt', dtype=float)[:,1:] # extract class labels\n",
    "test_rr=np.loadtxt('database/rr-test.txt', dtype=float)[:,1:] # extract class labels\n",
    "test_hos=np.loadtxt('database/hos_test.txt', dtype=float)\n",
    "test_mmorph=np.loadtxt('database/morph_test.txt', dtype=float)\n",
    "\n",
    "# training and testing class labels.\n",
    "train_labels=np.loadtxt('database/labels_train.txt', dtype=str)\n",
    "test_labels=np.loadtxt('database/labels_test.txt', dtype=str)\n",
    "\n",
    "# aggregate all features.\n",
    "train=np.hstack((train_rr, train_mmorph))\n",
    "test=np.hstack((test_rr, test_mmorph))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "transformer = GaussianRandomProjection(n_components = 2, eps=0.1)\n",
    "transformer.fit(train_rr[:,3:8])\n",
    "train_g = transformer.transform(train_rr[:,3:8])\n",
    "test_g = transformer.transform(test_rr[:,3:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46059   398]\n",
      " [  980  2240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46457\n",
      "           1       0.85      0.70      0.76      3220\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49677\n",
      "   macro avg       0.91      0.84      0.88     49677\n",
      "weighted avg       0.97      0.97      0.97     49677\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', ..., '0', '0', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_labels[train_labels != 'V'] = 0\n",
    "train_labels[train_labels == 'V'] = 1\n",
    "\n",
    "test_labels[test_labels != 'V'] = 0\n",
    "test_labels[test_labels == 'V'] = 1\n",
    "\n",
    "#classifier.Linear_D(train_g, train_labels, test_g, test_labels, jk=False,labels=[0,1])[2]\n",
    "classifier.Linear_D(train, train_labels, test, test_labels, jk=False,labels=['0','1'])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-eddfa40a5943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear_D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36mLinear_D\u001b[1;34m(X_train, y_train, X_test, y_test, jk, labels)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "classifier.Linear_D(train, train_labels, test, test_labels, jk=False,labels=['0','1'])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43237   315   180   288]\n",
      " [ 1708   100   231    10]\n",
      " [  734    99  2281   106]\n",
      " [  376     0     8     4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.94      0.98      0.96     44020\n",
      "           S       0.19      0.05      0.08      2049\n",
      "           V       0.84      0.71      0.77      3220\n",
      "           F       0.01      0.01      0.01       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49677\n",
      "   macro avg       0.50      0.44      0.45     49677\n",
      "weighted avg       0.89      0.92      0.90     49677\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['N', 'N', 'N', ..., 'N', 'N', 'N'], dtype='<U1')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.Linear_D(train, train_labels, test, test_labels, jk=False,labels=['N','S','V','F'])[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
