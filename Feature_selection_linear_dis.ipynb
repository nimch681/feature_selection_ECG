{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes.python import features_columns as col\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "from codes.python import TunedClassifier as classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])\n",
    "\n",
    "\n",
    "good_features_X = np.asarray(pd.read_csv(\"database/gooddata_X_train_no_outliers.csv\").iloc[:,1:263])\n",
    "good_features_y = np.asarray(pd.read_csv(\"database/gooddata_y_train_no_outliers.csv\").iloc[:,1])\n",
    "\n",
    "\n",
    "\n",
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "import pickle\n",
    "f = open('database/nvs_lin.text', 'rb')\n",
    "n_s = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvv_lin.text', 'rb')\n",
    "n_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/nvf_lin.text', 'rb')\n",
    "n_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svv_lin.text', 'rb')\n",
    "s_v = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/svf_lin.text', 'rb')\n",
    "s_f = pickle.load(f)[1]\n",
    "f.close()\n",
    "\n",
    "f = open('database/vvf_lin.text', 'rb')\n",
    "v_f = pickle.load(f)[1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[41034   955  1021  1011]\n",
      " [  512  1245   237    56]\n",
      " [  537   404  2226    53]\n",
      " [  361     0     6    21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     44021\n",
      "           1       0.48      0.61      0.54      2050\n",
      "           2       0.64      0.69      0.66      3220\n",
      "           3       0.02      0.05      0.03       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.53      0.57      0.54     49679\n",
      "weighted avg       0.92      0.90      0.91     49679\n",
      "\n",
      "[0.560565089690647, 2.4145543696453604, 0.5821018410509935]\n",
      "n_v\n",
      "[[39564  2044  2300   113]\n",
      " [ 1794   196    46    14]\n",
      " [  296   218  2413   293]\n",
      " [  191    61     6   130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92     44021\n",
      "           1       0.08      0.10      0.09      2050\n",
      "           2       0.51      0.75      0.60      3220\n",
      "           3       0.24      0.34      0.28       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.44      0.52      0.47     49679\n",
      "weighted avg       0.88      0.85      0.86     49679\n",
      "\n",
      "[0.3945505823809135, 1.4291981317673614, 0.37592505766137696]\n",
      "n_f\n",
      "[[36733   576  3011  3701]\n",
      " [ 1612    53   321    64]\n",
      " [ 1654    49  1052   465]\n",
      " [   27     0     5   356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87     44021\n",
      "           1       0.08      0.03      0.04      2050\n",
      "           2       0.24      0.33      0.28      3220\n",
      "           3       0.08      0.92      0.14       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.33      0.53      0.33     49679\n",
      "weighted avg       0.83      0.77      0.80     49679\n",
      "\n",
      "[0.17155579513674793, 0.6704229589431512, 0.16958076743626788]\n",
      "s_v\n",
      "[[36941   491  4717  1872]\n",
      " [ 1991     6    35    18]\n",
      " [  327   178  2572   143]\n",
      " [   62     1    70   255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.01      0.00      0.00      2050\n",
      "           2       0.35      0.80      0.48      3220\n",
      "           3       0.11      0.66      0.19       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.35      0.57      0.39     49679\n",
      "weighted avg       0.86      0.80      0.82     49679\n",
      "\n",
      "[0.30788957299298064, 1.1584099406785184, 0.2987460290813051]\n",
      "s_f\n",
      "[[40738   518  2253   512]\n",
      " [ 1935    51    47    17]\n",
      " [ 2058   269   729   164]\n",
      " [  171     2   116    99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     44021\n",
      "           1       0.06      0.02      0.04      2050\n",
      "           2       0.23      0.23      0.23      3220\n",
      "           3       0.12      0.26      0.17       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.33      0.36      0.34     49679\n",
      "weighted avg       0.82      0.84      0.83     49679\n",
      "\n",
      "[0.16423454335988483, 0.5437863524074615, 0.1500905657308751]\n",
      "v_f\n",
      "[[36791   768  1841  4621]\n",
      " [ 1746   126   125    53]\n",
      " [  443   146  2398   233]\n",
      " [   28     0     3   357]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.12      0.06      0.08      2050\n",
      "           2       0.55      0.74      0.63      3220\n",
      "           3       0.07      0.92      0.13       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.42      0.64      0.43     49679\n",
      "weighted avg       0.88      0.80      0.83     49679\n",
      "\n",
      "[0.32140230645442996, 1.4764561455917222, 0.34525817142618026]\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42710   778   416   117]\n",
      " [ 1076   857   117     0]\n",
      " [ 1866   359   939    56]\n",
      " [  360     0    16    12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.43      0.42      0.42      2050\n",
      "           2       0.63      0.29      0.40      3220\n",
      "           3       0.06      0.03      0.04       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.51      0.43      0.45     49679\n",
      "weighted avg       0.88      0.90      0.88     49679\n",
      "\n",
      "[0.4086296431852523, 1.7705014425211902, 0.42562750190777493]\n",
      "n_v\n",
      "[[43521   258   212    30]\n",
      " [ 2019    14    16     1]\n",
      " [  764    57  2205   194]\n",
      " [  349    12     5    22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.04      0.01      0.01      2050\n",
      "           2       0.90      0.68      0.78      3220\n",
      "           3       0.09      0.06      0.07       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.49      0.43      0.46     49679\n",
      "weighted avg       0.89      0.92      0.90     49679\n",
      "\n",
      "[0.5202896030929742, 1.637097456004836, 0.4647819835470916]\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41005    19   458  2539]\n",
      " [ 1919     3   101    27]\n",
      " [ 1982    10  1027   201]\n",
      " [   34     0     7   347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     44021\n",
      "           1       0.09      0.00      0.00      2050\n",
      "           2       0.64      0.32      0.43      3220\n",
      "           3       0.11      0.89      0.20       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.44      0.54      0.39     49679\n",
      "weighted avg       0.86      0.85      0.85     49679\n",
      "\n",
      "[0.24992622275099316, 1.058853057013656, 0.2573197435022036]\n",
      "s_v\n",
      "[[39588    35  1862  2536]\n",
      " [ 2003     0     7    40]\n",
      " [  839    80  2016   285]\n",
      " [   22     0    44   322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.51      0.63      0.56      3220\n",
      "           3       0.10      0.83      0.18       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.39      0.59      0.41     49679\n",
      "weighted avg       0.86      0.84      0.85     49679\n",
      "\n",
      "[0.34171875656803863, 1.1391946175041774, 0.3132587054720415]\n",
      "s_f\n",
      "[[41925    17  1949   130]\n",
      " [ 2016     0    30     4]\n",
      " [ 2718    12   437    53]\n",
      " [  280     0   106     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.17      0.14      0.15      3220\n",
      "           3       0.01      0.01      0.01       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.27      0.27      0.27     49679\n",
      "weighted avg       0.80      0.85      0.83     49679\n",
      "\n",
      "[0.07636546102569701, 0.30898946414410333, 0.07680641353086143]\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40968    52   840  2161]\n",
      " [ 1991    10    41     8]\n",
      " [  727    15  2301   177]\n",
      " [   33     0     4   351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     44021\n",
      "           1       0.13      0.00      0.01      2050\n",
      "           2       0.72      0.71      0.72      3220\n",
      "           3       0.13      0.90      0.23       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.48      0.64      0.47     49679\n",
      "weighted avg       0.88      0.88      0.88     49679\n",
      "\n",
      "[0.43511968335932966, 1.5715666741647651, 0.4140056759502605]\n",
      "Random\n",
      "all\n",
      "n_s\n",
      "[[40557   681  1879   904]\n",
      " [ 1389   125   518    18]\n",
      " [  341    22  2853     4]\n",
      " [  129     0   259     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     44021\n",
      "           1       0.15      0.06      0.09      2050\n",
      "           2       0.52      0.89      0.65      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.41      0.47      0.42     49679\n",
      "weighted avg       0.89      0.88      0.88     49679\n",
      "\n",
      "[0.47466241427034567, 1.6158464710520182, 0.43931201601667513]\n",
      "n_v\n",
      "[[40210  1655  2083    73]\n",
      " [ 1811   133   104     2]\n",
      " [  312   126  2743    39]\n",
      " [  233     2   152     1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     44021\n",
      "           1       0.07      0.06      0.07      2050\n",
      "           2       0.54      0.85      0.66      3220\n",
      "           3       0.01      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.39      0.46      0.42     49679\n",
      "weighted avg       0.87      0.87      0.87     49679\n",
      "\n",
      "[0.42933989804061384, 1.525904982326751, 0.4054080718111508]\n",
      "n_f\n",
      "[[35664   652  7702     3]\n",
      " [ 1617    16   417     0]\n",
      " [  739    23  2458     0]\n",
      " [   95     1   292     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87     44021\n",
      "           1       0.02      0.01      0.01      2050\n",
      "           2       0.23      0.76      0.35      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.30      0.40      0.31     49679\n",
      "weighted avg       0.84      0.77      0.79     49679\n",
      "\n",
      "[0.23931728296513452, 1.0204280622826016, 0.24721214926789248]\n",
      "s_v\n",
      "[[35106   588  7674   653]\n",
      " [ 1852    39   156     3]\n",
      " [  671     8  2535     6]\n",
      " [  174     1   212     1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86     44021\n",
      "           1       0.06      0.02      0.03      2050\n",
      "           2       0.24      0.79      0.37      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.31      0.40      0.31     49679\n",
      "weighted avg       0.84      0.76      0.79     49679\n",
      "\n",
      "[0.22415582852865723, 1.1072832099172492, 0.25048831550398476]\n",
      "s_f\n",
      "[[40077  1030  2383   531]\n",
      " [ 1890   101    57     2]\n",
      " [  752    24  2440     4]\n",
      " [  249     1   137     1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     44021\n",
      "           1       0.09      0.05      0.06      2050\n",
      "           2       0.49      0.76      0.59      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.38      0.43      0.39     49679\n",
      "weighted avg       0.86      0.86      0.86     49679\n",
      "\n",
      "[0.37119184215624534, 1.3807489322173794, 0.3581895376052951]\n",
      "v_f\n",
      "[[35764   576  3922  3759]\n",
      " [ 1518    96   422    14]\n",
      " [  408    15  2715    82]\n",
      " [   20     0    48   320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88     44021\n",
      "           1       0.14      0.05      0.07      2050\n",
      "           2       0.38      0.84      0.53      3220\n",
      "           3       0.08      0.82      0.14       388\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     49679\n",
      "   macro avg       0.39      0.63      0.40     49679\n",
      "weighted avg       0.87      0.78      0.81     49679\n",
      "\n",
      "[0.3149637208459872, 1.4117526904219904, 0.33395094672574244]\n",
      "ensamble ln\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42843   776   396     6]\n",
      " [ 1084   850   116     0]\n",
      " [ 1954   389   859    18]\n",
      " [  378     0     8     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.42      0.41      0.42      2050\n",
      "           2       0.62      0.27      0.37      3220\n",
      "           3       0.08      0.01      0.01       388\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.51      0.41      0.44     49679\n",
      "weighted avg       0.88      0.90      0.88     49679\n",
      "\n",
      "[0.3981745973349851, 1.7261557168747879, 0.41485676327684107]\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43563   272   174    12]\n",
      " [ 2020    14    16     0]\n",
      " [  831    66  2141   182]\n",
      " [  354    12     4    18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.04      0.01      0.01      2050\n",
      "           2       0.92      0.66      0.77      3220\n",
      "           3       0.08      0.05      0.06       388\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.49      0.43      0.45     49679\n",
      "weighted avg       0.89      0.92      0.90     49679\n",
      "\n",
      "[0.5113663977480521, 1.627114127275056, 0.4590724647834081]\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41030    61   411  2519]\n",
      " [ 1919     3   103    25]\n",
      " [ 2009    12  1001   198]\n",
      " [   34     0     7   347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     44021\n",
      "           1       0.04      0.00      0.00      2050\n",
      "           2       0.66      0.31      0.42      3220\n",
      "           3       0.11      0.89      0.20       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.43      0.53      0.39     49679\n",
      "weighted avg       0.85      0.85      0.85     49679\n",
      "\n",
      "[0.24648540674011496, 1.00949391767573, 0.24942944307952375]\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40334    51  2070  1566]\n",
      " [ 2006     1    27    16]\n",
      " [  845   117  2137   121]\n",
      " [   65     1    67   255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     44021\n",
      "           1       0.01      0.00      0.00      2050\n",
      "           2       0.50      0.66      0.57      3220\n",
      "           3       0.13      0.66      0.22       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.39      0.56      0.43     49679\n",
      "weighted avg       0.86      0.86      0.86     49679\n",
      "\n",
      "[0.3710710129110553, 1.1668959491634308, 0.3313975001009565]\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42489    29  1431    72]\n",
      " [ 2021     0    26     3]\n",
      " [ 2759    26   410    25]\n",
      " [  282     0   104     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.21      0.13      0.16      3220\n",
      "           3       0.02      0.01      0.01       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.28      0.27      0.27     49679\n",
      "weighted avg       0.81      0.86      0.83     49679\n",
      "\n",
      "[0.08563822160253709, 0.3353454279600795, 0.08473728929627848]\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41059    56   794  2112]\n",
      " [ 1991    11    41     7]\n",
      " [  775    33  2236   176]\n",
      " [   35     0     4   349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     44021\n",
      "           1       0.11      0.01      0.01      2050\n",
      "           2       0.73      0.69      0.71      3220\n",
      "           3       0.13      0.90      0.23       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.48      0.63      0.47     49679\n",
      "weighted avg       0.88      0.88      0.88     49679\n",
      "\n",
      "[0.4311712029574429, 1.5369302630914508, 0.40770188436515276]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(VotingClassifier(estimators=[('ln', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001)), ('lr', LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=10, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "           solver='warn', tol=0.0001, verbose=0, warm_start=False))],\n",
       "          flatten_transform=None, n_jobs=None, voting='hard', weights=None),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " [0.4311712029574429, 1.5369302630914508, 0.40770188436515276])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"ensamble ln\")\n",
    "print(\"all\")\n",
    "#classifier.voting_ensemble_lin(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.voting_ensemble_lin(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.voting_ensemble_lin(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.voting_ensemble_lin(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.voting_ensemble_lin(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.voting_ensemble_lin(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.voting_ensemble_lin(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_linear\n",
      "all\n",
      "n_s\n",
      "[[45976   483     0     0]\n",
      " [ 1444  1776     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     46459\n",
      "           1       0.79      0.55      0.65      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     49679\n",
      "   macro avg       0.44      0.39      0.41     49679\n",
      "weighted avg       0.96      0.96      0.96     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46199   260     0     0]\n",
      " [ 1493  1727     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     46459\n",
      "           1       0.87      0.54      0.66      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     49679\n",
      "   macro avg       0.46      0.38      0.41     49679\n",
      "weighted avg       0.96      0.96      0.96     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46459     0     0     0]\n",
      " [ 3220     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     46459\n",
      "           1       0.00      0.00      0.00      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.87      0.94      0.90     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44694  1765     0     0]\n",
      " [  772  2448     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     46459\n",
      "           1       0.58      0.76      0.66      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.39      0.43      0.41     49679\n",
      "weighted avg       0.96      0.95      0.95     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45491   968     0     0]\n",
      " [ 2842   378     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     46459\n",
      "           1       0.28      0.12      0.17      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.31      0.27      0.28     49679\n",
      "weighted avg       0.90      0.92      0.91     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46100   359     0     0]\n",
      " [ 1203  2017     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     46459\n",
      "           1       0.85      0.63      0.72      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.46      0.40      0.43     49679\n",
      "weighted avg       0.97      0.97      0.97     49679\n",
      "\n",
      "svm_poly\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46074   385     0     0]\n",
      " [ 1317  1903     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     46459\n",
      "           1       0.83      0.59      0.69      3220\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     49679\n",
      "   macro avg       0.90      0.79      0.84     49679\n",
      "weighted avg       0.96      0.97      0.96     49679\n",
      "\n",
      "n_v\n",
      "[[46449    10     0     0]\n",
      " [ 3219     1     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     46459\n",
      "           1       0.09      0.00      0.00      3220\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.51      0.50      0.48     49679\n",
      "weighted avg       0.88      0.94      0.90     49679\n",
      "\n",
      "n_f\n",
      "[[42645  3814     0     0]\n",
      " [ 1791  1429     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     46459\n",
      "           1       0.27      0.44      0.34      3220\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.62      0.68      0.64     49679\n",
      "weighted avg       0.92      0.89      0.90     49679\n",
      "\n",
      "s_v\n",
      "[[42944  3515     0     0]\n",
      " [ 1158  2062     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     46459\n",
      "           1       0.37      0.64      0.47      3220\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     49679\n",
      "   macro avg       0.67      0.78      0.71     49679\n",
      "weighted avg       0.93      0.91      0.92     49679\n",
      "\n",
      "s_f\n",
      "[[44244  2215     0     0]\n",
      " [ 1456  1764     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     46459\n",
      "           1       0.44      0.55      0.49      3220\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     49679\n",
      "   macro avg       0.71      0.75      0.73     49679\n",
      "weighted avg       0.93      0.93      0.93     49679\n",
      "\n",
      "v_f\n",
      "[[44395  2064     0     0]\n",
      " [ 1433  1787     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     46459\n",
      "           1       0.46      0.55      0.51      3220\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     49679\n",
      "   macro avg       0.72      0.76      0.73     49679\n",
      "weighted avg       0.94      0.93      0.93     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n",
      "[[44483  1976     0     0]\n",
      " [  398  2822     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97     46459\n",
      "           1       0.59      0.88      0.70      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.39      0.46      0.42     49679\n",
      "weighted avg       0.97      0.95      0.96     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44360  2099     0     0]\n",
      " [  723  2497     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     46459\n",
      "           1       0.54      0.78      0.64      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.38      0.43      0.40     49679\n",
      "weighted avg       0.96      0.94      0.95     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42410  4049     0     0]\n",
      " [  987  2233     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94     46459\n",
      "           1       0.36      0.69      0.47      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.33      0.40      0.35     49679\n",
      "weighted avg       0.94      0.90      0.91     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39868  6591     0     0]\n",
      " [  749  2471     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92     46459\n",
      "           1       0.27      0.77      0.40      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.31      0.41      0.33     49679\n",
      "weighted avg       0.94      0.85      0.88     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44346  2113     0     0]\n",
      " [  928  2292     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     46459\n",
      "           1       0.52      0.71      0.60      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     49679\n",
      "   macro avg       0.37      0.42      0.39     49679\n",
      "weighted avg       0.95      0.94      0.94     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43324  3135     0     0]\n",
      " [  623  2597     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     46459\n",
      "           1       0.45      0.81      0.58      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.36      0.43      0.38     49679\n",
      "weighted avg       0.95      0.92      0.93     49679\n",
      "\n",
      "xgboost\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45838   621     0     0]\n",
      " [  506  2714     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     46459\n",
      "           1       0.81      0.84      0.83      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     49679\n",
      "   macro avg       0.45      0.46      0.45     49679\n",
      "weighted avg       0.98      0.98      0.98     49679\n",
      "\n",
      "n_v\n",
      "[[44841  1618     0     0]\n",
      " [  736  2484     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     46459\n",
      "           1       0.61      0.77      0.68      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.40      0.43      0.41     49679\n",
      "weighted avg       0.96      0.95      0.96     49679\n",
      "\n",
      "n_f\n",
      "[[43372  3087     0     0]\n",
      " [  888  2332     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96     46459\n",
      "           1       0.43      0.72      0.54      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     49679\n",
      "   macro avg       0.35      0.41      0.37     49679\n",
      "weighted avg       0.94      0.92      0.93     49679\n",
      "\n",
      "s_v\n",
      "[[42510  3949     0     0]\n",
      " [  805  2415     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95     46459\n",
      "           1       0.38      0.75      0.50      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     49679\n",
      "   macro avg       0.34      0.42      0.36     49679\n",
      "weighted avg       0.94      0.90      0.92     49679\n",
      "\n",
      "s_f\n",
      "[[45021  1438     0     0]\n",
      " [ 1012  2208     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     46459\n",
      "           1       0.61      0.69      0.64      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     49679\n",
      "   macro avg       0.40      0.41      0.40     49679\n",
      "weighted avg       0.95      0.95      0.95     49679\n",
      "\n",
      "v_f\n",
      "[[45135  1324     0     0]\n",
      " [  678  2542     0     0]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     46459\n",
      "           1       0.66      0.79      0.72      3220\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     49679\n",
      "   macro avg       0.41      0.44      0.42     49679\n",
      "weighted avg       0.96      0.96      0.96     49679\n",
      "\n",
      "ada\n",
      "n_s\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "#X_train_under = pd.DataFrame(under_X_train,columns=features_clinic)\n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "y_test[y_test != 2] = 0\n",
    "y_test[y_test == 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.voting_ensemble(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.voting_ensemble(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.voting_ensemble(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.voting_ensemble(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.voting_ensemble(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.voting_ensemble(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "## Use this first\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train = X_train_balanced\n",
    "\n",
    "y_train = good_features_y\n",
    "\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "#classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.voting_ensemble(X_train[n_s], y_train, X_test[n_s], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.voting_ensemble(X_train[n_v], y_train, X_test[n_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.voting_ensemble(X_train[n_f], y_train, X_test[n_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.voting_ensemble(X_train[s_v], y_train, X_test[s_v], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.voting_ensemble(X_train[s_f], y_train, X_test[s_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.voting_ensemble(X_train[v_f], y_train, X_test[v_f], y_test, jk=True,labels=[0,1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[37880  6141     0     0]\n",
      " [  282  1768     0     0]\n",
      " [  341  2879     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91     44021\n",
      "           1       0.16      0.86      0.28      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.28      0.43      0.30     49679\n",
      "weighted avg       0.87      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37062  6959     0     0]\n",
      " [ 1654   396     0     0]\n",
      " [  260  2960     0     0]\n",
      " [  288   100     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.04      0.19      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.25      0.26      0.24     49679\n",
      "weighted avg       0.84      0.75      0.79     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30082 13939     0     0]\n",
      " [  813  1237     0     0]\n",
      " [  922  2298     0     0]\n",
      " [  231   157     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     44021\n",
      "           1       0.07      0.60      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     49679\n",
      "   macro avg       0.25      0.32      0.23     49679\n",
      "weighted avg       0.83      0.63      0.71     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32340 11681     0     0]\n",
      " [ 1947   103     0     0]\n",
      " [  168  3052     0     0]\n",
      " [  124   264     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82     44021\n",
      "           1       0.01      0.05      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     49679\n",
      "   macro avg       0.24      0.20      0.21     49679\n",
      "weighted avg       0.83      0.65      0.73     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37103  6918     0     0]\n",
      " [ 1284   766     0     0]\n",
      " [ 1146  2074     0     0]\n",
      " [  118   270     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.08      0.37      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.25      0.30      0.25     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35901  8120     0     0]\n",
      " [ 1530   520     0     0]\n",
      " [  277  2943     0     0]\n",
      " [  358    30     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87     44021\n",
      "           1       0.04      0.25      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.73      0.78     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42822  1199     0     0]\n",
      " [ 1760   290     0     0]\n",
      " [ 1797  1423     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     44021\n",
      "           1       0.10      0.14      0.12      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.82      0.87      0.84     49679\n",
      "\n",
      "n_v\n",
      "[[43609   412     0     0]\n",
      " [ 2032    18     0     0]\n",
      " [  733  2487     0     0]\n",
      " [  371    17     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.83      0.88      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43078   943     0     0]\n",
      " [ 1927   123     0     0]\n",
      " [ 2196  1024     0     0]\n",
      " [  291    97     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     44021\n",
      "           1       0.06      0.06      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.81      0.87      0.84     49679\n",
      "\n",
      "s_v\n",
      "[[41004  3017     0     0]\n",
      " [ 2011    39     0     0]\n",
      " [  926  2294     0     0]\n",
      " [  226   162     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.23      0.24      0.24     49679\n",
      "weighted avg       0.82      0.83      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42503  1518     0     0]\n",
      " [ 2025    25     0     0]\n",
      " [ 2771   449     0     0]\n",
      " [  289    99     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43031   990     0     0]\n",
      " [ 2002    48     0     0]\n",
      " [  786  2434     0     0]\n",
      " [  381     7     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     44021\n",
      "           1       0.01      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37437  6584     0     0]\n",
      " [ 1224   826     0     0]\n",
      " [  143  3077     0     0]\n",
      " [   27   361     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90     44021\n",
      "           1       0.08      0.40      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.26      0.31      0.26     49679\n",
      "weighted avg       0.86      0.77      0.81     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38475  5546     0     0]\n",
      " [ 1789   261     0     0]\n",
      " [  335  2885     0     0]\n",
      " [  195   193     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91     44021\n",
      "           1       0.03      0.13      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.84      0.78      0.81     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37174  6847     0     0]\n",
      " [ 1557   493     0     0]\n",
      " [  807  2413     0     0]\n",
      " [  366    22     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.89     44021\n",
      "           1       0.05      0.24      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34791  9230     0     0]\n",
      " [ 1983    67     0     0]\n",
      " [  732  2488     0     0]\n",
      " [  279   109     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     49679\n",
      "   macro avg       0.23      0.21      0.22     49679\n",
      "weighted avg       0.82      0.70      0.75     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40591  3430     0     0]\n",
      " [ 1829   221     0     0]\n",
      " [  762  2458     0     0]\n",
      " [  325    63     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     44021\n",
      "           1       0.04      0.11      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.83      0.82      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35646  8375     0     0]\n",
      " [ 1509   541     0     0]\n",
      " [  388  2832     0     0]\n",
      " [   62   326     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87     44021\n",
      "           1       0.04      0.26      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.73      0.78     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([1, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 0] = 1\n",
    "y_train[y_train == 0] = 0\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[38307  5714     0     0]\n",
      " [  585  1465     0     0]\n",
      " [  521  2699     0     0]\n",
      " [  367    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91     44021\n",
      "           1       0.15      0.71      0.25      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.28      0.40      0.29     49679\n",
      "weighted avg       0.86      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37361  6660     0     0]\n",
      " [ 1751   299     0     0]\n",
      " [  316  2904     0     0]\n",
      " [  294    94     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.03      0.15      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29186 14835     0     0]\n",
      " [  511  1539     0     0]\n",
      " [ 1015  2205     0     0]\n",
      " [  154   234     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.66      0.78     44021\n",
      "           1       0.08      0.75      0.15      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     49679\n",
      "   macro avg       0.26      0.35      0.23     49679\n",
      "weighted avg       0.84      0.62      0.70     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33839 10182     0     0]\n",
      " [ 1870   180     0     0]\n",
      " [  402  2818     0     0]\n",
      " [   19   369     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.84     44021\n",
      "           1       0.01      0.09      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     49679\n",
      "   macro avg       0.24      0.21      0.22     49679\n",
      "weighted avg       0.83      0.68      0.75     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35820  8201     0     0]\n",
      " [ 1093   957     0     0]\n",
      " [ 1263  1957     0     0]\n",
      " [   35   353     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87     44021\n",
      "           1       0.08      0.47      0.14      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.26      0.32      0.25     49679\n",
      "weighted avg       0.83      0.74      0.78     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36807  7214     0     0]\n",
      " [ 1569   481     0     0]\n",
      " [  367  2853     0     0]\n",
      " [  316    72     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.05      0.23      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.75      0.79     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43438   583     0     0]\n",
      " [ 1907   143     0     0]\n",
      " [ 2227   993     0     0]\n",
      " [  353    35     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94     44021\n",
      "           1       0.08      0.07      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.26      0.26     49679\n",
      "weighted avg       0.81      0.88      0.84     49679\n",
      "\n",
      "n_v\n",
      "[[43839   182     0     0]\n",
      " [ 2035    15     0     0]\n",
      " [  901  2319     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.88      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42372  1649     0     0]\n",
      " [ 1919   131     0     0]\n",
      " [ 2116  1104     0     0]\n",
      " [  102   286     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     44021\n",
      "           1       0.04      0.06      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.81      0.86      0.83     49679\n",
      "\n",
      "s_v\n",
      "[[41087  2934     0     0]\n",
      " [ 2014    36     0     0]\n",
      " [ 1190  2030     0     0]\n",
      " [  184   204     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.82      0.83      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42450  1571     0     0]\n",
      " [ 2021    29     0     0]\n",
      " [ 2802   418     0     0]\n",
      " [  273   115     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.23      0.24      0.24     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43205   816     0     0]\n",
      " [ 2009    41     0     0]\n",
      " [  855  2365     0     0]\n",
      " [  382     6     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     44021\n",
      "           1       0.01      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.82      0.87      0.85     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40634  3387     0     0]\n",
      " [ 1658   392     0     0]\n",
      " [  314  2906     0     0]\n",
      " [  239   149     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     44021\n",
      "           1       0.06      0.19      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.84      0.83      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40498  3523     0     0]\n",
      " [ 1988    62     0     0]\n",
      " [  522  2698     0     0]\n",
      " [  216   172     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.24      0.24     49679\n",
      "weighted avg       0.83      0.82      0.82     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38855  5166     0     0]\n",
      " [ 1715   335     0     0]\n",
      " [  912  2308     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90     44021\n",
      "           1       0.04      0.16      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.82      0.79      0.80     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-69a517207124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s_v\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"s_f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\feature_selection_ECG\\codes\\python\\TunedClassifier.py\u001b[0m in \u001b[0;36mrandomForest\u001b[1;34m(X_train, y_train, X_test, y_test, jk, n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, min_impurity_decrease, max_features, max_leaf_nodes, class_weight, labels)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "#y_train_b = np.copy(y_train)\n",
    "y_train[y_train == 3] = -1\n",
    "\n",
    "y_train[y_train == 2] = -1\n",
    "y_train[y_train >= 0] = 0\n",
    "\n",
    "y_train[y_train < 0] = 1\n",
    "#y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[41473  2548     0     0]\n",
      " [  959  1091     0     0]\n",
      " [  684  2536     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     44021\n",
      "           1       0.18      0.53      0.26      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.28      0.37      0.30     49679\n",
      "weighted avg       0.85      0.86      0.85     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40518  3503     0     0]\n",
      " [ 1951    99     0     0]\n",
      " [  316  2904     0     0]\n",
      " [  347    41     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.02      0.05      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.24      0.24      0.24     49679\n",
      "weighted avg       0.83      0.82      0.82     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34765  9256     0     0]\n",
      " [  645  1405     0     0]\n",
      " [ 1190  2030     0     0]\n",
      " [  351    37     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86     44021\n",
      "           1       0.11      0.69      0.19      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     49679\n",
      "   macro avg       0.26      0.37      0.26     49679\n",
      "weighted avg       0.84      0.73      0.77     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40372  3649     0     0]\n",
      " [ 1999    51     0     0]\n",
      " [  684  2536     0     0]\n",
      " [  238   150     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.83      0.81      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36534  7487     0     0]\n",
      " [ 1015  1035     0     0]\n",
      " [ 1487  1733     0     0]\n",
      " [   39   349     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     44021\n",
      "           1       0.10      0.50      0.16      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.26      0.33      0.26     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39405  4616     0     0]\n",
      " [ 1759   291     0     0]\n",
      " [  698  2522     0     0]\n",
      " [  379     9     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     44021\n",
      "           1       0.04      0.14      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.83      0.80      0.81     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43705   316     0     0]\n",
      " [ 1976    74     0     0]\n",
      " [ 2347   873     0     0]\n",
      " [  359    29     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95     44021\n",
      "           1       0.06      0.04      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.80      0.88      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43722   299     0     0]\n",
      " [ 2039    11     0     0]\n",
      " [  802  2418     0     0]\n",
      " [  353    35     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.00      0.01      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.83      0.88      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43921   100     0     0]\n",
      " [ 2015    35     0     0]\n",
      " [ 2406   814     0     0]\n",
      " [  384     4     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     44021\n",
      "           1       0.04      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.80      0.88      0.84     49679\n",
      "\n",
      "s_v\n",
      "[[43185   836     0     0]\n",
      " [ 2040    10     0     0]\n",
      " [ 1504  1716     0     0]\n",
      " [  299    89     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.81      0.87      0.84     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42507  1514     0     0]\n",
      " [ 2028    22     0     0]\n",
      " [ 2743   477     0     0]\n",
      " [  266   122     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43169   852     0     0]\n",
      " [ 2012    38     0     0]\n",
      " [ 1040  2180     0     0]\n",
      " [  384     4     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.87      0.84     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43509   512     0     0]\n",
      " [ 1861   189     0     0]\n",
      " [  341  2879     0     0]\n",
      " [  176   212     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     44021\n",
      "           1       0.05      0.09      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.84      0.88      0.86     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43211   810     0     0]\n",
      " [ 1849   201     0     0]\n",
      " [  590  2630     0     0]\n",
      " [  325    63     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     44021\n",
      "           1       0.05      0.10      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.25      0.27      0.26     49679\n",
      "weighted avg       0.84      0.87      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41445  2576     0     0]\n",
      " [ 1931   119     0     0]\n",
      " [ 1106  2114     0     0]\n",
      " [  362    26     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     44021\n",
      "           1       0.02      0.06      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.82      0.84      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40185  3836     0     0]\n",
      " [ 2040    10     0     0]\n",
      " [ 1115  2105     0     0]\n",
      " [  330    58     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.23      0.23      0.23     49679\n",
      "weighted avg       0.82      0.81      0.81     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42736  1285     0     0]\n",
      " [ 2032    18     0     0]\n",
      " [  857  2363     0     0]\n",
      " [  298    90     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     44021\n",
      "           1       0.00      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.23      0.24      0.24     49679\n",
      "weighted avg       0.82      0.86      0.84     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41428  2593     0     0]\n",
      " [ 1873   177     0     0]\n",
      " [  806  2414     0     0]\n",
      " [  343    45     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     44021\n",
      "           1       0.03      0.09      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.83      0.84      0.83     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_tr = StandardScaler()\n",
    "scale_te = StandardScaler()\n",
    "\n",
    "scale_tr.fit(X_train)\n",
    "scale_te.fit(X_test)\n",
    "X_train = scale_tr.transform(X_train)\n",
    "X_test = scale_te.transform(X_test)\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "\n",
    "   \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "\n",
    "y_train[y_train != 2] = 0\n",
    "y_train[y_train == 2] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "y7=classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])[2]\n",
    "\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 3] = 0\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[39498  4523     0     0]\n",
      " [  334  1716     0     0]\n",
      " [  835  2385     0     0]\n",
      " [  382     6     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     44021\n",
      "           1       0.20      0.84      0.32      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.29      0.43      0.31     49679\n",
      "weighted avg       0.86      0.83      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39498  4523     0     0]\n",
      " [ 1577   473     0     0]\n",
      " [ 1433  1787     0     0]\n",
      " [  286   102     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91     44021\n",
      "           1       0.07      0.23      0.11      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.25      0.28      0.25     49679\n",
      "weighted avg       0.82      0.80      0.81     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37951  6070     0     0]\n",
      " [ 1682   368     0     0]\n",
      " [ 2406   814     0     0]\n",
      " [  381     7     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88     44021\n",
      "           1       0.05      0.18      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.79      0.77      0.78     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33923 10098     0     0]\n",
      " [ 1570   480     0     0]\n",
      " [ 2283   937     0     0]\n",
      " [  376    12     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83     44021\n",
      "           1       0.04      0.23      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     49679\n",
      "   macro avg       0.23      0.25      0.22     49679\n",
      "weighted avg       0.79      0.69      0.73     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36183  7838     0     0]\n",
      " [ 1540   510     0     0]\n",
      " [ 1630  1590     0     0]\n",
      " [  360    28     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86     44021\n",
      "           1       0.05      0.25      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.24      0.27      0.24     49679\n",
      "weighted avg       0.81      0.74      0.77     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32397 11624     0     0]\n",
      " [ 1492   558     0     0]\n",
      " [ 1605  1615     0     0]\n",
      " [  375    13     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81     44021\n",
      "           1       0.04      0.27      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     49679\n",
      "   macro avg       0.24      0.25      0.22     49679\n",
      "weighted avg       0.80      0.66      0.72     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43515   506     0     0]\n",
      " [ 1785   265     0     0]\n",
      " [ 2999   221     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.27      0.13      0.17      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.29      0.28      0.28     49679\n",
      "weighted avg       0.80      0.88      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43932    89     0     0]\n",
      " [ 2043     7     0     0]\n",
      " [ 3185    35     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.05      0.00      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44007    14     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3212     8     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.23     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "s_v\n",
      "[[43973    48     0     0]\n",
      " [ 2050     0     0     0]\n",
      " [ 3100   120     0     0]\n",
      " [  386     2     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.00      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.22      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43999    22     0     0]\n",
      " [ 2049     1     0     0]\n",
      " [ 3198    22     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.02      0.00      0.00      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43992    29     0     0]\n",
      " [ 2044     6     0     0]\n",
      " [ 3136    84     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.05      0.00      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.89      0.83     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n",
      "[[43434   587     0     0]\n",
      " [ 1929   121     0     0]\n",
      " [ 3091   129     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.14      0.06      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.26      0.26      0.25     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43394   627     0     0]\n",
      " [ 1970    80     0     0]\n",
      " [ 3095   125     0     0]\n",
      " [  387     1     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93     44021\n",
      "           1       0.10      0.04      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.26      0.25     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43134   887     0     0]\n",
      " [ 2015    35     0     0]\n",
      " [ 3208    12     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     44021\n",
      "           1       0.04      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.79      0.87      0.83     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43844   177     0     0]\n",
      " [ 2035    15     0     0]\n",
      " [ 3214     6     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     44021\n",
      "           1       0.08      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43174   847     0     0]\n",
      " [ 1996    54     0     0]\n",
      " [ 3210    10     0     0]\n",
      " [  386     2     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     44021\n",
      "           1       0.06      0.03      0.04      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.79      0.87      0.83     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43653   368     0     0]\n",
      " [ 2011    39     0     0]\n",
      " [ 3205    15     0     0]\n",
      " [  388     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     44021\n",
      "           1       0.09      0.02      0.03      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.79      0.88      0.83     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "y_train[y_train != 1] = 0\n",
    "y_train[y_train == 1] = 1\n",
    "\n",
    "#y_test[y_test != 0] = 1\n",
    "#y_test[y_test == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[39472  4549     0     0]\n",
      " [  284  1766     0     0]\n",
      " [  370  2850     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     44021\n",
      "           1       0.19      0.86      0.31      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.29      0.44      0.31     49679\n",
      "weighted avg       0.87      0.83      0.84     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37167  6854     0     0]\n",
      " [ 1660   390     0     0]\n",
      " [  309  2911     0     0]\n",
      " [  297    91     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.04      0.19      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.25      0.26      0.24     49679\n",
      "weighted avg       0.84      0.76      0.79     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31049 12972     0     0]\n",
      " [  583  1467     0     0]\n",
      " [  859  2361     0     0]\n",
      " [  340    48     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81     44021\n",
      "           1       0.09      0.72      0.16      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     49679\n",
      "   macro avg       0.26      0.36      0.24     49679\n",
      "weighted avg       0.84      0.65      0.72     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34173  9848     0     0]\n",
      " [ 1970    80     0     0]\n",
      " [  181  3039     0     0]\n",
      " [  257   131     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85     44021\n",
      "           1       0.01      0.04      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     49679\n",
      "   macro avg       0.24      0.20      0.21     49679\n",
      "weighted avg       0.83      0.69      0.75     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37640  6381     0     0]\n",
      " [ 1289   761     0     0]\n",
      " [ 1194  2026     0     0]\n",
      " [  176   212     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89     44021\n",
      "           1       0.08      0.37      0.13      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     49679\n",
      "   macro avg       0.25      0.31      0.26     49679\n",
      "weighted avg       0.83      0.77      0.80     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36101  7920     0     0]\n",
      " [ 1523   527     0     0]\n",
      " [  366  2854     0     0]\n",
      " [  375    13     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88     44021\n",
      "           1       0.05      0.26      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.74      0.78     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42922  1099     0     0]\n",
      " [ 1595   455     0     0]\n",
      " [ 1772  1448     0     0]\n",
      " [  377    11     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     44021\n",
      "           1       0.15      0.22      0.18      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.27      0.30      0.28     49679\n",
      "weighted avg       0.82      0.87      0.85     49679\n",
      "\n",
      "n_v\n",
      "[[43559   462     0     0]\n",
      " [ 2028    22     0     0]\n",
      " [  853  2367     0     0]\n",
      " [  376    12     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.88      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43589   432     0     0]\n",
      " [ 1970    80     0     0]\n",
      " [ 2275   945     0     0]\n",
      " [  379     9     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95     44021\n",
      "           1       0.05      0.04      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.80      0.88      0.84     49679\n",
      "\n",
      "s_v\n",
      "[[41581  2440     0     0]\n",
      " [ 2026    24     0     0]\n",
      " [  822  2398     0     0]\n",
      " [  282   106     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     44021\n",
      "           1       0.00      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     49679\n",
      "   macro avg       0.23      0.24      0.24     49679\n",
      "weighted avg       0.82      0.84      0.83     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42174  1847     0     0]\n",
      " [ 2022    28     0     0]\n",
      " [ 2738   482     0     0]\n",
      " [  296    92     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.79      0.85      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43051   970     0     0]\n",
      " [ 2001    49     0     0]\n",
      " [  828  2392     0     0]\n",
      " [  383     5     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     44021\n",
      "           1       0.01      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.87      0.85     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n",
      "[[38897  5124     0     0]\n",
      " [ 1238   812     0     0]\n",
      " [  185  3035     0     0]\n",
      " [   30   358     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92     44021\n",
      "           1       0.09      0.40      0.14      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.26      0.32      0.27     49679\n",
      "weighted avg       0.86      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40001  4020     0     0]\n",
      " [ 1798   252     0     0]\n",
      " [  515  2705     0     0]\n",
      " [  309    79     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     44021\n",
      "           1       0.04      0.12      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.83      0.81      0.82     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38141  5880     0     0]\n",
      " [ 1678   372     0     0]\n",
      " [  810  2410     0     0]\n",
      " [  367    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90     44021\n",
      "           1       0.04      0.18      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.83      0.78      0.80     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "#y_train_b = np.copy(y_train)\n",
    "y_train[y_train == 2] = -2\n",
    "\n",
    "y_train[y_train == 1] = -1\n",
    "y_train[y_train >= 0] = 0\n",
    "\n",
    "y_train[y_train < 0] = 1\n",
    "#y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "#y_train[y_train == -2] = 2\n",
    "\n",
    "#y_train[y_train == -1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "all\n",
      "n_s\n",
      "[[38307  5714     0     0]\n",
      " [  585  1465     0     0]\n",
      " [  521  2699     0     0]\n",
      " [  367    21     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91     44021\n",
      "           1       0.15      0.71      0.25      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     49679\n",
      "   macro avg       0.28      0.40      0.29     49679\n",
      "weighted avg       0.86      0.80      0.82     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37361  6660     0     0]\n",
      " [ 1751   299     0     0]\n",
      " [  316  2904     0     0]\n",
      " [  294    94     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89     44021\n",
      "           1       0.03      0.15      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.83      0.76      0.79     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29186 14835     0     0]\n",
      " [  511  1539     0     0]\n",
      " [ 1015  2205     0     0]\n",
      " [  154   234     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.66      0.78     44021\n",
      "           1       0.08      0.75      0.15      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     49679\n",
      "   macro avg       0.26      0.35      0.23     49679\n",
      "weighted avg       0.84      0.62      0.70     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33839 10182     0     0]\n",
      " [ 1870   180     0     0]\n",
      " [  402  2818     0     0]\n",
      " [   19   369     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.84     44021\n",
      "           1       0.01      0.09      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     49679\n",
      "   macro avg       0.24      0.21      0.22     49679\n",
      "weighted avg       0.83      0.68      0.75     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35820  8201     0     0]\n",
      " [ 1093   957     0     0]\n",
      " [ 1263  1957     0     0]\n",
      " [   35   353     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87     44021\n",
      "           1       0.08      0.47      0.14      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.26      0.32      0.25     49679\n",
      "weighted avg       0.83      0.74      0.78     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36807  7214     0     0]\n",
      " [ 1569   481     0     0]\n",
      " [  367  2853     0     0]\n",
      " [  316    72     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89     44021\n",
      "           1       0.05      0.23      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.25      0.27      0.24     49679\n",
      "weighted avg       0.84      0.75      0.79     49679\n",
      "\n",
      "Lin\n",
      "all\n",
      "n_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43438   583     0     0]\n",
      " [ 1907   143     0     0]\n",
      " [ 2227   993     0     0]\n",
      " [  353    35     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94     44021\n",
      "           1       0.08      0.07      0.08      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.25      0.26      0.26     49679\n",
      "weighted avg       0.81      0.88      0.84     49679\n",
      "\n",
      "n_v\n",
      "[[43839   182     0     0]\n",
      " [ 2035    15     0     0]\n",
      " [  901  2319     0     0]\n",
      " [  378    10     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     49679\n",
      "   macro avg       0.23      0.25      0.24     49679\n",
      "weighted avg       0.82      0.88      0.85     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42372  1649     0     0]\n",
      " [ 1919   131     0     0]\n",
      " [ 2116  1104     0     0]\n",
      " [  102   286     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     44021\n",
      "           1       0.04      0.06      0.05      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.24      0.26      0.25     49679\n",
      "weighted avg       0.81      0.86      0.83     49679\n",
      "\n",
      "s_v\n",
      "[[41087  2934     0     0]\n",
      " [ 2014    36     0     0]\n",
      " [ 1190  2030     0     0]\n",
      " [  184   204     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     44021\n",
      "           1       0.01      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.23      0.24      0.23     49679\n",
      "weighted avg       0.82      0.83      0.82     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42450  1571     0     0]\n",
      " [ 2021    29     0     0]\n",
      " [ 2802   418     0     0]\n",
      " [  273   115     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93     44021\n",
      "           1       0.01      0.01      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     49679\n",
      "   macro avg       0.23      0.24      0.24     49679\n",
      "weighted avg       0.79      0.86      0.82     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43205   816     0     0]\n",
      " [ 2009    41     0     0]\n",
      " [  855  2365     0     0]\n",
      " [  382     6     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     44021\n",
      "           1       0.01      0.02      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.82      0.87      0.85     49679\n",
      "\n",
      "randomforest\n",
      "all\n",
      "n_s\n",
      "[[40609  3412     0     0]\n",
      " [ 1665   385     0     0]\n",
      " [  304  2916     0     0]\n",
      " [  237   151     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     44021\n",
      "           1       0.06      0.19      0.09      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     49679\n",
      "   macro avg       0.25      0.28      0.26     49679\n",
      "weighted avg       0.84      0.83      0.83     49679\n",
      "\n",
      "n_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40310  3711     0     0]\n",
      " [ 1993    57     0     0]\n",
      " [  522  2698     0     0]\n",
      " [  212   176     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     44021\n",
      "           1       0.01      0.03      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     49679\n",
      "   macro avg       0.24      0.24      0.23     49679\n",
      "weighted avg       0.83      0.81      0.82     49679\n",
      "\n",
      "n_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38955  5066     0     0]\n",
      " [ 1699   351     0     0]\n",
      " [  930  2290     0     0]\n",
      " [  369    19     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91     44021\n",
      "           1       0.05      0.17      0.07      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.24      0.26      0.24     49679\n",
      "weighted avg       0.82      0.79      0.81     49679\n",
      "\n",
      "s_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35770  8251     0     0]\n",
      " [ 2014    36     0     0]\n",
      " [  714  2506     0     0]\n",
      " [  254   134     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     44021\n",
      "           1       0.00      0.02      0.01      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     49679\n",
      "   macro avg       0.23      0.21      0.22     49679\n",
      "weighted avg       0.82      0.72      0.77     49679\n",
      "\n",
      "s_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42109  1912     0     0]\n",
      " [ 1975    75     0     0]\n",
      " [  865  2355     0     0]\n",
      " [  332    56     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     44021\n",
      "           1       0.02      0.04      0.02      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     49679\n",
      "   macro avg       0.24      0.25      0.24     49679\n",
      "weighted avg       0.82      0.85      0.84     49679\n",
      "\n",
      "v_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36631  7390     0     0]\n",
      " [ 1690   360     0     0]\n",
      " [  564  2656     0     0]\n",
      " [   37   351     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88     44021\n",
      "           1       0.03      0.18      0.06      2050\n",
      "           2       0.00      0.00      0.00      3220\n",
      "           3       0.00      0.00      0.00       388\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     49679\n",
      "   macro avg       0.24      0.25      0.23     49679\n",
      "weighted avg       0.84      0.74      0.79     49679\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "             criterion='gini', max_depth=16, max_features=10,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0001,\n",
       "             n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "             random_state=None, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]\n",
    "\n",
    "\n",
    "features_clinic,c_ID,f_M, f_V, f_d , norm_mlii, norm_v1 , norm_dtw = col.get_columns()\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "\n",
    "#y_train_b = np.copy(y_train)\n",
    "y_train[y_train == 2] = -2\n",
    "\n",
    "y_train[y_train == 3] = -1\n",
    "y_train[y_train >= 0] = 0\n",
    "\n",
    "y_train[y_train < 0] = 1\n",
    "#y_train_b[y_train_b == 2] = 1\n",
    "\n",
    "#y_train[y_train == -2] = 2\n",
    "\n",
    "#y_train[y_train == -1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"svm_linear\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_linear(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_linear(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_linear(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_linear(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_linear(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_linear(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_linear(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "print(\"svm_poly\")\n",
    "print(\"all\")\n",
    "classifier.svm_model_poly(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.svm_model_poly(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.svm_model_poly(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.svm_model_poly(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.svm_model_poly(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.svm_model_poly(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.svm_model_poly(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"xgboost\")\n",
    "print(\"all\")\n",
    "classifier.xgboost(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.xgboost(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.xgboost(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.xgboost(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.xgboost(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.xgboost(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.xgboost(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ada\")\n",
    "classifier.ada(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.ada(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.ada(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.ada(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.ada(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.ada(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.ada(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Log\")\n",
    "print(\"all\")\n",
    "#classifier.logisticRegress(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.logisticRegress(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.logisticRegress(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.logisticRegress(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.logisticRegress(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.logisticRegress(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.logisticRegress(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Lin\")\n",
    "print(\"all\")\n",
    "#classifier.Linear_D(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.Linear_D(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.Linear_D(X_train[n_v], y_train, X_test[n_v], y_test, jk=False ,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.Linear_D(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.Linear_D(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.Linear_D(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.Linear_D(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "\n",
    "print(\"randomforest\")\n",
    "print(\"all\")\n",
    "#classifier.randomForest(X_train[feature_good], y_train, X_test[feature_good], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_s\")\n",
    "classifier.randomForest(X_train[n_s], y_train, X_test[n_s], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_v\")\n",
    "classifier.randomForest(X_train[n_v], y_train, X_test[n_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"n_f\")\n",
    "classifier.randomForest(X_train[n_f], y_train, X_test[n_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_v\")\n",
    "classifier.randomForest(X_train[s_v], y_train, X_test[s_v], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"s_f\")\n",
    "classifier.randomForest(X_train[s_f], y_train, X_test[s_f], y_test, jk=False,labels=[0,1,2,3])\n",
    "print(\"v_f\")\n",
    "classifier.randomForest(X_train[v_f], y_train, X_test[v_f], y_test, jk=False,labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
