{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_DF_beats as DF\n",
    "import numpy as np\n",
    "from codes.python import metric\n",
    "from codes. python import post_process_features_ex as post_features\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "ls = []\n",
    "ls.extend(['N', 'L', 'R'])                    # N\n",
    "ls.extend(['A', 'a', 'J', 'S', 'e', 'j'])     # SVEB \n",
    "ls.extend(['V', 'E'])                         # VEB\n",
    "ls.extend(['F'])\n",
    "#ls.extend([ 'P', '/', 'f', 'u'])\n",
    "patient_l_1 = [101]\n",
    "#patient_l_2 = [100]\n",
    "patient_ls_1 = [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]\n",
    "patient_ls_2 = [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]\n",
    "\n",
    "\n",
    "ls2 = []\n",
    "ls2.extend([\"['N']\",\"['L']\", \"['R']\"])                    # N\n",
    "ls2.extend([\"['A']\", \"['a']\", \"['J']\", \"['S']\",  \"['e']\", \"['j']\"])     # SVEB \n",
    "ls2.extend([\"['V']\", \"['E']\"])                         # VEB\n",
    "ls2.extend([\"['F']\"])\n",
    "#ls.extend([ \"['P']\",\"[ '/']\",\" ['f']\", \"['u']\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_clinic_1_old, np_clinic_2_old,np_non_var_1_old, np_non_var_2_old, np_class_ID_1_old, np_class_ID_2_old, patients_ls_1, patients_ls_2, DB1, DB2, DB1_V1, DB2_V1, DB1_non_cli, DB2_non_cli, DB1_dwt, DB2_dwt, DB1_dwt_V1, DB2_dwt_V1 = DF.get_all_dataframe(patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done norm\n",
      "row 0 done\n",
      "done norm\n",
      "row 1 done\n"
     ]
    }
   ],
   "source": [
    "np_clinic_1, np_clinic_2,np_non_var_1, np_non_var_2, np_class_ID_1, np_class_ID_2 = DF.get_all_dataframe_patient_specific(200,patient_l_1=patient_ls_1,patient_l_2=patient_ls_2 , ls=ls, ls2=ls2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1_old = [int(i) for i in np_class_ID_1_old]\n",
    "np_class_ID_2_old = [int(i) for i in np_class_ID_2_old]\n",
    "X_train = np_clinic_1_old\n",
    "X_test = np_clinic_2_old\n",
    "y_train = np.asarray(np_class_ID_1_old)\n",
    "y_test = np.asarray(np_class_ID_2_old)\n",
    "input_size=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_class_ID_1 = [int(i) for i in np_class_ID_1]\n",
    "np_class_ID_2 = [int(i) for i in np_class_ID_2]\n",
    "\n",
    "X_train = np_clinic_1\n",
    "X_test = np_clinic_2\n",
    "y_train = np.asarray(np_class_ID_1)\n",
    "y_test = np.asarray(np_class_ID_2)\n",
    "input_size=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "\n",
    "np_clinic_1_class = np.hstack((y_train,X_train))\n",
    "#np_clinic_2_class = np.hstack((np_class_ID_2,np_clinic_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = [\"R_duration\", \"R_height\", \"R_amp0\", \"R_amp1\",\"R_amp2\",\"R_amp3\", \"R_amp4\", \"R_amp5\", \"R_amp6\", \"R_amp7\", \"R_amp8\", \"R_amp9\", \"R_prominence\",\"R_areas\",\"Q_duration\", \"Q_height\", \"Q_amp0\", \"Q_amp1\",\"Q_amp2\",\"Q_amp3\", \"Q_amp4\", \"Q_amp5\", \"Q_amp6\", \"Q_amp7\", \"Q_amp8\", \"Q_amp9\", \"Q_prominence\",\"Q_areas\", \"S_duration\", \"S_height\", \"S_amp0\", \"S_amp1\",\"S_amp2\",\"S_amp3\", \"S_amp4\", \"S_amp5\", \"S_amp6\", \"S_amp7\", \"S_amp8\", \"S_amp9\", \"S_prominence\",\"S_areas\", \"P_duration\", \"P_height\", \"P_amp0\", \"P_amp1\",\"P_amp2\",\"P_amp3\", \"P_amp4\", \"P_amp5\", \"P_amp6\", \"P_amp7\", \"P_amp8\", \"P_amp9\", \"P_prominence\",\"P_areas\", \"P_neg_duration\", \"P_neg_height\", \"P_neg_amp0\", \"P_neg_amp1\",\"P_neg_amp2\",\"P_neg_amp3\", \"P_neg_amp4\", \"P_neg_amp5\", \"P_neg_amp6\", \"P_neg_amp7\", \"P_neg_amp8\", \"P_neg_amp9\", \"P_neg_prominence\",\"P_neg_areas\", \"T_duration\", \"T_height\", \"T_amp0\", \"T_amp1\",\"T_amp2\",\"T_amp3\", \"T_amp4\", \"T_amp5\", \"T_amp6\", \"T_amp7\", \"T_amp8\", \"T_amp9\", \"T_prominence\",\"T_areas\",\"T_neg_durations\",\"T_neg_height\", \"T_neg_amp0\", \"T_neg_amp1\", \"T_neg_amp2\", \"T_neg_amp3\", \"T_neg_amp4\", \"T_neg_amp5\", \"T_neg_amp6\", \"T_neg_amp7\", \"T_neg_amp8\", \"T_neg_amp9\",\"T_neg_prominence\",\"T_neg_areas\", \"rr_int_pre\", \"rr_int_post\", \"rr_int_10\", \"rr_int_50\", \"rr_int_all\", \"QRS_int\", \"QRS_int_10\", \"QRS_int_50\", \"PQ_int\", \"PQ_int_10\", \"PQ_int_50\", \"PR_int\", \"PR_int_10\", \"PR_int_50\", \"ST_int\", \"ST_int_10\", \"ST_int_50\", \"RT_int\", \"RT_int_10\", \"RT_int_50\", \"PT_int\", \"PT_int_10\", \"PT_int_50\", \"RP\",\"TR\",\"neg_RQ\", \"neg_PR\", \"neg_ST\", \"neg_RT\", \"neg_PT\", \"P_neg_T\", \"neg_P_neg_T\"]\n",
    "feat_labels_V = [\"R_duration_V\", \"R_height_V\", \"R_amp0_V\", \"R_amp1_V\",\"R_amp2_V\",\"R_amp3_V\", \"R_amp4_V\", \"R_amp5_V\", \"R_amp6_V\", \"R_amp7_V\", \"R_amp8_V\", \"R_amp9_V\", \"R_prominence_V\",\"R_areas_V\",\"Q_duration_V\", \"Q_height_V\", \"Q_amp0_V\", \"Q_amp1_V\",\"Q_amp2_V\",\"Q_amp3_V\", \"Q_amp4_V\", \"Q_amp5_V\", \"Q_amp6_V\", \"Q_amp7_V\", \"Q_amp8_V\", \"Q_amp9_V\", \"Q_prominence_V\",\"Q_areas_V\", \"S_duration_V\", \"S_height_V\", \"S_amp0_V\", \"S_amp1_V\",\"S_amp2_V\",\"S_amp3_V\", \"S_amp4_V\", \"S_amp5_V\", \"S_amp6_V\", \"S_amp7_V\", \"S_amp8_V\", \"S_amp9_V\", \"S_prominence_V\",\"S_areas_V\", \"P_duration_V\", \"P_height_V\", \"P_amp0_V\", \"P_amp1_V\",\"P_amp2_V\",\"P_amp3_V\", \"P_amp4_V\", \"P_amp5_V\", \"P_amp6_V\", \"P_amp7_V\", \"P_amp8_V\", \"P_amp9_V\", \"P_prominence_V\",\"P_areas_V\", \"P_neg_duration_V\", \"P_neg_height_V\", \"P_neg_amp0_V\", \"P_neg_amp1_V\",\"P_neg_amp2_V\",\"P_neg_amp3_V\", \"P_neg_amp4_V\", \"P_neg_amp5_V\", \"P_neg_amp6_V\", \"P_neg_amp7_V\", \"P_neg_amp8_V\", \"P_neg_amp9_V\", \"P_neg_prominence_V\",\"P_neg_areas_V\", \"T_duration_V\", \"T_height_V\", \"T_amp0_V\", \"T_amp1_V\",\"T_amp2_V\",\"T_amp3_V\", \"T_amp4_V\", \"T_amp5_V\", \"T_amp6_V\", \"T_amp7_V\", \"T_amp8_V\", \"T_amp9_V\", \"T_prominence_V\",\"T_areas_V\",\"T_neg_durations_V\",\"T_neg_height_V\", \"T_neg_amp0_V\", \"T_neg_amp1_V\", \"T_neg_amp2_V\", \"T_neg_amp3_V\", \"T_neg_amp4_V\", \"T_neg_amp5_V\", \"T_neg_amp6_V\", \"T_neg_amp7_V\", \"T_neg_amp8_V\", \"T_neg_amp9_V\",\"T_neg_prominence_V\",\"T_neg_areas_V\", \"rr_int_pre_V\", \"rr_int_post_V\", \"rr_int_10_V\", \"rr_int_50_V\", \"rr_int_all_V\", \"QRS_int_V\", \"QRS_int_10_V\", \"QRS_int_50_V\", \"PQ_int_V\", \"PQ_int_10_V\", \"PQ_int_50_V\", \"PR_int_V\", \"PR_int_10_V\", \"PR_int_50_V\", \"ST_int_V\", \"ST_int_10_V\", \"ST_int_50_V\", \"RT_int_V\", \"RT_int_10_V\", \"RT_int_50_V\", \"PT_int_V\", \"PT_int_10_V\", \"PT_int_50_V\", \"RP_V\",\"TR_V\",\"neg_RQ_V\", \"neg_PR_V\", \"neg_ST_V\", \"neg_RT_V\", \"neg_PT_V\", \"P_neg_T_V\", \"neg_P_neg_T_V\"]\n",
    "feat_labels_dtw = [\"dtw1\",\"dtw2\"]\n",
    "norm_dtw = [\"dtw1_v1\",\"dtw2_v1\"]\n",
    "classID = [\"classID\"]\n",
    "non_clinic = list(DB1_non_cli.iloc[:,0:140].columns.values)\n",
    "\n",
    "feature_norm_mill = []\n",
    "for i in range(len(feat_labels)):\n",
    "    feature_norm_mill.append(str(feat_labels[i]+\"_n_MLII\"))\n",
    "\n",
    "feature_norm_V1 = []\n",
    "for i in range(len(feat_labels)):\n",
    "    feature_norm_V1.append(str(feat_labels[i]+\"_n_V1\"))\n",
    "    \n",
    "\n",
    "c_ID = np.asarray(classID)\n",
    "f_M = np.asarray(feat_labels)\n",
    "f_V = np.asarray(feat_labels_V)\n",
    "f_d = np.asarray(feat_labels_dtw)\n",
    "non_cli = np.asarray(non_clinic)\n",
    "norm_mlii = np.asarray(feature_norm_mill)\n",
    "norm_v1 = np.asarray(feature_norm_V1)\n",
    "norm_dtw = np.asarray(norm_dtw)\n",
    "\n",
    "features_clinic_with_class = np.hstack((c_ID,f_M,f_V, f_d))\n",
    "\n",
    "\n",
    "features_clinic = np.hstack((f_M,f_V, f_d))\n",
    "features_clinic_norm = np.hstack((f_M,f_V, f_d,norm_mlii,norm_v1,norm_dtw ))\n",
    "#row=[]\n",
    "#for i in range(0,len(np_clinic_new_1)):\n",
    "    #row.append(i)\n",
    "    \n",
    "X_train_balanced = pd.DataFrame(good_features_X,columns=features_clinic)\n",
    "X_train = pd.DataFrame(X_train,columns=features_clinic)\n",
    "X_test = pd.DataFrame(X_test,columns=features_clinic)\n",
    "\n",
    "#X_train_balanced_norm = pd.DataFrame(X_train_norm,columns=features_clinic_norm)\n",
    "#X_test_norm = pd.DataFrame(X_test_norm,columns=features_clinic_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np_clinic_1_class,columns=features_clinic_with_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymrmr as mrmr\n",
    "\n",
    "rank=mrmr.mRMR(df, 'MID', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtw1',\n",
       " 'QRS_int_50_V',\n",
       " 'R_amp0_V',\n",
       " 'PQ_int_V',\n",
       " 'neg_ST_V',\n",
       " 'neg_RT_V',\n",
       " 'PQ_int_10_V',\n",
       " 'T_amp6',\n",
       " 'T_neg_durations_V',\n",
       " 'PR_int_50_V',\n",
       " 'QRS_int_10_V',\n",
       " 'QRS_int_V',\n",
       " 'T_neg_areas_V',\n",
       " 'PQ_int_50_V',\n",
       " 'TR_V',\n",
       " 'R_amp0',\n",
       " 'PR_int_V',\n",
       " 'S_amp0',\n",
       " 'PT_int_10_V',\n",
       " 'RT_int_10_V',\n",
       " 'neg_PR_V',\n",
       " 'RP_V',\n",
       " 'T_amp8',\n",
       " 'T_amp6_V',\n",
       " 'PT_int_50_V',\n",
       " 'PR_int_10_V',\n",
       " 'R_amp1_V',\n",
       " 'RT_int_50_V',\n",
       " 'neg_RQ_V',\n",
       " 'RT_int_V',\n",
       " 'ST_int_50_V',\n",
       " 'ST_int_V',\n",
       " 'T_amp7',\n",
       " 'ST_int_10_V',\n",
       " 'R_duration',\n",
       " 'T_areas_V',\n",
       " 'QRS_int',\n",
       " 'QRS_int_10',\n",
       " 'T_areas',\n",
       " 'T_neg_durations',\n",
       " 'T_neg_areas',\n",
       " 'dtw2',\n",
       " 'P_neg_areas',\n",
       " 'P_neg_prominence',\n",
       " 'QRS_int_50',\n",
       " 'PQ_int',\n",
       " 'PQ_int_10',\n",
       " 'T_duration',\n",
       " 'T_amp4',\n",
       " 'PR_int']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n vs all results for various classifier\n",
      "SVM\n",
      "[[34986   635  3908  4492]\n",
      " [  502  1336   122    90]\n",
      " [  198    51  2525   446]\n",
      " [   26     0     7   355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88     44021\n",
      "           1       0.66      0.65      0.66      2050\n",
      "           2       0.38      0.78      0.52      3220\n",
      "           3       0.07      0.91      0.12       388\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     49679\n",
      "   macro avg       0.52      0.79      0.54     49679\n",
      "weighted avg       0.92      0.79      0.84     49679\n",
      "\n",
      "[0.4007485524244452, 2.4813919785105343, 0.5105482735260394]\n",
      "XGboost\n",
      "[[32504  3265  5083  3169]\n",
      " [ 1605   356    65    24]\n",
      " [   98   100  2960    62]\n",
      " [   13     1   288    86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     44021\n",
      "           1       0.10      0.17      0.12      2050\n",
      "           2       0.35      0.92      0.51      3220\n",
      "           3       0.03      0.22      0.05       388\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     49679\n",
      "   macro avg       0.36      0.51      0.38     49679\n",
      "weighted avg       0.87      0.72      0.77     49679\n",
      "\n",
      "[0.260806870366151, 1.541109529091336, 0.3230421263194925]\n",
      "Logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27124  6324  3569  7004]\n",
      " [ 1548   366    47    89]\n",
      " [   56   367  2639   158]\n",
      " [   10     6    17   355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75     44021\n",
      "           1       0.05      0.18      0.08      2050\n",
      "           2       0.42      0.82      0.56      3220\n",
      "           3       0.05      0.91      0.09       388\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     49679\n",
      "   macro avg       0.37      0.63      0.37     49679\n",
      "weighted avg       0.87      0.61      0.70     49679\n",
      "\n",
      "[0.18168090715241353, 1.4706800715522876, 0.2746754625202427]\n",
      "Linear_D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23977  9263  2018  8763]\n",
      " [ 1529   429    26    66]\n",
      " [  180   422  2374   244]\n",
      " [   11    10    11   356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.69     44021\n",
      "           1       0.04      0.21      0.07      2050\n",
      "           2       0.54      0.74      0.62      3220\n",
      "           3       0.04      0.92      0.07       388\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     49679\n",
      "   macro avg       0.39      0.60      0.36     49679\n",
      "weighted avg       0.86      0.55      0.65     49679\n",
      "\n",
      "[0.13728121179103422, 1.5249225728776072, 0.25925592750521803]\n",
      "SVM_LN\n",
      "[[30477  4400  3510  5634]\n",
      " [ 1629   282    65    74]\n",
      " [  189   492  2362   177]\n",
      " [   12     5    21   350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.69      0.80     44021\n",
      "           1       0.05      0.14      0.08      2050\n",
      "           2       0.40      0.73      0.51      3220\n",
      "           3       0.06      0.90      0.11       388\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     49679\n",
      "   macro avg       0.36      0.62      0.37     49679\n",
      "weighted avg       0.86      0.67      0.75     49679\n",
      "\n",
      "[0.20560315239852295, 1.3219937734118536, 0.26805079787574315]\n",
      "voting_ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30411  4603  3434  5573]\n",
      " [ 1606   336    49    59]\n",
      " [   81   312  2682   145]\n",
      " [   12     4    23   349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80     44021\n",
      "           1       0.06      0.16      0.09      2050\n",
      "           2       0.43      0.83      0.57      3220\n",
      "           3       0.06      0.90      0.11       388\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     49679\n",
      "   macro avg       0.38      0.65      0.39     49679\n",
      "weighted avg       0.87      0.68      0.75     49679\n",
      "\n",
      "[0.2266152750072726, 1.4941803209512923, 0.30008017762254785]\n",
      "ada\n",
      "Linear_d all samples\n",
      "[[38038   211  2301  3471]\n",
      " [ 1946    45    12    47]\n",
      " [  543   157  2283   237]\n",
      " [   20     3    16   349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     44021\n",
      "           1       0.11      0.02      0.04      2050\n",
      "           2       0.50      0.71      0.58      3220\n",
      "           3       0.09      0.90      0.16       388\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     49679\n",
      "   macro avg       0.41      0.62      0.42     49679\n",
      "weighted avg       0.87      0.82      0.84     49679\n",
      "\n",
      "[0.3311343623044848, 1.3341435171557259, 0.33233512079670813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 0.33233512079670813)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"n vs all results for various classifier\")\n",
    "\n",
    "\n",
    "#Linear_D(train, train_labels, test, test_labels, labels=['N','S','V','F'])\n",
    "print(\"SVM\")\n",
    "svm_model_poly(good_features_X, good_features_y,X_test , y_test, labels=[0,1,2,3])\n",
    "print(\"XGboost\")\n",
    "xgboost(np.asarray(X_train_balanced[rank]), good_features_y, np.asarray(X_test[rank]), y_test, labels=[0,1,2,3])\n",
    "#svm_model_poly(X_train_df[df[df['rfscore'] >= score]['features'].values], good_features_y,X_test_df[df[df['rfscore'] >= score]['features'].values] , y_test, labels=[0,1,2,3])[0]\n",
    "print(\"Logistic\")\n",
    "logisticRegress(X_train_balanced[rank], good_features_y, X_test[rank], y_test, labels=[0,1,2,3])\n",
    "print(\"Linear_D\")\n",
    "Linear_D(X_train_balanced[rank], good_features_y, X_test[rank], y_test,  labels=[0,1,2,3])\n",
    "#ada(X_train_df[rank['features'].values], good_features_y, X_test_df[rank['features'].values], y_test,  labels=[0,1,2,3])\n",
    "print(\"SVM_LN\")\n",
    "svm_model_linear(np.asarray(X_train_balanced[rank]), good_features_y, np.asarray(X_test[rank]), y_test,  labels=[0,1,2,3])\n",
    "print(\"voting_ensemble\")\n",
    "voting_ensemble(np.asarray(X_train_balanced[rank]), good_features_y,np.asarray( X_test[rank]), y_test,  labels=[0,1,2,3])\n",
    "print(\"ada\")\n",
    "\n",
    "#ada(np.asarray(X_train_balanced[n_s]), good_features_y,np.asarray( X_test[n_s]), y_test,  labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "#print(\"voting_ensemble\")\n",
    "\n",
    "#voting_ensemble(good_features_X, good_features_y,np.asarray(X_test) , y_test, labels=[0,1,2,3])\n",
    "\n",
    "#feature_good = rank[rank['rfscore'] >= score]['features'].values\n",
    "\n",
    "print(\"Linear_d all samples\")\n",
    "Linear_D(X_train[rank], y_train, X_test[rank], y_test, labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chont\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34058  2055  4191  3717]\n",
      " [ 1702   246    51    51]\n",
      " [  321   160  2586   153]\n",
      " [   18     3    28   339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85     44021\n",
      "           1       0.10      0.12      0.11      2050\n",
      "           2       0.38      0.80      0.51      3220\n",
      "           3       0.08      0.87      0.15       388\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     49679\n",
      "   macro avg       0.38      0.64      0.40     49679\n",
      "weighted avg       0.87      0.75      0.79     49679\n",
      "\n",
      "[0.272441688453433, 1.4001311170438815, 0.3112372338572017]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=10, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "           solver='warn', tol=0.0001, verbose=0, warm_start=False),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 0.3112372338572017)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegress(X_train[rank[0:20]], y_train, X_test[rank[0:20]], y_test, labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_features\n",
    "\n",
    "1        261     dtw1    0.179\n",
    "2        246     RT_int_V        0.000\n",
    "3        93      T_neg_amp6      0.012\n",
    "4        82      T_amp9          0.009\n",
    "5        3       R_amp0          0.012\n",
    "6        133     R_amp0_V        0.009\n",
    "7        31      S_amp0          0.003\n",
    "8        94      T_neg_amp7      0.006\n",
    "9        262     dtw2    0.015\n",
    "10       81      T_amp8          0.005\n",
    "11       92      T_neg_amp5      0.003\n",
    "12       129     P_neg_T         0.003\n",
    "13       73      T_amp0          0.004\n",
    "14       88      T_neg_amp1      0.004\n",
    "15       99      rr_int_pre      0.003\n",
    "16       91      T_neg_amp4      0.004\n",
    "17       80      T_amp7          0.005\n",
    "18       87      T_neg_amp0      0.003\n",
    "19       74      T_amp1          0.003\n",
    "20       23      Q_amp6          0.003\n",
    "\n",
    "\n",
    "rank20_all = ['dtw1',\n",
    "     'RT_int_V',\n",
    "     'T_neg_amp6',\n",
    "     'T_amp9',\n",
    "     'R_amp0',\n",
    "     'R_amp0_V',\n",
    "     'S_amp0',\n",
    "     'T_neg_amp7',\n",
    "     'dtw2',\n",
    "     'T_amp8',\n",
    "     'T_neg_amp5',\n",
    "     'P_neg_T',\n",
    "     'T_amp0',\n",
    "     'T_neg_amp1',\n",
    "     'rr_int_pre',\n",
    "     'T_neg_amp4',\n",
    "     'T_amp7',\n",
    "     'T_neg_amp0',\n",
    "     'T_amp1',\n",
    "     'Q_amp6']\n",
    "\n",
    "\n",
    "['dtw1',\n",
    " 'PT_int_10_V',\n",
    " 'R_amp0_V',\n",
    " 'T_amp6',\n",
    " 'T_neg_amp6',\n",
    " 'R_amp0',\n",
    " 'P_neg_T',\n",
    " 'dtw2',\n",
    " 'T_amp7',\n",
    " 'T_neg_amp4',\n",
    " 'T_neg_amp1',\n",
    " 'T_amp4',\n",
    " 'rr_int_post_V',\n",
    " 'T_neg_amp7',\n",
    " 'T_amp5',\n",
    " 'S_amp0',\n",
    " 'T_neg_amp5',\n",
    " 'T_amp8',\n",
    " 'T_neg_amp2',\n",
    " 'T_prominence',\n",
    " 'T_neg_amp9',\n",
    " 'T_amp3',\n",
    " 'T_neg_amp3',\n",
    " 'R_amp5_V',\n",
    " 'T_amp9',\n",
    " 'neg_P_neg_T',\n",
    " 'T_neg_amp0',\n",
    " 'T_amp2',\n",
    " 'T_neg_amp8',\n",
    " 'Q_amp3',\n",
    " 'T_amp1',\n",
    " 'PT_int',\n",
    " 'T_amp0',\n",
    " 'R_prominence_V',\n",
    " 'S_amp1',\n",
    " 'T_neg_prominence',\n",
    " 'T_height',\n",
    " 'T_neg_height',\n",
    " 'Q_amp9',\n",
    " 'R_amp1',\n",
    " 'rr_int_pre',\n",
    " 'T_amp6_V',\n",
    " 'R_amp1_V',\n",
    " 'Q_amp0',\n",
    " 'neg_PT',\n",
    " 'S_amp9_V',\n",
    " 'Q_amp9_V',\n",
    " 'Q_amp1',\n",
    " 'T_amp5_V',\n",
    " 'P_amp6']\n",
    "\n",
    "\n",
    "\n",
    "*** mRMR features ***\n",
    "Order    Fea     Name    Score\n",
    "1        261     dtw1    0.187\n",
    "2        250     PT_int_10_V     0.000\n",
    "3        133     R_amp0_V        0.012\n",
    "4        79      T_amp6          0.012\n",
    "5        93      T_neg_amp6      0.017\n",
    "6        3       R_amp0          0.010\n",
    "7        129     P_neg_T         0.005\n",
    "8        262     dtw2    0.020\n",
    "9        80      T_amp7          0.005\n",
    "10       91      T_neg_amp4      0.007\n",
    "11       88      T_neg_amp1      0.003\n",
    "12       77      T_amp4          0.004\n",
    "13       230     rr_int_post_V   0.003\n",
    "14       94      T_neg_amp7      0.004\n",
    "15       78      T_amp5          0.004\n",
    "16       31      S_amp0          0.004\n",
    "17       92      T_neg_amp5      0.005\n",
    "18       81      T_amp8          0.004\n",
    "19       89      T_neg_amp2      0.004\n",
    "20       83      T_prominence    0.003\n",
    "21       96      T_neg_amp9      0.003\n",
    "22       76      T_amp3          0.004\n",
    "23       90      T_neg_amp3      0.003\n",
    "24       138     R_amp5_V        0.003\n",
    "25       82      T_amp9          0.003\n",
    "26       130     neg_P_neg_T     0.003\n",
    "27       87      T_neg_amp0      0.004\n",
    "28       75      T_amp2          0.003\n",
    "29       95      T_neg_amp8      0.003\n",
    "30       20      Q_amp3          0.003\n",
    "31       74      T_amp1          0.003\n",
    "32       119     PT_int          0.003\n",
    "33       73      T_amp0          0.002\n",
    "34       143     R_prominence_V          0.003\n",
    "35       32      S_amp1          0.002\n",
    "36       97      T_neg_prominence        0.002\n",
    "37       72      T_height        0.002\n",
    "38       86      T_neg_height    0.002\n",
    "39       26      Q_amp9          0.002\n",
    "40       4       R_amp1          0.002\n",
    "41       99      rr_int_pre      0.002\n",
    "42       209     T_amp6_V        0.001\n",
    "43       134     R_amp1_V        0.002\n",
    "44       17      Q_amp0          0.001\n",
    "45       128     neg_PT          0.001\n",
    "46       170     S_amp9_V        0.001\n",
    "47       156     Q_amp9_V        0.001\n",
    "48       18      Q_amp1          0.001\n",
    "49       208     T_amp5_V        0.001\n",
    "50       51      P_amp6          0.001\n",
    "\n",
    "\n",
    "[[37065   240  3199  3517]\n",
    " [ 1568   230   220    32]\n",
    " [  418   263  2301   238]\n",
    " [   65     0    24   299]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.84      0.89     44021\n",
    "           1       0.31      0.11      0.17      2050\n",
    "           2       0.40      0.71      0.51      3220\n",
    "           3       0.07      0.77      0.13       388\n",
    "\n",
    "   micro avg       0.80      0.80      0.80     49679\n",
    "   macro avg       0.43      0.61      0.43     49679\n",
    "weighted avg       0.88      0.80      0.83     49679\n",
    "\n",
    "[0.3291050051577591, 1.5411623076989205, 0.3571977910412446]\n",
    "\n",
    "\n",
    "\n",
    "n_f\n",
    "\n",
    "['dtw1',\n",
    " 'QRS_int_50_V',\n",
    " 'R_amp0_V',\n",
    " 'PQ_int_V',\n",
    " 'neg_ST_V',\n",
    " 'neg_RT_V',\n",
    " 'PQ_int_10_V',\n",
    " 'T_amp6',\n",
    " 'T_neg_durations_V',\n",
    " 'PR_int_50_V',\n",
    " 'QRS_int_10_V',\n",
    " 'QRS_int_V',\n",
    " 'T_neg_areas_V',\n",
    " 'PQ_int_50_V',\n",
    " 'TR_V',\n",
    " 'R_amp0',\n",
    " 'PR_int_V',\n",
    " 'S_amp0',\n",
    " 'PT_int_10_V',\n",
    " 'RT_int_10_V',\n",
    " 'neg_PR_V',\n",
    " 'RP_V',\n",
    " 'T_amp8',\n",
    " 'T_amp6_V',\n",
    " 'PT_int_50_V',\n",
    " 'PR_int_10_V',\n",
    " 'R_amp1_V',\n",
    " 'RT_int_50_V',\n",
    " 'neg_RQ_V',\n",
    " 'RT_int_V',\n",
    " 'ST_int_50_V',\n",
    " 'ST_int_V',\n",
    " 'T_amp7',\n",
    " 'ST_int_10_V',\n",
    " 'R_duration',\n",
    " 'T_areas_V',\n",
    " 'QRS_int',\n",
    " 'QRS_int_10',\n",
    " 'T_areas',\n",
    " 'T_neg_durations',\n",
    " 'T_neg_areas',\n",
    " 'dtw2',\n",
    " 'P_neg_areas',\n",
    " 'P_neg_prominence',\n",
    " 'QRS_int_50',\n",
    " 'PQ_int',\n",
    " 'PQ_int_10',\n",
    " 'T_duration',\n",
    " 'T_amp4',\n",
    " 'PR_int']\n",
    "\n",
    "\n",
    "Order    Fea     Name    Score\n",
    "1        261     dtw1    0.025\n",
    "2        236     QRS_int_50_V    -0.000\n",
    "3        133     R_amp0_V        0.001\n",
    "4        237     PQ_int_V        -0.000\n",
    "5        256     neg_ST_V        -0.000\n",
    "6        257     neg_RT_V        -0.000\n",
    "7        238     PQ_int_10_V     -0.000\n",
    "8        79      T_amp6          0.000\n",
    "9        215     T_neg_durations_V       -0.000\n",
    "10       242     PR_int_50_V     -0.000\n",
    "11       235     QRS_int_10_V    -0.000\n",
    "12       234     QRS_int_V       -0.000\n",
    "13       228     T_neg_areas_V   -0.000\n",
    "14       239     PQ_int_50_V     -0.000\n",
    "15       253     TR_V    -0.000\n",
    "16       3       R_amp0          0.000\n",
    "17       240     PR_int_V        -0.000\n",
    "18       31      S_amp0          0.000\n",
    "19       250     PT_int_10_V     -0.000\n",
    "20       247     RT_int_10_V     -0.000\n",
    "21       255     neg_PR_V        -0.000\n",
    "22       252     RP_V    -0.000\n",
    "23       81      T_amp8          0.000\n",
    "24       209     T_amp6_V        0.000\n",
    "25       251     PT_int_50_V     -0.000\n",
    "26       241     PR_int_10_V     -0.000\n",
    "27       134     R_amp1_V        0.000\n",
    "28       248     RT_int_50_V     -0.000\n",
    "29       254     neg_RQ_V        -0.000\n",
    "30       246     RT_int_V        -0.000\n",
    "31       245     ST_int_50_V     -0.000\n",
    "32       243     ST_int_V        -0.000\n",
    "33       80      T_amp7          0.000\n",
    "34       244     ST_int_10_V     -0.000\n",
    "35       1       R_duration      -0.000\n",
    "36       214     T_areas_V       -0.000\n",
    "37       104     QRS_int         -0.000\n",
    "38       105     QRS_int_10      -0.000\n",
    "39       84      T_areas         -0.000\n",
    "40       85      T_neg_durations         -0.000\n",
    "41       98      T_neg_areas     -0.000\n",
    "42       262     dtw2    0.000\n",
    "43       70      P_neg_areas     -0.000\n",
    "44       69      P_neg_prominence        -0.000\n",
    "45       106     QRS_int_50      -0.000\n",
    "46       107     PQ_int          -0.000\n",
    "47       108     PQ_int_10       -0.000\n",
    "48       71      T_duration      -0.000\n",
    "49       77      T_amp4          0.000\n",
    "50       110     PR_int          -0.000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s\n",
    "\n",
    "['dtw1',\n",
    " 'RT_int_V',\n",
    " 'neg_ST',\n",
    " 'PT_int',\n",
    " 'TR_V',\n",
    " 'PQ_int',\n",
    " 'Q_amp3',\n",
    " 'ST_int_V',\n",
    " 'neg_RT',\n",
    " 'neg_PT_V',\n",
    " 'neg_PR',\n",
    " 'RP',\n",
    " 'QRS_int_50_V',\n",
    " 'PR_int',\n",
    " 'PQ_int_V',\n",
    " 'PQ_int_10_V',\n",
    " 'QRS_int_V',\n",
    " 'PQ_int_50_V',\n",
    " 'RP_V',\n",
    " 'PR_int_V',\n",
    " 'R_amp8',\n",
    " 'PR_int_10_V',\n",
    " 'ST_int_10_V',\n",
    " 'QRS_int_10_V',\n",
    " 'rr_int_pre',\n",
    " 'neg_RT_V',\n",
    " 'neg_PR_V',\n",
    " 'PT_int_50_V',\n",
    " 'RT_int_50_V',\n",
    " 'Q_amp2',\n",
    " 'neg_RQ_V',\n",
    " 'ST_int_50_V',\n",
    " 'PT_int_10_V',\n",
    " 'RT_int_10_V',\n",
    " 'neg_ST_V',\n",
    " 'T_neg_areas_V',\n",
    " 'PR_int_50_V',\n",
    " 'PT_int_V',\n",
    " 'R_duration',\n",
    " 'T_neg_areas',\n",
    " 'QRS_int_10',\n",
    " 'Q_amp9',\n",
    " 'T_areas',\n",
    " 'T_neg_durations',\n",
    " 'P_neg_areas',\n",
    " 'QRS_int',\n",
    " 'P_neg_height',\n",
    " 'S_amp4_V',\n",
    " 'QRS_int_50',\n",
    " 'PQ_int_10']\n",
    "\n",
    "\n",
    "\n",
    "*** mRMR features ***\n",
    "Order    Fea     Name    Score\n",
    "1        261     dtw1    0.013\n",
    "2        246     RT_int_V        0.000\n",
    "3        126     neg_ST          0.000\n",
    "4        119     PT_int          0.000\n",
    "5        253     TR_V    0.000\n",
    "6        107     PQ_int          0.000\n",
    "7        20      Q_amp3          0.000\n",
    "8        243     ST_int_V        0.000\n",
    "9        127     neg_RT          0.000\n",
    "10       258     neg_PT_V        0.000\n",
    "11       125     neg_PR          0.000\n",
    "12       122     RP      0.000\n",
    "13       236     QRS_int_50_V    0.000\n",
    "14       110     PR_int          0.000\n",
    "15       237     PQ_int_V        0.000\n",
    "16       238     PQ_int_10_V     0.000\n",
    "17       234     QRS_int_V       0.000\n",
    "18       239     PQ_int_50_V     0.000\n",
    "19       252     RP_V    0.000\n",
    "20       240     PR_int_V        0.000\n",
    "21       11      R_amp8          0.000\n",
    "22       241     PR_int_10_V     0.000\n",
    "23       244     ST_int_10_V     0.000\n",
    "24       235     QRS_int_10_V    0.000\n",
    "25       99      rr_int_pre      0.000\n",
    "26       257     neg_RT_V        0.000\n",
    "27       255     neg_PR_V        0.000\n",
    "28       251     PT_int_50_V     0.000\n",
    "29       248     RT_int_50_V     0.000\n",
    "30       19      Q_amp2          0.000\n",
    "31       254     neg_RQ_V        0.000\n",
    "32       245     ST_int_50_V     0.000\n",
    "33       250     PT_int_10_V     0.000\n",
    "34       247     RT_int_10_V     0.000\n",
    "35       256     neg_ST_V        0.000\n",
    "36       228     T_neg_areas_V   0.000\n",
    "37       242     PR_int_50_V     0.000\n",
    "38       249     PT_int_V        0.000\n",
    "39       1       R_duration      0.000\n",
    "40       98      T_neg_areas     0.000\n",
    "41       105     QRS_int_10      0.000\n",
    "42       26      Q_amp9          0.000\n",
    "43       84      T_areas         0.000\n",
    "44       85      T_neg_durations         0.000\n",
    "45       70      P_neg_areas     0.000\n",
    "46       104     QRS_int         0.000\n",
    "47       58      P_neg_height    0.000\n",
    "48       165     S_amp4_V        0.000\n",
    "49       106     QRS_int_50      0.000\n",
    "50       108     PQ_int_10       0.000\n",
    "\n",
    "\n",
    "n_v\n",
    "\n",
    "['dtw1',\n",
    " 'T_neg_durations_V',\n",
    " 'T_neg_amp6',\n",
    " 'T_amp6',\n",
    " 'R_amp0_V',\n",
    " 'T_neg_amp1',\n",
    " 'T_amp7',\n",
    " 'dtw2',\n",
    " 'P_neg_T',\n",
    " 'T_neg_amp4',\n",
    " 'T_amp4',\n",
    " 'T_neg_amp7',\n",
    " 'T_amp8',\n",
    " 'neg_P_neg_T',\n",
    " 'T_neg_amp5',\n",
    " 'T_amp5',\n",
    " 'R_amp0',\n",
    " 'S_amp0',\n",
    " 'T_neg_amp2',\n",
    " 'rr_int_post_V',\n",
    " 'T_amp3',\n",
    " 'T_neg_amp3',\n",
    " 'T_prominence',\n",
    " 'T_neg_amp9',\n",
    " 'T_amp9',\n",
    " 'T_neg_amp0',\n",
    " 'T_amp2',\n",
    " 'T_neg_amp8',\n",
    " 'PT_int',\n",
    " 'T_amp1',\n",
    " 'R_prominence_V',\n",
    " 'T_height',\n",
    " 'T_amp0',\n",
    " 'T_neg_height',\n",
    " 'Q_amp1',\n",
    " 'T_neg_prominence',\n",
    " 'S_amp1',\n",
    " 'Q_amp0',\n",
    " 'Q_amp9_V',\n",
    " 'R_amp5_V',\n",
    " 'T_amp6_V',\n",
    " 'neg_PT',\n",
    " 'S_amp9_V',\n",
    " 'P_amp6',\n",
    " 'T_amp5_V',\n",
    " 'P_amp8',\n",
    " 'Q_amp2',\n",
    " 'T_amp3_V',\n",
    " 'R_amp1',\n",
    " 'P_amp3']\n",
    "\n",
    "*** mRMR features ***\n",
    "Order    Fea     Name    Score\n",
    "1        261     dtw1    0.164\n",
    "2        215     T_neg_durations_V       -0.000\n",
    "3        93      T_neg_amp6      0.012\n",
    "4        79      T_amp6          0.011\n",
    "5        133     R_amp0_V        0.010\n",
    "6        88      T_neg_amp1      0.005\n",
    "7        80      T_amp7          0.007\n",
    "8        262     dtw2    0.024\n",
    "9        129     P_neg_T         0.005\n",
    "10       91      T_neg_amp4      0.005\n",
    "11       77      T_amp4          0.006\n",
    "12       94      T_neg_amp7      0.004\n",
    "13       81      T_amp8          0.004\n",
    "14       130     neg_P_neg_T     0.003\n",
    "15       92      T_neg_amp5      0.005\n",
    "16       78      T_amp5          0.004\n",
    "17       3       R_amp0          0.005\n",
    "18       31      S_amp0          0.003\n",
    "19       89      T_neg_amp2      0.004\n",
    "20       230     rr_int_post_V   0.003\n",
    "21       76      T_amp3          0.003\n",
    "22       90      T_neg_amp3      0.004\n",
    "23       83      T_prominence    0.003\n",
    "24       96      T_neg_amp9      0.004\n",
    "25       82      T_amp9          0.003\n",
    "26       87      T_neg_amp0      0.003\n",
    "27       75      T_amp2          0.003\n",
    "28       95      T_neg_amp8      0.003\n",
    "29       119     PT_int          0.003\n",
    "30       74      T_amp1          0.003\n",
    "31       143     R_prominence_V          0.003\n",
    "32       72      T_height        0.002\n",
    "33       73      T_amp0          0.002\n",
    "34       86      T_neg_height    0.002\n",
    "35       18      Q_amp1          0.002\n",
    "36       97      T_neg_prominence        0.002\n",
    "37       32      S_amp1          0.002\n",
    "38       17      Q_amp0          0.001\n",
    "39       156     Q_amp9_V        0.001\n",
    "40       138     R_amp5_V        0.002\n",
    "41       209     T_amp6_V        0.001\n",
    "42       128     neg_PT          0.001\n",
    "43       170     S_amp9_V        0.001\n",
    "44       51      P_amp6          0.001\n",
    "45       208     T_amp5_V        0.001\n",
    "46       53      P_amp8          0.001\n",
    "47       19      Q_amp2          0.001\n",
    "48       206     T_amp3_V        0.001\n",
    "49       4       R_amp1          0.001\n",
    "50       48      P_amp3          0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "## small C from 1 to 3 seems to be good for f class recalled\n",
    "## degree 3 is better all around\n",
    "## Tol at 0.01 seems best\n",
    "\n",
    "def svm_model_poly(X_train, y_train, X_test, y_test, C=10, kernel='poly', degree=3, gamma='auto', \n",
    "                        coef0=0.001, shrinking=True, probability=True, tol=0.01, \n",
    "                        cache_size=200, verbose=False, \n",
    "                        max_iter=-1, decision_function_shape='ovo', random_state=None, labels = [0,1,2,3]):\n",
    "    \n",
    "    svm_model_linear = svm.SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, \n",
    "                        coef0=coef0, shrinking=shrinking, probability=probability, tol=tol, \n",
    "                        cache_size=cache_size, verbose=verbose, \n",
    "                        max_iter=max_iter, decision_function_shape='ovo', random_state=random_state) \n",
    "    \n",
    "    svm_model_linear.fit(X_train, y_train)\n",
    "    y_pred = svm_model_linear.predict(X_test)    \n",
    "    print(confusion_matrix(y_test,y_pred, labels=labels))  \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(metric.get_metrics(y_pred,y_test,lb=labels))\n",
    "    \n",
    "    return svm_model_linear,y_pred, metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def Linear_D(X_train, y_train, X_test, y_test, labels = [0,1,2,3]):\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)  \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred, labels = labels))  \n",
    "    print(classification_report(y_test,y_pred, labels=labels))\n",
    "    print(metric.get_metrics(y_pred,y_test, lb=labels))\n",
    "    \n",
    "    return clf,y_pred, metric.get_metrics(y_pred,y_test,lb=labels)[2]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Number of feature at 50 or 100 is good too\n",
    "## numner of estimators leaves at 1000 \n",
    "\n",
    "def randomForest(X_train, y_train, X_test, y_test,n_estimators=1000, criterion='gini', max_depth=16, min_samples_split=2, min_samples_leaf=3, min_weight_fraction_leaf=0.0001,min_impurity_decrease=0.0, max_features=50, max_leaf_nodes=None, class_weight='balanced', labels = [0,1,2,3]):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,min_weight_fraction_leaf=min_weight_fraction_leaf, class_weight=class_weight, min_impurity_decrease=min_impurity_decrease,max_features=max_features)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)    \n",
    "    print(confusion_matrix(y_test,y_pred, labels=labels))  \n",
    "    print(classification_report(y_test,y_pred, labels=labels))\n",
    "    print(metric.get_metrics(y_pred,y_test, lb=labels))\n",
    "    \n",
    "    return rf, y_pred, metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "### xgbo is good for normal classes too\n",
    "## do this one next \n",
    "## XGB is very goos for V class\n",
    "## XGboost tree classifcation is good with 5 or more tree depth\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def xgboost(X_train,y_train, X_test, y_test, max_depth = 8, eta = 1, gamma = 0.001, min_child_weight=0.1,max_delta_step=10, subsample=0.6,colsample_bytree = 0.7, colsample_bylevel= 1, colsample_bynode=1, alpha=0, reg_lambda= 1, tree_method='exact', grow_policy='depthwise', refresh_leaf=True, process_type='default', predictor= 'cpu_predictor', labels = [0,1,2,3]): \n",
    "    model = XGBClassifier(max_depth = max_depth, eta = eta, gamma = gamma,min_child_weight=min_child_weight,subsample=subsample, max_delta_step= max_delta_step,colsample_bytree=colsample_bytree,colsample_bylevel=colsample_bylevel,colsample_bynode=colsample_bynode,alpha=alpha,reg_lambda=reg_lambda,grow_policy=grow_policy, tree_method=tree_method,refresh_leaf=refresh_leaf,process_type=process_type, predictor= predictor,objective = 'reg:logistic')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(confusion_matrix(y_test.ravel(),y_pred.ravel(), labels=labels))  \n",
    "    print(classification_report(y_test.ravel(),y_pred.ravel(), labels=labels))\n",
    "    print(metric.get_metrics(y_pred.ravel(),y_test.ravel(), lb=labels))\n",
    "    \n",
    "    return model, y_pred,metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## L1 one is good , l2 would be used\n",
    "## very good at f class recall\n",
    "## solver = ['newton-cg', 'lbfgs', 'liblinear'are all good, ensemble with all would be good\n",
    "\n",
    "## false dual is better\n",
    "def logisticRegress(X_train, y_train, X_test, y_test, penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=10, class_weight='balanced', random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None, labels = [0,1,2,3]):\n",
    "    lr = LogisticRegression(penalty=penalty, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight=class_weight, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs)\n",
    "        # dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "    lr.fit(X_train, y_train.ravel())  \n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(confusion_matrix(y_test.ravel(),y_pred.ravel(), labels=labels))  \n",
    "    print(classification_report(y_test.ravel(),y_pred.ravel(), labels=labels))\n",
    "    print(metric.get_metrics(y_pred.ravel(),y_test.ravel(), lb=labels))\n",
    "    \n",
    "    return lr,y_pred, metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def ada(X_train, y_train, X_test, y_test,labels = [0,1,2,3]):\n",
    "\n",
    "    svm_model_poly = svm.SVC(C=10,  kernel='linear', degree=3, gamma='auto', \n",
    "                        coef0=0.0, shrinking=True, probability=True, tol=0.1, \n",
    "                        cache_size=200, verbose=False, \n",
    "                        max_iter=-1, decision_function_shape='ovo', random_state=None)\n",
    "\n",
    "    ada = AdaBoostClassifier(base_estimator=svm_model_poly, n_estimators=50 )\n",
    "    ada.fit(X_train, y_train)  \n",
    "    y_pred = ada.predict(X_test)\n",
    "    print(confusion_matrix(y_test.ravel(),y_pred.ravel(), labels=labels))  \n",
    "    print(classification_report(y_test.ravel(),y_pred.ravel(), labels=labels))\n",
    "    print(metric.get_metrics(y_pred.ravel(),y_test.ravel(), lb=labels))\n",
    "    \n",
    "    return ada, y_pred, metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "## Number of feature at 50 or 100 is good too\n",
    "\n",
    "\n",
    "def svm_model_linear(X_train, y_train, X_test, y_test, C=10, kernel='linear', degree=3, gamma='auto', \n",
    "                        coef0=0.0, shrinking=True, probability=True, tol=0.1, \n",
    "                        cache_size=200, verbose=False, \n",
    "                        max_iter=-1, decision_function_shape='ovo', random_state=None, labels = [0,1,2,3] ):\n",
    "    \n",
    "    svm_model_linear = svm.SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, \n",
    "                        coef0=coef0, shrinking=shrinking, probability=probability, tol=tol, \n",
    "                        cache_size=cache_size, verbose=verbose, \n",
    "                        max_iter=max_iter, decision_function_shape=decision_function_shape, random_state=random_state) \n",
    "    \n",
    "    svm_model_linear.fit(X_train, y_train)\n",
    "    y_pred = svm_model_linear.predict(X_test)    \n",
    "    print(confusion_matrix(y_test.ravel(),y_pred.ravel(), labels=labels))  \n",
    "    print(classification_report(y_test.ravel(),y_pred.ravel(), labels=labels))\n",
    "    print(metric.get_metrics(y_pred.ravel(),y_test.ravel(), lb=labels))\n",
    "    \n",
    "    return svm_model_linear, y_pred, metric.get_metrics(y_pred,y_test, lb=labels)[2]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "def voting_ensemble(X_train, y_train, X_test,y_test, labels=[0,1,2,3]):\n",
    "    svm_model_linear = svm.SVC(C=10, kernel='linear', degree=3, gamma='auto', \n",
    "                            coef0=0.0, shrinking=True, probability=True, tol=0.1, \n",
    "                            cache_size=200, verbose=False, \n",
    "                            max_iter=-1, decision_function_shape='ovo', random_state=None)\n",
    "\n",
    "    svm_model_poly = svm.SVC(C=10, kernel='poly', degree=3, gamma='auto', \n",
    "                            coef0=0.001, shrinking=True, probability=True, tol=0.01, \n",
    "                            cache_size=200, verbose=False, \n",
    "                            max_iter=-1, decision_function_shape='ovo', random_state=None)\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=16, min_samples_split=2, \n",
    "                                min_samples_leaf=3, min_weight_fraction_leaf=0.0001,min_impurity_decrease=0.0, \n",
    "                                max_features=50, max_leaf_nodes=None, class_weight='balanced')\n",
    "\n",
    "\n",
    "    lr = LogisticRegression( penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=10, \n",
    "                            class_weight='balanced', random_state=None, solver='warn', max_iter=100, multi_class='warn',\n",
    "                            verbose=0, warm_start=False, n_jobs=None)\n",
    "\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = 8, eta = 1, gamma = 0.001, min_child_weight=0.1,max_delta_step=10, \n",
    "                        subsample=0.6,colsample_bytree = 0.7, colsample_bylevel= 1, colsample_bynode=1, alpha=0, \n",
    "                        reg_lambda= 1, tree_method='exact', grow_policy='depthwise', refresh_leaf=True, \n",
    "                        process_type='default', predictor= 'cpu_predictor',objective = 'reg:logistic')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    eclf = VotingClassifier(estimators=[ ('xgb',xgb), ('lr',lr), ('svm_ln',svm_model_linear)], voting='hard')#, weights=[2,2,2,2])\n",
    "\n",
    "\n",
    "\n",
    "    #clf1 = clf1.fit(X, y)\n",
    "    #clf2 = clf2.fit(X, y)\n",
    "    #clf3 = clf3.fit(X, y)\n",
    "    eclf = eclf.fit(X_train, y_train)\n",
    "\n",
    "    predict = eclf.predict(X_test)\n",
    "    #scores = cross_val_score(X_train, y_train.data, iris.target, cv=10)\n",
    "    #scores.mean()                             \n",
    "\n",
    "    print(confusion_matrix(y_test,predict, labels=labels))  \n",
    "    print(classification_report(y_test,predict, labels=labels))\n",
    "    print(metric.get_metrics(predict.ravel(),y_test.ravel(),lb=labels))\n",
    "    \n",
    "    return eclf, predict, metric.get_metrics(predict.ravel(),y_test.ravel(), lb=labels)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
